INFO:10/29/2018 10:14:40 AM:Initializing class corpus for : anglais[corpus_en.py:417 - main()]
INFO:10/29/2018 10:14:40 AM: retrieving corpus from corpus class[corpus_en.py:419 - main()]
INFO:10/29/2018 10:14:40 AM:retrieving corpus list from db[corpus_en.py:64 - get_corpus_list_fromDB()]
INFO:10/29/2018 10:14:41 AM:1 RSS feeds[corpus_en.py:423 - main()]
INFO:10/29/2018 10:14:41 AM:retrieving last indexed url (last day) from db[corpus_en.py:98 - get_last_indexed_fromDB()]
INFO:10/29/2018 10:14:41 AM:0 already retrieved[corpus_en.py:427 - main()]
INFO:10/29/2018 10:14:41 AM:retrieving corpus[corpus_en.py:131 - retrieve_corpus()]
INFO:10/29/2018 10:14:41 AM:Retrieving rss feeds from list : [corpus_en.py:155 - retrieve_feeds()]
INFO:10/29/2018 10:14:41 AM:1 rss feeds[corpus_en.py:157 - retrieve_feeds()]
INFO:10/29/2018 10:14:41 AM:Retrieving feeds for :https://journals.plos.org/plosone/feed/atom[corpus_en.py:162 - retrieve_feeds()]
INFO:10/29/2018 10:14:43 AM:[u'Etats-Unis', u'PLOS', u'Sciences', u'National', u'rss', u'utf-8', u'606', u'en', u'None', u'None'][corpus_en.py:168 - retrieve_feeds()]
INFO:10/29/2018 10:14:43 AM:
30 articles[corpus_en.py:176 - retrieve_feeds()]
INFO:10/29/2018 10:14:43 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206729[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:43 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206729[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:14:46 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206721[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:46 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206721[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:14:47 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206719[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:47 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206719[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:14:49 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206663[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:49 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206663[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:14:50 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206613[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:50 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206613[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:14:53 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206578[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:53 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206578[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:14:59 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206576[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:14:59 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206576[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:01 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206539[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:01 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206539[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:03 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206530[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:03 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206530[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:05 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206512[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:05 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206512[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:06 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206503[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:06 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206503[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:08 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206499[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:08 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206499[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:10 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206469[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:10 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206469[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:15 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206463[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:15 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206463[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:19 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206444[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:19 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206444[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:21 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206435[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:21 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206435[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:24 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206426[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:24 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206426[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:26 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206421[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:26 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206421[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:29 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206416[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:29 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206416[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:30 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206412[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:30 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206412[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:32 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206378[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:32 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206378[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:35 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206375[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:35 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206375[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:38 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206366[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:38 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206366[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:40 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206350[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:40 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206350[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:43 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206344[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:43 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206344[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:46 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206323[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:46 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206323[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:48 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206301[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:48 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206301[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:50 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206299[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:50 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206299[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:53 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206295[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:53 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206295[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:55 AM:Retrieving https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206292[corpus_en.py:185 - retrieve_feeds()]
INFO:10/29/2018 10:15:55 AM:Retrieving : https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206292[URLutils.py:71 - get_url_article()]
INFO:10/29/2018 10:15:58 AM:[{'category': '', 'dateS': '2018-10-29T10:14:43Z', 'description': u'by Sara Costa-Cabral, Rachel Brough, Asha Konde, Marieke Aarts, James Campbell, Eliana Marinari, Jenna Riffell, Alberto Bardelli, Christopher Torrance, Christopher J. Lord, Alan Ashworth', 'title': u'Correction: Correction: CDK1 Is a Synthetic Lethal Target for KRAS Mutant Tumours', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206729', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Correction: Correction: CDK1 Is a Synthetic Lethal Target for KRAS Mutant Tumours\n\nThere is an error in the Correction published on April 20, 2017. The correct affiliation for the eighth author, Alberto Bartelli, is Candiolo Cancer Institute-FPO, IRCCS, Candiolo, TO, Italy and Department of Oncology, University of Torino, Candiolo, TO 10060, Italy.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:14:46Z', 'description': u'by Guoqiao Zheng, Hongyao Yu, Anna Kanerva, Asta F\xf6rsti, Kristina Sundquist, Kari Hemminki', 'title': u'Correction: Familial risks of ovarian cancer by age at diagnosis, proband type and histology', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206721', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Correction: Familial risks of ovarian cancer by age at diagnosis, proband type and histology', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:14:47Z', 'description': u'by The PLOS ONE Staff ', 'title': u'Correction: Abnormal CSF amyloid-\u03b242 and tau levels in hip fracture patients without dementia', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206719', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Correction: Abnormal CSF amyloid-\u03b242 and tau levels in hip fracture patients without dementia\n\nNotice of republication\nThis article was republished on October 16, 2018 to correct for formatting errors in the Materials and methods, Results, and Discussion sections introduced during the typesetting process. The publisher apologizes for these errors. Please download this article again to view the correct version. The originally published, uncorrected article and the republished, corrected article are provided here for reference.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:14:49Z', 'description': u'by Jos\xe9phine Grange, Manon Chatellier, Marie-Th\xe9r\xe8se Chev\xe9, Anne Paumier, Claudine Launay-Bourillon, Guillaume Legendre, Marion Olivier, Guillaume Ducarme\nObjective To identify the predictors of intrauterine balloon tamponade (IUBT) failure for persistent postpartum hemorrhage (PPH) after vaginal delivery. Design Retrospective case-series in five maternity units in a perinatal network. Setting All women who underwent IUBT for persistent PPH after vaginal delivery from January 2011 to December 2015 in these hospitals. Methods All maternity apply the same management policy for PPH. IUBT, using a Bakri balloon, was used as a second line therapy for persistent PPH after failure of bimanual uterine massage and uterotonics to stop bleeding after vaginal delivery. Women who required another second line therapy (embolization or surgical procedures) to stop bleeding after IUBT were defined as cases, and women whom IUBT stopped bleeding were defined as control group. We determined independent predictors for failed IUBT using multiple regression and adjusting for demographics with adjusted odds ratios (aORs) and 95% confidence intervals (95% CI). Results During the study period, there were 91,880 deliveries in the five hospitals and IUBT was used in 108 women to control bleeding. The success rate was % (80/108). In 28 women, invasive procedures were required (19 embolization and 9 surgical procedures with 5 peripartum hysterectomies). Women with failed IUBT were more often obese (% vs. %; p = ), duration of labor was shorter ( min vs. ; p = ), and major PPH (\u22651,500 mL) before IUBT was more frequent (64% vs. 40%; p = ). Obesity was a predictive factor of failed IUBT (aOR , 95% CI \u2013). Major PPH before IUBT seemed to be another predictor of failure (aOR , 95% CI \u2013), but our result did not reach statistical significativity. Conclusion Intrauterine balloon tamponade is an effective second line therapy for persistent primary PPH after vaginal delivery. Pre-pregnancy obesity is a risk factor of IUBT failure.', 'title': u'Predictors of failed intrauterine balloon tamponade for persistent postpartum hemorrhage after vaginal delivery', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206663', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Predictors of failed intrauterine balloon tamponade for persistent postpartum hemorrhage after vaginal delivery\n\nFigures\nAbstract\nObjective\nDesign\nRetrospective case-series in five maternity units in a perinatal network.\nSetting\nAll women who underwent IUBT for persistent PPH after vaginal delivery from January 2011 to December 2015 in these hospitals.\nMethods\nAll maternity apply the same management policy for PPH. IUBT, using a Bakri balloon, was used as a second line therapy for persistent PPH after failure of bimanual uterine massage and uterotonics to stop bleeding after vaginal delivery. Women who required another second line therapy (embolization or surgical procedures) to stop bleeding after IUBT were defined as cases, and women whom IUBT stopped bleeding were defined as control group. We determined independent predictors for failed IUBT using multiple regression and adjusting for demographics with adjusted odds ratios (aORs) and 95% confidence intervals (95% CI).\nResults\nDuring the study period, there were 91,880 deliveries in the five hospitals and IUBT was used in 108 women to control bleeding. The success rate was % (80/108). In 28 women, invasive procedures were required (19 embolization and 9 surgical procedures with 5 peripartum hysterectomies). Women with failed IUBT were more often obese (% vs. %; p = ), duration of labor was shorter ( min vs. ; p = ), and major PPH (\u22651,500 mL) before IUBT was more frequent (64% vs. 40%; p = ). Obesity was a predictive factor of failed IUBT (aOR , 95% CI \u2013). Major PPH before IUBT seemed to be another predictor of failure (aOR , 95% CI \u2013), but our result did not reach statistical significativity.\nConclusion\nIntrauterine balloon tamponade is an effective second line therapy for persistent primary PPH after vaginal delivery. Pre-pregnancy obesity is a risk factor of IUBT failure.\nData Availability: All relevant data are within the manuscript and its Supporting Information file (S1 File).\nFunding: The authors received no specific funding for this work.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nPostpartum hemorrhage (PPH) constitutes a major component of severe maternal morbidity and mortality and complicates approximately 5% to 15% of all deliveries [1]. After failure of primary management of PPH after vaginal delivery, second-line treatments, such as pelvic arterial embolization, vessel ligation, uterine compression sutures, can be attempted to achieve arrest of severe persistent PPH, defined as excessive bleeding (1,000 mL or greater) within the first 24 hours after birth [2], and to avoid peripartum hysterectomy [3\u20136]. In a recent large population-based retrospective cohort study included 72,529 women in two French perinatal networks, invasive procedures (pelvic vessel ligation, arterial embolization, hysterectomy) were used in  per 1,000 deliveries [7].\nRecently, a summary of studies showed that intrauterine balloon tamponade (IUBT), as Bakri balloon (Cook Medical, Bloomington, IN, USA), is an effective tool to avoid invasive procedures treating persistent PPH, and 75% of women did not need further treatment after IUBT [2]. Nonetheless, IUBT has been mainly described after all deliveries including a quarter to half of cesarean deliveries in each sample of the largest published studies [8\u201312], and only one study with a very small sample (n = 66) has specifically analyzed the effectiveness of IUBT after vaginal delivery [13]. In a retrospective study in five maternity units in a perinatal network, we aimed to evaluate the effectiveness of IUBT specifically after vaginal delivery for management of persistent PPH, and to identify the risk factors of IUBT failure after vaginal delivery on this population.\nMaterial and methods\nStudy sample\nThe study protocol and the consent procedure were approved by a Research Ethics Committee (Comit\xe9 d\u2019Ethique de la Recherche en Obst\xe9trique et Gyn\xe9cologie\u2013CEROG\u2014Paris) (N\xb0 2016-OBST-03-28) on 30th July 2016 before the beginning of the study. This study was conducted in accordance with the approved guidelines. All women received written information by the same midwife (MC). Written consent was not required for retrospective study according to the French law. This retrospective cohort study included all women who underwent IUBT, using Bakri balloon (Cook Medical, Bloomington, IN, USA), for persistent primary PPH after vaginal delivery from January 2011 to December 2015 in five maternity units in the same Pays de la Loire perinatal network in France. Postpartum hemorrhage (PPH) was defined by blood loss \u2265500mL within 24 hours after birth. The Pays de la Loire perinatal network in France contains 23 maternities with more than 40,000 births/year. The five maternities were arbitrarily chosen because they have used more than fifteen Bakri balloons for persistent PPH after vaginal delivery during the study period. Three centers are tertiary public hospitals with more than 4,000 births/year, 3,500 births/year and 2,600 births/year and the two others are secondary private hospitals with 4,900 births/year and 3,000 births/year. Women were identified in the hospital discharge database by the procedure codes for "intrauterine balloon tamponade" and "postpartum hemorrhage". An exclusion criterion was IUBT after cesarean delivery in the current pregnancy.\nMeasures\nThe details of the procedures used to manage PPH after vaginal delivery, as well as maternal sociodemographic characteristics, information regarding pregnancy follow-up, clinical characteristics at admission, intrapartum variables and all clinical outcomes identified during the immediate postpartum period were retrospectively collected by the same midwife (MC).\nAll maternity belongs to the same perinatal network and all aspects of management of the third stage of the labor were identical in all maternity: intravenous injection of 5 IU oxytocin; placement of a graduated (100 mL graduation) collector bag [MVF Merivaara, Lay-St Christophe, France] just after birth which was left in place until the birth attendant judged that bleeding had stopped and that there was no reason to monitor further, and always at least for 15 minutes; suturing of lacerations; and manual removal of the placenta at 30 minutes after birth if not expelled. A common protocol for the stepwise management of PPH to stop bleeding after vaginal delivery was developed in all maternity units in the network, including both bimanual uterine massage, manual exploration of the uterus and administration of additional uterotonic agents such as sulprostone within 30 minutes of the PPH diagnosis if oxytocin fails to control the bleeding, and with IUBT if these actions failed to stop bleeding before recourse to either surgery or interventional radiology [14]. Nonetheless, the decision to use IUBT after vaginal delivery, using a Bakri balloon (Cook Medical, Bloomington, IN, USA), was left to the obstetrician\u2019s discretion and was done with women\u2019s agreement.\nMaternal characteristics collected included age, pre-pregnancy body mass index (BMI, based on height and the first weight noted in the obstetric record), parity, previous cesarean section, and medical history, as history of PPH. Intrapartum variables recorded included gestational age at delivery determined by the craniocaudal length at a first-trimester ultrasound examination or by the date of last menstrual period and/or a second- or third-trimester ultrasound if the first-trimester ultrasound was not performed, as described in detail previously [15], prenatal suspicion of macrosomia determined by fundal height measurement at delivery > 37 cm and/or ultrasonographic fetal abdominal circumference > 90th percentile for gestational age on Hadlock curves, as described in detail previously [16], detailed labor and delivery information, including type of labor (spontaneous or induced), mode of induction of labor (prostaglandins, amniotomy, or oxytocin), type of analgesia (intravenous, local, or regional), durations of labor (from 3cm to birth) and of the active phase of second stage (from the beginning of expulsive efforts to birth), soft tissue damage (perineal hematoma, third or fourth-degree perineal lacerations, cervical laceration), and birth weight.\nThe maternal short-term outcome considered included estimated blood loss measured with a collector bag [MVF Merivaara, Lay-St Christophe, France] placed just after birth [5,17], times from birth to PPH onset and to each stage of PPH management (sulprostone administration, balloon insertion), causes of PPH, need for manual removal of partial or total retained placenta, need for an additional uterotonic agent (., sulprostone) due to PPH, mediolateral episiotomy (left to the discretion of the practitioner), soft tissue damage (perineal hematoma; second-, third- or fourth-degree perineal lacerations; cervical laceration), use of tranexamic acid, blood transfusions, invasive procedures for severe persistent PPH after failure of IUBT to stop the bleeding (defined by use of at least one of the following: uterine compression sutures, pelvic artery ligation, uterine embolization, or peripartum hysterectomy), and maternal postpartum complications, such as thromboembolic events (defined by a deep vein pulmonary embolism or thrombophlebitis), admission to intensive care, and maternal death. We also analyzed the characteristics of balloon introduction (volume inflated).\nThe objective was to determine predictors of failed IUBT in women with persistent PPH after vaginal delivery. The primary outcome was failure of IUBT, defined as a request of subsequent invasive procedures, such as pelvic arterial embolization, vessel ligation, uterine compression, or peripartum hysterectomy to stop bleeding. Women in the case group were defined as women who had IUBT but required another second line therapy (embolization or surgical procedures) to stop bleeding, and women whom IUBT stopped bleeding were defined as control group.\nStatistical analysis\nA de-identified data set of women with IUBT was entered into EXCEL spreadsheets (S1 File), and migrated into the free Web statistics tool BiostaTGV software (/) for analysis. No sample size calculation was done before the study and we collected data on all cases over a specified time period. Continuous parameters are given as means +/- standard deviation and compared by t-tests (or Mann-Whitney tests when appropriate); categorical variables were reported using counts and percentages and compared by chi-square tests (or Fisher exact tests when appropriate). Differences in maternal characteristics, obstetric, and PPH short-term-related outcomes were compared between the success and the failure groups. Crude odds ratio (OR) and 95% confidence interval (CI) were calculated for all factors studied in the analysis. Univariate and multivariable logistic regression analyses were conducted to determine independent predictors for failed IUBT. Factors identified as associated in univariate analysis with IUBT failure at a  level were included in this stepwise procedure. Statistical significance was defined as a P value < .\nResults\nDuring the 60-month study period, there were 91,880 deliveries in the five hospitals, 1,367 persistent PPH after vaginal delivery (%) and 108 women (%) underwent IUBT by use of a Bakri balloon (Cook Medical, Bloomington, IN, USA) to control bleeding after primary management of PPH after vaginal delivery (Fig 1).\nTable 1 summarizes the characteristics of the five maternities during the study-period (births, PPH, IUBT and failure of IUBT). Bleeding stopped after IUBT in 80 women (%). In 28 women (%), invasive procedures were required, including 19 arterial embolization and 9 surgical procedures with 5 peripartum hysterectomies (Fig 1). The rates of failure of IUBT (\u2013%) were no significantly different according to the maternity (Table 1).\nUterine atony (% (13/28) compared to % (26/80); p = ) was more frequent in the failure group. The success and failure groups had similar rates of active management of PPH (diagnosis of PPH period, management, sulprostone treatment, and estimated blood loss) (Table 3). Estimated blood loss at balloon insertion was higher in the failure group (\xb1 mL compared to \xb1; p = ) and PPH \u2265 1,500 mL before use of IUBT was more frequent in the failure group (64% compared to 40%; p = ). Nonetheless, the mean time from birth to IUBT (\xb1 compared to \xb1; p = ) did not differ between groups (Table 3).\nMean estimated blood loss after balloon placement (\xb1 compared to \xb1; p<) and mean elapse time of bleeding stop from birth (\xb1 compared to \xb1; p = ) were significantly higher in the failure group. As consequences, women in the failure group had higher total blood loss (2,\xb1 compared to 1,\xb1; p<). Frequencies of use of tranexamic acid, and packed red blood cells, fresh frozen plasma and fibrinogen concentrates transfusions, and transfusion of \u22654 U of packed red blood cells were significantly higher in the failure group (Table 3), in accordance with the perinatal network guidelines of management of persistent PPH which recommended systematic transfusions and use of tranexamic acid in these cases. The women who underwent intensive care units admission after delivery were more frequent (% compared to %; p<) in the failure group, and had longer hospitalizations in the maternity unit (\xb1 compared to \xb1 days; p = ) (Table 3). Overall, only two women, who were in the success group, had postpartum complications (thromboembolic events). There was no maternal death.\nAfter adjustment for confounding factors in the multivariate logistic regression analysis (maternal age, obesity, labor duration and estimated blood loss at balloon insertion), obesity was a risk factor of failed IUBT (aOR , CI95% \u2013). Major PPH (\u22651,500mL) at balloon insertion seemed to be another risk factor of failure (aOR , CI95% \u2013), but our result did not reach statistical significativity.\nDiscussion\nMain findings\nThis retrospective cohort study confirmed the effectiveness of IUBT in our perinatal network with a high rate of success of this process (%) to stop bleeding after primary management of PPH after vaginal delivery. We also demonstrated that pre-pregnancy obesity and major PPH (\u22651,500mL) at balloon insertion were risk factors of failed IUBT.\nInterpretation\nOur results are consistent with previous studies that reported rates of success of IUBT from 60 to 94% [8,10,18,19], and a systematic review from 46 studies reported an overall rate of success of 84% for IUBT [18]. Moreover, some authors have suggested that IUBT may be an effective solution of stabilizing a woman with persistent PPH before maternal transfer to an embolization unit [14] or prevent the need for embolization or surgery [20]. Nonetheless, IUBT has been mainly described after all deliveries including a quarter to half of cesarean deliveries in each sample of the largest published studies [8\u201312], and only one study has specifically analyzed the effectiveness of IUBT after vaginal delivery [13]. Recently, Darwish et al. [13] reported a single blinded randomized controlled trial conducted in Egypt including 66 women with primary atonic PPH following vaginal delivery to assess the efficacy of condom-loaded Foley\'s catheter versus Bakri balloon. In this small size sample study, Bakri balloon was an effective tool (30/33; %) for the management of primary atonic PPH following vaginal delivery [13].\nIn our study, pre-pregnancy obesity was a risk factor of failed IUBT (aOR , 95% CI \u2013), that has never been reported. It\u2019s an interesting result for physician because obesity is well known as a risk factor of PPH [21], and it appears to be also a risk factor of failure of IUBT. The information gained from this study is helpful in counselling physicians; obese women with persistent PPH after vaginal delivery are high-risk women for failed IUBT and will probably require more often invasive procedure to achieve bleeding after vaginal delivery and to improve maternal outcomes.\nWe reported that the mean time from birth to IUBT (\xb1 compared to \xb1; p = ) did not differ between groups and between maternity. Nonetheless, estimated blood loss at balloon insertion was higher in the failure group (\xb1 mL compared to \xb1; p = ) and major PPH (\u22651,500 mL) before use of IUBT was more frequent in the failure group (64% compared to 40%; p = ). Major blood loss (\u22651,500mL) before IUBT seems to be another predictive factor of failure (aOR , 95% CI \u2013; p = ), but our result did not reach statistical significativity. These results are in concordance with Howard et al. [22] who analyzed the efficacy of IUBT to decrease the maternal morbidity in 420 women with PPH. They showed that women receiving IUBT at lower estimated blood loss quartiles had with decreased maternal morbidity with higher nadir hemoglobin, less frequent packed red blood cell transfusion, fewer intensive care unit admissions, and fewer hysterectomies. The risk of coagulopathy increases quickly with blood loss and early IUBT may prevent its occurrence. Vintejoux et al. [9] also showed a 100% success rate of IUBT in case of early use (defined by a blood loss less than 1,000mL). Recently, a prospective cohort study in ten maternity units in a perinatal network in France including 226 women with IUBT (171 after vaginal delivery and 55 during or after caesarean delivery) showed that estimated blood loss before IUBT (>1,500mL) was a predictive factor of IUBT failure (aOR , 95% CI \u2013) [10]. Our study was probably underpowered to show a same significant result but these results may reinforce the idea that IUBT must be used earlier in the management of persistent PPH.\nStrengths and limitations\nThe principal strength of this study is that we only included women who required IUBT for a persistent PPH after vaginal delivery in a large retrospective multicentre study to identify the factors predicting IUBT failure. Most of the largest published studies mainly described the use of IUBT after all deliveries including a quarter to half of cesarean deliveries [8\u201312] that may modify analysis and conclusions. Second, all maternity units in the network followed a common protocol for stepwise management of PPH after vaginal delivery, with IUBT required as the initial second-line therapy, even though the decision to use IUBT after vaginal delivery was left to the obstetrician\u2019s discretion.\nThe main limitation is the retrospective design of this study limiting conclusions. Results may be biases from unknown factors that have been not collected in our study, even though exhaustive data were collected for all important factors potentially associated with IUBT failure (maternal characteristics, intrapartum variables such as type of labor or estimated blood loss before IUBT insertion, timing of the different step of PPH management). Second, we have arbitrarily chosen five maternities of the perinatal network which usually used IUBT with Bakri balloon (more than 15 cases) during the study period. That may introduce a selection bias about the results, even though we have selected maternities with the most trained teams about IUBT with Bakri balloon. Third, no formal sample size was calculated as we collected data on all cases over a specified time period. This means that some characteristics that might be truly predictive of failure may not have been identified due to a type 2 error.\nConclusion\nWe found that intrauterine balloon tamponade using Bakri balloon is an effective second line therapy for persistent primary PPH after vaginal delivery. Using IUBT as a systematic part of the management is a reasonable addition to PPH protocols. Maternal obesity at Bakri balloon insertion seemed to be a risk factor of failure of the device, and when Bakri balloon is placed late for persistent PPH after vaginal delivery that it is less likely to be successful. Furthermore, additional prospective studies included numerous women with persistent PPH after vaginal delivery are needed to confirm these results and to test the safety of IUBT to reduce maternal morbidity and mortality.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:14:50Z', 'description': u'by Daniele Bertoglio, Jeroen Verhaeghe, Lauren Kosten, David Thomae, Annemie Van der Linden, Sigrid Stroobants, John Wityak, Celia Dominguez, Ladislav Mrzljak, Steven Staelens\n\nThe positron emission tomography (PET) tracer [18F]MNI-659, selective for phosphodiesterase 10A (PDE10A), is a promising tool to assess an early biomarker for Huntington\u2019s disease (HD). In this study we investigated [18F]MNI-659 uptake in the Q175 mouse model of HD. Given the focal striatal distribution of PDE10A as well as the striatal atrophy occurring in HD, the spatial normalization approach applied during the processing could sensibly affect the accuracy of the regional quantification. We compared the use of a magnetic resonance images (MRI) template based on individual MRI over a PET and CT templates for regional quantification and spatial normalization of [18F]MNI-659 PET images. We performed [18F]MNI-659 PET imaging in six months old heterozygous (HET) Q175 mice and wild-type (WT) littermates, followed by X-ray computed tomography (CT) scan. In the same week, individual T2-weighted MRI were acquired. Spatial normalization and regional quantification of the PET/CT images was performed on MRI, [18F]MNI-659 PET, or CT template and compared to binding potential (BPND) using volumes manually delineated on the individual MR images. Striatal volume was significantly reduced in HET mice (-%, p<) compared to WT littermates. [18F]MNI-659 BPND in striatum of HET animals was significantly reduced (p<) when compared to WT littermates using all three templates. However, BPND values were significantly higher for HET mice using the PET template compared to the MRI and CT ones (p<), with an overestimation at lower activities. On the other hand, the CT template spatial normalization introduced larger variability reducing the effect size. The PET and CT template-based approaches resulted in a lower accuracy in BPND quantification with consequent decrease in the detectability of disease effect. This study demonstrates that for [18F]MNI-659 brain PET imaging in mice the use of an MRI-based spatial normalization is recommended to achieve accurate quantification and fully exploit the detectability of disease effect.', 'title': u'MR-based spatial normalization improves [18F]MNI-659 PET regional quantification and detectability of disease effect in the Q175 mouse model of Huntington\u2019s disease', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206613', 'keywords': '', 'ID_RSS': u'606', 'contents': u'MR-based spatial normalization improves [18F]MNI-659 PET regional quantification and detectability of disease effect in the Q175 mouse model of Huntington\u2019s disease\n\nFigures\nAbstract\nThe positron emission tomography (PET) tracer [18F]MNI-659, selective for phosphodiesterase 10A (PDE10A), is a promising tool to assess an early biomarker for Huntington\u2019s disease (HD). In this study we investigated [18F]MNI-659 uptake in the Q175 mouse model of HD. Given the focal striatal distribution of PDE10A as well as the striatal atrophy occurring in HD, the spatial normalization approach applied during the processing could sensibly affect the accuracy of the regional quantification. We compared the use of a magnetic resonance images (MRI) template based on individual MRI over a PET and CT templates for regional quantification and spatial normalization of [18F]MNI-659 PET images. We performed [18F]MNI-659 PET imaging in six months old heterozygous (HET) Q175 mice and wild-type (WT) littermates, followed by X-ray computed tomography (CT) scan. In the same week, individual T2-weighted MRI were acquired. Spatial normalization and regional quantification of the PET/CT images was performed on MRI, [18F]MNI-659 PET, or CT template and compared to binding potential (BPND) using volumes manually delineated on the individual MR images. Striatal volume was significantly reduced in HET mice (-%, p<) compared to WT littermates. [18F]MNI-659 BPND in striatum of HET animals was significantly reduced (p<) when compared to WT littermates using all three templates. However, BPND values were significantly higher for HET mice using the PET template compared to the MRI and CT ones (p<), with an overestimation at lower activities. On the other hand, the CT template spatial normalization introduced larger variability reducing the effect size. The PET and CT template-based approaches resulted in a lower accuracy in BPND quantification with consequent decrease in the detectability of disease effect. This study demonstrates that for [18F]MNI-659 brain PET imaging in mice the use of an MRI-based spatial normalization is recommended to achieve accurate quantification and fully exploit the detectability of disease effect.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: This work was funded by CHDI Foundation, Inc, a nonprofit biomedical research organization exclusively dedicated to developing therapeutics that will substantially improve the lives of HD-affected individuals. The funder had the following involvement with the study: study design and interpretation of the results. D. Bertoglio has a . fellowship from the Research Foundation Flanders (FWO, 11W2516N/11W2518N).\nCompeting interests: This study received funding from CHDI Foundation, Inc, a nonprofit biomedical research organization exclusively dedicated to developing therapeutics that will substantially improve the lives of HD-affected individuals. The funder had the following involvement with the study: study design and interpretation of the results. This does not alter our adherence to PLOS ONE policies on sharing data and materials\nIntroduction\nHuntington\u2019s disease (HD) is an autosomal dominant neurodegenerative disorder characterized by progressive decline in motor function and cognition, and development of psychiatric symptoms [1]. The disease is caused by an expanded CAG repeat in exon 1 of the gene encoding the protein huntingtin (HTT) [2]. Despite the progresses in elucidating the molecular pathology of HD, no disease-modifying therapies are yet available. The main neuropathological feature of HD is the loss of GABAergic medium spiny neurons (MSNs), which represent about 80\u201390% of striatal neurons [3]. This results in progressive striatal atrophy, followed by cortical degeneration in some patients [4].\nPhosphodiesterase 10A (PDE10A) is highly expressed in MSNs, where it regulates intracellular signaling by hydrolyzing the important second messengers cyclic adenosine monophosphate and cyclic guanosine monophosphate [5]. PDE10A has been proposed as an early biomarker and therapeutic target for HD based on the evidence that decreased levels of PDE10A expression occur before the onset of motor-related HD symptoms in transgenic HD mice [6]. In addition, pharmacological inhibition of PDE10A in mouse models of HD improved behavioral and neuropathological abnormalities [7, 8]. The recent development of selective PDE10A radioligands (. [18F]MNI-659, (2-(2-(3-(4-(2-[18F]fluoroethoxy)phenyl)-7-methyl-4-oxo-3,4-dihydroquinazolin-2-yl)ethyl)-4-isopropoxyisoindoline-1,3-dione) and [18F]JNJ42259152) [9, 10] allowed to investigate in vivo changes of PDE10A by means of positron emission tomography (PET). HD-related PDE10A decrease at early disease stage has been confirmed by several in vivo studies both in mouse models of HD [11\u201313] and patients with HD [14, 15].\nThese findings underline the importance of PET imaging in the evaluation PDE10A levels. However, given that PET is an imaging technique of comparatively low spatial resolution and PDE10A expression is mostly limited to the striatum, which is subjected to atrophy in HD, precise image processing and analysis may be challenging to achieve without individual magnetic resonance imaging (MRI). Indeed, co-registration of PET/Computed tomography (CT) with individual MRI, where PET images are fused onto the structural MRI of the same subject, allows taking advantage of the best of both techniques improving signal sensitivity.\nSpatial normalization of the PET images and delineation of the volumes of interest (VOIs) are critical steps for group-level statistical analyses. The most accurate method for quantification of PET images requires a dedicated individual MRI for precise co-registration of the PET images and manual delineation of the VOIs. However, this approach is laborious and it could be complicated by inter- and intra-operator variability. Thus, the use of a template for spatial normalization and creation of VOIs is very attractive to standardize the analysis. However, the choice of a specific template warrants caution as various templates are characterized by differences in performance and they might cause the introduction of inaccuracies and under- or overestimations in the quantification.\nIn this study, we investigated the ability of the PET ligand [18F]MNI-659 to detect changes in PDE10A levels at 6 months of age in the recently reported knock-in Q175 animal model for HD [16, 17]. The Q175 mouse model shows motor, cognitive, molecular and electrophysiological abnormalities similar to patients with HD. Given the focal striatal distribution of PDE10A as well as the striatal atrophy occurring in HD, we evaluated different approaches of spatial normalization of the PET data in order to determine which one provides optimal detectability of the disease effect: the first was based on a MRI template generated using the individual MR images, a second on a PET template, and a third using the CT images. The final aim of the study was to validate the most accurate spatial normalization approach for quantification of [18F]MNI-659 PET imaging in mice by comparing the binding potential (BPND) values from each method with BPND quantified in an independent manner using VOIs manually delineated on the individual MR images.\nMaterials and methods\nAnimals\nHeterozygous (HET) six months old male Q175 knock-in mice (n = 18; JAX strain name: -Htttm1Mfc/190JChdi) containing the human mutant HTT (mHTT) allele with the expanded CAG repeat within the native mouse Huntington gene [16] and age-matched C57BL/6J wild-type littermates (WT, n = 18) were obtained from Jackson Laboratories (Bar Harbour, Maine, USA). The animals were single-housed in individually ventilated cages under a 12 h light/dark cycle in a temperature- and humidity-controlled environment with food and water ad libitum. The animals were acclimatized to the facility for at least one week before the start of procedures, which were performed according to the European Committee Guidelines (decree 2010/63/CEE) and the Animal Welfare Act (7 USC 2131). All experiments were approved by the Ethical Committee for Animal Testing (ECD 2014\u201392) at the University of Antwerp (Belgium).\nT2-weighted MRI\nTo assess atrophy of the striatum and for co-registration purpose, individual MR images were obtained in the same week of the microPET/CT scan. The animals were anaesthetized using isoflurane in a mixture of N2/O2 (induction 5%, maintenance %) and placed in prone position onto the scanner (7T Biospec, Bruker, Germany). A rectal thermistor was inserted to monitor the body temperature, which was maintained at 37 \xb1 1\xb0C by means of a feedback-controlled warm air circuitry (MR-compatible Small Animal Heating System, SA Instruments, Inc. USA). Three-dimensional (3D) turbo rapid acquisition with relaxation enhancement (turboRARE) images were acquired with repetition time 3185 ms, echo time 44 ms, echo train length (ETL) was 8, and matrix size 128 x 64 x 40. Field of view (FOV) was  x 13 x 10 mm3 and resolution of  x  x  mm3. Images were acquired using a standard Bruker cross coil set-up with a quadrature volume coil for excitation and an array mouse surface coil for signal detection. The MR image acquisition procedure lasted 21 min. Data were acquired using ParaVision  (Bruker, Germany).\n[18F]MNI-659 microPET imaging\nSynthesis of [18F]MNI-659 was accomplished by reacting dried [18F]Fluoride with the MNI-659 precursor (7 mg) in DMSO (1 ml), followed by purification and formulation into a solution containing propyleneglycol, ethanol, and phosphate buffered saline solution (PBS) as previously described [10]. The specific activity was determined using a UV calibration curve (\u03bb = 230 nm) and was 305 \xb1  GBq/\u03bcmol.\nMicroPET/CT imaging was performed on two Siemens Inveon PET-CT scanners (Siemens Preclinical Solution, USA). An equal number of animals for each genotype was scanned on each PET-CT scanner in a head-to-head position. The animals were anaesthetized using isoflurane (Forene, Belgium) in medical oxygen (induction 5%, maintenance %). On the day of the scan, body weight was  \xb1  g for WT mice and  \xb1  g for HET Q175 mice (p < ). The body temperature of the animals was maintained at 37 \xb1 1\xb0C during the entire scanning period via a temperature-controlled heating pad. At the onset of the 90 min dynamic microPET scan, cold dose was within tracer conditions (< \u03bcg/kg) with WT mice receiving on average  \xb1  \u03bcg/kg and HET mice  \xb1  \u03bcg/kg. Thus, the radiotracer was injected intravenously with a bolus of  \xb1  MBq for WT and  \xb1  MBq for HET during 12 s (1 ml/min) using an automated pump (Pump 11 Elite, Harvard Apparatus, USA). Following the microPET scan, a 10 min 80 kV/500 \u03bcA CT scan was performed for attenuation correction and for co-registration of the microPET images to the MRI data. The microPET and CT images are co-registered by the scanner software given that the images are acquired on the same microPET/CT scanner. Two WT mice and two HET Q175 animals were excluded from the analysis due to CT-failure. One HET Q175 mouse was not included in the analysis due to faulty tracer injection.\nPET images were processed and analyzed using PMOD  software (Pmod Technologies, Zurich, Switzerland). Spatial normalization of the PET/CT images was performed three times independently using a MRI, a PET, and a CT template as described below in order to compare the three approaches.\nUsing VOIs manually delineated on the MRI template, time activity curves (TACs) of striatum and cerebellum were extracted from the spatially normalized images (S1 Fig). Following kinetic modelling performed with PKIN (PMOD ), the binding potential (BPND) for these regions was calculated using the simplified reference tissue model (SRTM) [19] with the cerebellum as reference tissue.\nBPND values obtained from the MRI, PET, and CT template-based normalized images were subsequently compared to evaluate the impact of spatial normalization on PET uptake quantification. To validate the accuracy of the template-based spatial normalization approaches for noninvasive [18F]MNI-659 quantification of BPND an independent quantification was performed using VOIs that were manually delineated on the individual MR images and calculating BPND. Next, CT images were co-registered to their individual T2-weighted MR image through rigid body transformation (rigid matching, mouse changing, interpolation method = trilinear, minimization method = downhill simplex) in PFUS (PMOD ). The transformations were saved and applied to the PET images. Then, TACs were extracted from the individual delineated VOIs (. striatum and cerebellum) using PVIEW (PMOD ). The striatal VOIs were manually delineated on the individual MR images using PVIEW, and they were used to measure changes in striatal volume between genotypes.\nAs the partial volume effect might affect [18F]MNI-659 quantification, BPND values obtained from the whole striatum from each template-based normalization approach were compared to the values extracted from 50% inner part of the original striatal VOI (focal striatum). In addition, to remove the anatomical boundaries of the striatal VOI, we have analyzed the effect of considering only the hottest 20% of the striatal VOIs on the BPND quantification. Then, BPND values were obtained from each template-based normalization approach and compared to the values determined using the VOIs manually delineated on the individual MR images.\nCreation of [18F]MNI-659 PET template.\nIn order to investigate the PET template-based spatial normalization, we first created the [18F]MNI-659 PET template in standardized MR space with VOIs manually delineated on the MRI template. Only data from the WT animals were used. As Fig 1 shows, static [18F]MNI-659 PET scans (n = 16) covering the whole scan duration (. 90 min) were generated. CT images were spatially co-registered to individual T2-weighted MR images through rigid body transformation (rigid matching, mouse changing, interpolation method = trilinear, minimization method = downhill simplex) in PFUS. This transformation was then applied to the PET images (PET and CT images were intrinsically co-registered as acquired on the same gantry) in order to co-register them to the individual MRI (Step 1). Next, MRI images were normalized to the MRI of the first animal through brain normalization (non-linear warping, 16 iterations, frequency cutoff = 3, regularization = 1) transformation in PFUS and were visually inspected for accuracy (Step 2). The average of all WT MR images normalized to the first animal were used to generate the MRI template on which VOIs (striatum and cerebellum) were manually delineated. Then, both CT and static PET images were normalized to the MRI template using the same MR to MR template transformation as their corresponding individual MR images. The transformed static PET images were averaged in order to obtain the [18F]MNI-659 PET template (Step 3). As illustrated in Fig 1, the resulting PET template was spatially registered to the MRI one and the VOIs delineated on the MRI template could also be used in the PET template (Step 4).\nFirst, static [18F]MNI-659 PET images covering the whole scan duration (. 90 min) were generated. Static PET images and the corresponding CT images were co-registered through rigid body transformation to their individual MRI (REG, Step 1) based on CT to MR transformation. Following this step, MRI and PET images were then normalized to the MRI of the first animal through a non-linear warping registration (NORM, Step 2) and were visually inspected for accuracy. Next, the static PET images were averaged in order to obtain the [18F]MNI-659 PET template (AVG, Step 3). The averages of all MR images normalized to the first animal were used to generate the MRI template and to delineate manually the VOIs (. striatum and cerebellum). The PET template corresponds and is spatially registered to the MRI template, thus the VOIs defined on the MRI template can be also used in the PET template (Step 4). Unmasked PET images were used for both spatial normalization approaches, however, for visual clarity, masked images are shown. Only data from the WT animals were used. REG = registration, NORM = normalization, AVG = average, WT = wild-type, HET = heterozygous.\nTemplate-based spatial normalizations.\nMRI template-based spatial normalization of the [18F]MNI-659 PET images was performed as summarized in Fig 2A. First, using PVIEW brains in PET and CT images were cropped automatically. Next, the CT images were thresholded using PVIEW (replace values <500 with 0) in order to have a clear image of the skull. Then, CT images were co-registered to their individual T2-weighted MR image through rigid body transformation (rigid matching, mouse changing, interpolation method = trilinear, minimization method = downhill simplex) in PFUS. The transformations were saved and applied to the PET images (Step 1). Next, brain normalization of the individual MR images to the MRI template was performed in PFUS (non-linear warping, 16 iterations, frequency cutoff = 3, regularization = 1). Transformed images were inspected for accuracy and the transformations were saved. Then, these transformations (. individual MRI to MRI template) were applied to the dynamic [18F]MNI-659 PET images (Step 2) in order to obtain the PET images normalized to the MRI template for extraction of the TACs (Step 3).\n(A) MRI template-based spatial normalization: CT images were co-registered to their individual T2-weighted MR image through a rigid body transformation and the same transformation was applied to the PET images (Step 1). Then a non-linear warping of the individual MR images to MRI template was performed (Step 2). The same transformation was applied to the [18F]MNI-659 PET images in order to obtain the PET images normalized to the MRI templates for extraction of the TACs from the VOIs (Step 3). (B) PET template-based spatial normalization: [18F]MNI-659 PET images were normalized through a non-linear warping to the PET template (Step 1) and TACs were extracted from the VOIs (Step 2). (C) CT template-based spatial normalization: CT images were co-registered to the CT of the first animal through a rigid body transformation and the same transformation was applied to the PET images (Step 1). Finally, TACs were extracted from the VOIs (Step 2). Unmasked PET images were used for both spatial normalization approaches, however, for visual clarity, masked images are shown. TACs = time-activity curves.\nPET template-based spatial normalization of the [18F]MNI-659 PET images was performed as depicted in Fig 2B starting from the same cropped images. Brain normalization of the individual static cropped PET images to the PET template was performed in PFUS (non-linear warping, 16 iterations, frequency cutoff = 3, regularization = 1) (Step 1). Transformed images were inspected for accuracy and the transformations were saved. Finally, transformations were applied to the dynamic images and the TACs were extracted (Step 2).\nCT template-based spatial normalization was done using the same cropped images as summarized in Fig 2C. CT images were co-registered to the CT of the first animal through a rigid body transformation (rigid matching, mouse constant, interpolation method = trilinear, minimization method = downhill simplex) and the same transformations were applied to the PET images (Step 1). Next, co-registered PET images were inspected for accuracy and the transformations were saved. Finally, dynamic images were transformed and the TACs were extracted (Step 2). As the MRI template was generated in the space of the first animal, the CT template corresponds and is spatially registered to the MRI template, thus the VOIs defined on the MRI template can be also used for the CT template.\nFor all spatial normalization approaches WT and HET mice underwent the same processing. Unmasked PET images were used for the registration processes in order to provide as much anatomical information as possible.\nStatistical analysis\nAll data were assessed for normality (Shapiro-Wilk test). Since no evidence against normality was found, unpaired T-test was used to compare whole brain and striatal volumes between WT and HET Q175 mice. Repeated-measurements ANOVA with Bonferroni correction for multiple comparison was used to investigate regional differences between WT and HET Q175 mice and within each genotype for all spatial normalization approaches. Agreement between BPND values obtained from the normalization approaches was estimated and visualized by Bland Altman plots as well as Pearson\u2019s correlation tests. In addition, Pearson\u2019s correlation tests were used to examine the correlation between BPND values based on manually delineated VOIs and the BPND values derived from the template-based approaches as well as to compare the BPND values obtained from the whole and 50% or 80% reduced striatal VOIs. Averages and standard errors of the differences as well as 95% confidence intervals (CI) of difference were reported when comparing the normalization approaches. All analyses were performed with GraphPad Prism (v ) statistical software, with the exception of the effect size, which was calculated with G*Power software (/). The data are represented as mean \xb1 standard deviation (SD) unless specified. All tests were two-tailed and significance was set at p < .\nResults\nVolumetric assessment\nVolumetric assessment of striatum was performed using VOIs manually delineated on the individual MR images and is represented in Fig 3. No difference in whole brain volume was observed between genotypes (p = ). Striatal volume normalized to the whole brain was significantly reduced in HET mice compared to WT littermates (p < ), displaying a volume reduction of % in HET compared to WT mice.\nMRI template-based spatial normalization resulted in an average decrease of  \xb1 10% (95% CI of difference = + to +) in the striatum of HET mice compared to WT littermates at 6 months of age. PET template-based spatial normalization showed a decrease in the striatum of HET mice (average decrease of  \xb1 %; 95% CI of difference = + to +) compared to WT littermates at 6 months of age. Finally, CT template-based spatial normalization resulted in an average decrease of  \xb1 % (95% CI of difference = + to +) in the striatum of HET mice compared to WT littermates at 6 months of age.\nThe MRI-based approach showed the largest effect size (d = ) given the large average difference and limited standard deviation of the groups. The PET-based approach resulted in a lower effect size (d = ) due to the reduced average difference between genotypes. Finally, the CT-based approach showed the lowest effect size (d = ) because of the larger standard deviation in each investigated group (Table 1).\nImpact of spatial normalization for PET quantification\nThe results of the different spatial normalizations for [18F]MNI-659 are summarized in Table 1 and Fig 4B. The BPND values in striatum were higher in both WT and HET when analyzed using the PET template-based spatial normalization. This normalization-based difference was pronounced and statistically significant in the HET Q175 mice when compared to both the MRI template (p < ; + \xb1 %; 95% CI of difference = + to +) as well as the CT template (p < ; + \xb1 %; 95% CI of difference = + to +) (Table 1). WT mice displayed only a negligible normalization-based change when compared to the MRI-based (p = ; +%; 95% CI of difference = - to +) or CT-based (p = ; +%; 95% CI of difference = - to +) quantification (Table 1). As a result, the BPND difference between HET and WT Q175 mice was reduced when using the PET template-based normalization instead of the MRI template-based one. In addition, the CT template-based approach was characterized by an increased standard deviation for both WT and HET animals, thus requiring larger group sizes to obtain the same statistical power. Overall BPND values obtained using the PET and MRI template-based normalization strategies significantly correlated (WT: r = , r2 = , and p < ; HET: r = 0842, r2 = , and p < ), however the regression line sensibly deviated from the identity line for HET Q175 mice (Fig 5A), especially towards the lower activities. The deviation between these two normalization strategies of the HET Q175 mice can also be appreciated with a Bland Altman plot, where the bias between the two approaches is represented by the gap between the mean (red and blue dashed lines for HET and WT, respectively) and the X axis (% and % for HET and WT, respectively) (Fig 5B). On the other hand, BPND values obtained using the CT template-based normalization approach significantly correlated with the MRI template-based ones (WT: r = , r2 = , and p = ; HET: r = , r2 = , and p < ), however the correlations were only moderate due to a more scattered distribution (Fig 5C). The Bland Altman plot based on the CT and MRI template-based approaches underlined this variability as visible by the large 95% confidence intervals (dotted lines, Fig 5D).\n(A) Correlation between striatal [18F]MNI-659 BPND values obtained from MRI- and PET-based spatial normalizations for WT and HET Q175 mice. The regression line of HET Q175 mice sensibly deviated from the identity line (dotted line) at lower values. (B) Bland Altman plot to compare the MRI- and PET-based approaches of spatial normalizations for [18F]MNI-659. HET Q175 mice were characterized by a relevant deviation between the two approaches, while WT littermates showed high agreement between measurements. (C) Correlation between striatal [18F]MNI-659 BPND values obtained from MRI- and CT-based spatial normalizations for WT and HET Q175 mice. (D) Bland Altman plot to compare the MRI- and CT-based approaches of spatial normalizations for [18F]MNI-659. HET Q175 mice were characterized by a deviation between the two approaches, while WT littermates showed agreement between measurements. Dotted lines represent the 95% limits of agreement (mean difference \xb1  x SD of the differences). The bias between the two approaches is represented by the gap between the mean (red and blue dashed lines for HET and WT, respectively) and X axis (solid line). The solid horizontal line indicates y = 0. WT = wild-type, HET = heterozygous.\nFinally, to remove the anatomical boundaries of the striatal VOI, we have analyzed the effect of considering only the hottest 20% of the striatal VOIs on the BPND quantification (S3 Fig). The resulting correlations were comparable to the ones obtained considering the whole striatal VOI (Fig 6), with an expected increase of the values due to the smaller VOI: MRI template (r = , p <  and r = , p =  for WT and HET mice, respectively) (Panel A in S3 Fig), PET template (r = , p =  and r = , p =  for WT and HET mice, respectively) (Panel B in S3 Fig), and CT template (r = , p =  and r = , p <  for WT and HET mice, respectively) (Panel C in S3 Fig). These results suggest that the VOI delineation and size did not change the outcome.\nDiscussion\nTo date, no studies to directly validate the influence of MRI for [18F]MNI-659 PET quantification have been performed. In the present work, we prospectively evaluated the BPND values after MRI, PET, and CT template-based spatial normalization of HET mice and WT littermates. We found that the PET template-based spatial normalization resulted in significantly higher BPND values in striatum of HET Q175 mice. The CT template-based approach did not affect the group-average quantification, however ensued in a larger variability at the group levels.\nSince dedicated high resolution small animal MR scanners are not often available in proximity of preclinical PET centers, the use of a ligand-specific PET template is frequently the preferred choice and it has proved to provide high accuracy results [20\u201324]. However, likely due to the focal uptake of [18F]MNI-659 and the substantial signal reduction in HET Q175 mice, the performance of the PET template is not sufficient to ensure proper quantification. A valid alternative could be the use of the CT images for spatial normalization since they are acquired in parallel with the PET images for attenuation correction [25]. Although this approach might be easy to apply, it lacks detailed information of the brain due to the limited contrast of the brain tissue. Indeed, given the high intensity of the signal in the skull, this is the only structure to drive the CT-based spatial normalization [26]. As a consequence of the lack of spatial information within the brain structures, the performance of this approach can provide an overall reliable group-level quantification, but it is not accurate when looking at the specific subject.\nA major hallmark of HD is loss of projection neurons in the striatum, with consequent striatal atrophy [4]. Given that PDE10A is expressed in MSNs in the striatum, structural changes could potentially affect the PET quantification. In the present study, we found decreased striatal volume of HET Q175 mice as previously reported in animal models of HD [16, 27, 28]. A cross-sectional study in patients with early HD demonstrated a relationship between striatal [18F]MNI-659 uptake and regional brain atrophy (r = , p < ) [15]. However, this was not the case in present study.\nIn this study, we found a statistically significant decrease in [18F]MNI-659 BPND values in HET mice compared to WT littermates at 6 months of age using all spatial normalization approaches (-%, -%, and -% for MRI, PET, and CT template-based, respectively). This is in line with the recent literature where a decrease of 40 to 50% in binding of PDE10A in the striatum has been reported in animal models of HD [11\u201313] as well as in patients with HD [14, 15, 29]. When we evaluated the differences in BPND values between the spatial normalization approaches, we found that PET template-based normalization resulted in statistically significant higher BPND values in striatum of the HET mice compared to the other two approaches (p < ). This deviation in HET Q175 mice was clearly visible when using the Bland Altman plot.\nNonetheless, a comparison of the approaches to an independent measurement is required to ensure which method is more accurate in obtaining the striatal binding potential. To this end, we quantified BPND with VOIs manually delineated on the individual MR images since the values obtained with this approach should represent the reference methods for BPND quantification of [18F]MNI-659. Interestingly, the MRI template-based approach was almost in perfect agreement with BPND (r >  for both genotypes). The PET template-based approach resulted in weaker correlations with BPND for HET Q175 mice (r = ) with a clear deviation from the identity line, and the CT template-based approach showed moderate correlation for WT mice (r = ).\nThese evidences suggest that PET template-based normalization introduces some deviations at lower activities, possibly due to the very low spatial information in the PET images, resulting in a less accurate normalization. Although this observed overestimation of the BPND values at lower activities may seem counterintuitive, it is likely to be linked to the mismatch between the PET template and the individual HET PET images. The software may introduce changes during the spatial normalization in order to compensate for the decreased signal, causing a deformation of the image in order to better fit it to the PET template. Alternatively, it might enhance the spillover from outside into the striatum to increase the activity and better match the template. Since at very low radiotracer uptakes there was a larger mismatch, this effect might be amplified with the reduction of the uptake. Consequently, the PET template-based approach is characterized by an overestimation of the striatal binding potential at lower activities, which translates in a decline of the capacity to detect the disease effect.\nUnlike the PET template approach, the CT-based spatial normalization did not introduce deviations from the identity line, however the BPND values showed a larger variability. Thus, the CT template-based approach resulted in a reduced statistical power, thus lowering the detectability of the disease effect.\n[18F]MNI-659 PET imaging is a promising noninvasive tool to detect early HD. It may be employed to monitor longitudinal changes and as treatment read-out when testing efficacy of novel HD therapies. For these reasons, it is important to apply the most accurate spatial normalization approach in order to avoid the introduction of biases that could lead to the misinterpretation of results. For instance, the overestimation of BPND values introduced by the PET template-based spatial normalization fails to accurately quantify the striatal BPND at lower values. Consequently, the temporal decline during a longitudinal study or the efficacy of a novel therapy in preventing PDE10A decline could be underestimated.\nPDE10 has been detected as one of the earliest and most profoundly downregulated gene in mouse models of HD [6, 17, 30\u201332]. This reduction in PDE10A levels is not only related to neuronal loss in the striatum, but it has been suggested to be related to interference of mHTT with the transcriptional machinery of PDE10A, leading to an altered pattern of gene expression followed by neuron dysfunction and death [33]. In addition, [18F]MNI-659 binding strongly correlates with markers of disease severity [15]. Interestingly, a recent longitudinal study in patients with HD showed an average 15% decline in [18F]MNI-659 binding potential in the caudate suggesting caudate as a sensitive marker of early premanifest pathology or prediction of the motor manifestation [29]. Finally, [18F]MNI-659 is characterized by excellent brain penetration, good specificity for PDE10A, a high signal to background ratio, and test-retest reliability [10, 15]. Given the potential application of this PET tracer to monitor an early biomarker for HD, and considering its possible application to predict treatment response, it is fundamental to exploit its potential by determining the optimal spatial normalization to detect disease effect.\nIn conclusion, this study demonstrates that for [18F]MNI-659 brain PET imaging in mice the use of a PET or CT template-based approach results in a lower accuracy of BPND quantification with overestimation of binding potential when tracer uptake is significantly reduced or increased variability with reduced statistical power, respectively. Thus, the use of an MRI-based spatial normalization is recommended to achieve accurate quantification and higher detectability of disease effect.\nBPND of [18F]MNI-659 using striatal VOI manually delineated on the individual MR images were compared to the hottest 20% of the striatal VOIs for each spatial normalization approach. BPND values showed strong significant correlations with the MRI template-based approach for both WT and HET mice (r =  and r = , respectively) (A) as well as with the PET template-based approach for WT mice (r = ), while HET mice did not (r = ) and they sensibly deviated from the identity line (B). Finally, significant correlations were found when using the CT-based approach for both WT and HET mice (r =  and r = , respectively) (C). Pearson\u2019s correlation tests. Dotted line represents identity line. WT = wild-type, HET = heterozygous.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:14:53Z', 'description': u'by Behrouz Taheri, Mohsen Mohammadi, Iraj Nabipour, Niloofar Momenzadeh, Mona Roozbehani\nBackground The global crisis of antibiotic resistance increases the demand for the new promising alternative drugs such as antimicrobial peptides (AMPs). Accordingly, we have described a new, previously unrecognized effective AMP, named dicentracin-like, from Asian sea bass and characterized its antimicrobial activity by comparison with moronecidin. Methodology/ Results Gene expression analysis demonstrated the expression of dicentracin-like peptide in tissues of the immune system such as the skin and the head kidney, which is an important endocrine and lymphoid organ. Moronecidin and dicentracin-like exhibited a higher antibacterial activity against gram-positive bacteria relative to gram-negative ones, while both peptides showed a greater binding ability to gram-negative bacteria compared to gram-positive ones. This contradiction between antibacterial activity and binding affinity may be related to the outer membrane from gram-negative bacteria. Compared with moronecidin, dicentracin-like peptide showed more potent binding ability to all gram-positive and gram-negative bacteria. In addition, dicentracin-like peptide exhibited a high antibacterial activity against the investigated microorganisms, except against Staphylococcus aureus. A direct relationship was found between the binding affinity/cationicity and the antibiofilm activity of the peptides wherein, an elevation in pH corresponded to a decrease in their antibiofilm property. Time-kill kinetics analysis against clinical Acinetobacter baumannii isolate indicated that bactericidal effect of dicentracin-like and moronecidin at inhibitory concentration (1XMIC) was observed after 4 and 6 hours, respectively, while bactericidal effect of both AMPs at concentration of 2XMIC was observed after 2 hours. Dicentracin-like peptide showed higher inhibitory activity at subinhibitory concentration (1/2XMIC), relative to moronecidin. Compared with moronecidin, dicentracin-like peptide possessed greater binding affinity to bacteria at high salt concentration, as well as at alkaline pH; In addition, dicentracin-like exhibited a higher antibiofilm activity in comparison to moronecidin even at alkaline pH. Hemolytic analysis against human RBC revealed that hemolytic activity of moronecidin was more potent than that of dicentracin-like, which is consistent with its greater non-polar face hydrophobicity. Conclusions In the present study, In Silico comparative sequence analysis and antimicrobial characterization led to identify a new, previously unrecognized antimicrobial function for named dicentracin-like peptide by comparison with moronecidin, representing a possible template for designing new effective AMPs and improving known ones.', 'title': u'Identification of novel antimicrobial peptide from Asian sea bass (Lates calcarifer) by in silico and activity characterization', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206578', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Identification of novel antimicrobial peptide from Asian sea bass (Lates calcarifer) by in silico and activity characterization\n\nFigures\nAbstract\nBackground\nThe global crisis of antibiotic resistance increases the demand for the new promising alternative drugs such as antimicrobial peptides (AMPs). Accordingly, we have described a new, previously unrecognized effective AMP, named dicentracin-like, from Asian sea bass and characterized its antimicrobial activity by comparison with moronecidin.\nMethodology/ Results\nGene expression analysis demonstrated the expression of dicentracin-like peptide in tissues of the immune system such as the skin and the head kidney, which is an important endocrine and lymphoid organ. Moronecidin and dicentracin-like exhibited a higher antibacterial activity against gram-positive bacteria relative to gram-negative ones, while both peptides showed a greater binding ability to gram-negative bacteria compared to gram-positive ones. This contradiction between antibacterial activity and binding affinity may be related to the outer membrane from gram-negative bacteria. Compared with moronecidin, dicentracin-like peptide showed more potent binding ability to all gram-positive and gram-negative bacteria. In addition, dicentracin-like peptide exhibited a high antibacterial activity against the investigated microorganisms, except against Staphylococcus aureus. A direct relationship was found between the binding affinity/cationicity and the antibiofilm activity of the peptides wherein, an elevation in pH corresponded to a decrease in their antibiofilm property. Time-kill kinetics analysis against clinical Acinetobacter baumannii isolate indicated that bactericidal effect of dicentracin-like and moronecidin at inhibitory concentration (1XMIC) was observed after 4 and 6 hours, respectively, while bactericidal effect of both AMPs at concentration of 2XMIC was observed after 2 hours. Dicentracin-like peptide showed higher inhibitory activity at subinhibitory concentration (1/2XMIC), relative to moronecidin. Compared with moronecidin, dicentracin-like peptide possessed greater binding affinity to bacteria at high salt concentration, as well as at alkaline pH; In addition, dicentracin-like exhibited a higher antibiofilm activity in comparison to moronecidin even at alkaline pH. Hemolytic analysis against human RBC revealed that hemolytic activity of moronecidin was more potent than that of dicentracin-like, which is consistent with its greater non-polar face hydrophobicity.\nConclusions\nIn the present study, In Silico comparative sequence analysis and antimicrobial characterization led to identify a new, previously unrecognized antimicrobial function for named dicentracin-like peptide by comparison with moronecidin, representing a possible template for designing new effective AMPs and improving known ones.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nAntibiotic agents are effective compounds to eradicate pathogenic bacteria, consequently leading to the treatment of these infections caused by these pathogens. In the past years, the emergence of multi-drug resistant pathogens has reduced therapeutic efficiency of classical antibiotics [1\u20133]. To fight against drug resistant pathogens, there is an urgent demand for the discovery of novel antibiotics [4]. Antimicrobial peptides have attracted considerable attention owing to their broad-spectrum antibacterial activity and their ubiquitous presence as a part of the host defense systems in both invertebrates and vertebrates [5\u20137]. In contrast to conventional antibiotics, most of the AMPs exert their antibacterial activity without the need for binding to a specific ligand. These AMPs disrupt membrane integrity through pore formation in the cell membrane. Furthermore, some of them can prevent proteins and nucleic acids synthesis in bacteria through inhibition of certain enzymes involved in these processes, [8, 9]. Innate immunity is very vital for vertebrates with less efficient adaptive immunities, especially those with exposure to a wide range of pathogens such as fish and amphibians. Fish as a rich sources of AMPs, expresses major classes of AMPs including pleurocidins, and piscidin [10\u201312]. In addition, it has been demonstrated that Fish-originated AMPs retain antibacterial properties even in high salt concentration [13]. The purification and identification of AMPs from natural sources are laborious, time consuming, and sometimes impossible due to their very low expression; accordingly, a sufficient number of animals and their tissues are required for purification of AMP [14]. To overcome these problems, the identification of AMPs-coding nucleotide sequence from small tissue-derived genomic DNA or a genomic and expressed sequence tag (EST) database is a good strategy [15]. AMPs are produced from a precursor containing a very conserved signal peptide that can be employed as a query sequence in the NCBI database to find novel AMPs [15], while the mature AMPs sequence is highly variable even in closely related species. This variability is observed in a species with different microbiota such that their sequence is under robust natural selection [15, 16]. Moronecidin, a member of the piscidin family, is an amphipathic and cationic well-known AMP that was initially isolated from the hybrid striped bass. Its precursor contains a signal peptide, mature piscidin-like peptide, and a C-terminal prodomain. Similar to other AMPs, the signal peptide-coding sequence of moronecidin is more significantly conserved than the two other parts [17]. In the present study, in silico comparative sequence analysis using the signal peptide of moronecidin led to identification of a new, previously unrecognized cationic peptide, named dicentracin-like, in Asian sea bass (Latescalcarifer), and afterwards antimicrobial characterization of the peptide was performed by comparison with moronecidin.\nMaterials and methods\nDatabase searching\nThe signal peptide sequences of moronecidin from hybrid striped bass [18] (MKCATLFLVLSMVVLMAEPGDA, ) was used as a query to search for the non-redundant GenBank CDS translations + PDB + SwissProt + PIR+ PRF against Asian sea bass(barramundi perch, tax id: 8187) with an algorithm parameters word size: 3, matrix: BLOSUM62, gap costs: existence 11, and extension 1 [15, 17]. The output hits were examined for the conserved signal peptide and the first case in the output was predicted as dicentracin-like(), with the highest total score (cover score: 95%; identity score:86%). The amino acid sequence of dicentracin-like () was used as a query in BLASTP  + against the non-redundant Gen Bank CDS translations + PDB + SwissProt + PIR + PRF. The output revealed that the peptide was most similar to known AMPs, such as piscidin-4 and -5 precursors from the hybrid striped bass (GenBank  and ). Therefore, this finding suggests that dicentracin-like () can be a novel AMP.\n(A) The residue numbering starts from the N-terminus. Hydrophobic and positively charged residues are defined with yellow and blue color, respectively. (B) Three dimensional structure of dicentracin-like as predicted by I-TASSER (-TASSER/) and three dimensional structure of moronecidin with PDB code2 JOS as obtained from protein data bank () and displayed with Discovery studio 3.\nEthics statement\nAll animal proceduresin this study were performed under protocol approved by the Animal Care and Use Committee of Bushehr University of Medical Sciences\u2013Iran (Permit number: ). The animal experiments were in accordance with the Specific National Ethical Guidelines for Biomedical Research issued by the Research and Technology Deputy of Ministry of Health and Medicinal Education (MOHME) of Iran (issued in 2005).\nCloning and sequencing\nTotal RNA was extracted from Asian sea bass fish with Trizol (GeneALL, Korea) and the first chain complementary deoxyribonucleic acid (cDNA) was synthesized according to the manufacturer\u2019s instructions (Thermo, Life Sciences). Dicentracin-like coding gene () was amplified using the specific forward (5- ATA GGA TCCATGAAGTGTGTTATGCTTTTTC -3) and reverse (5- ATA CTC GAGTCAAAATGAGGCCTGATAATC-3) primers that were designed using Gene Runner software on the basis of dicentracin-like gene sequences(). After amplification of the gene, PCR product was extracted from agarose gel and digested with BamH1/Xho1 enzymes, and inserted in BamH1/Xho1 sites in the pET28b vector. \u03b1 cells were transformed ligated plasmid and colony containing recombinant plasmid was selected by the colony PCR method using T7 universal primers. Then the recombinant plasmid was extracted and the inserted DNA was sequenced (Source: BioScience, UK).\nSemi-quantitative RT-PCR\nTotal RNA was extracted from the skin, the head kidney, the lung and the intestine tissue (100 mg) using RiboEx Total RNA (GeneALL, Korea). The first chain of complementary deoxyribonucleic acid (cDNA) was synthesized according to the manufacturer\u2019s instructions (Thermo, Life Sciences); and was used as a template to amplify dicentracin-like coding gene () by a polymerase chain reaction. The specific primers were designed according to the sequence of the dicentracin-like gene () and was amplified using the following primers, including the forward primer: 5- ATGAAGTGTGTTATGCTTTTTC -3 and reverse primer: 5- TCAAAATGAGGCCTGATAATC -3. For semi-quantitative RT-PCR, EF1\u03b1 gene was used as an internal control; the forward and reverse primers for EF1\u03b1 gene were 5\u2019-TGCTGATTGTGGCTGCTGGTACTG -3\u2019 and 5\u2019- GGTGTAGGCCAGCAGGGCGTG-3, respectively. The dicentracin-like gene expression was relatively quantified with Image software. The relative quantification was determined by the expression level of dicentracin-like gene relative to the EF1\u03b1 gene expression in each tissue.\nPeptide synthesis\nDicentracin-like and morocidin peptides were synthesized by the solid-phase synthesis method using N-(9-fluorenyl) methoxycarbonyl (Fmoc) chemistry by Pepmic (Suzhou, China) and were purified with RP-HPLC, using the SHIMADZU Inertsil ODS-SP(*250 mm* 5\u03bcm) column. Peptides were eluted by a 0\u2013100% H2O/acetonitrile gradient, with % trifluoroacetic acid for 30 minutes. The homogeneity of peptides were estimated with analytical high-performance using an Inertsil ODS-SP (*250 mm* 5\u03bcm) column that showed 95% purity. The correct atomic masses of purified peptides were verified with mass spectrometry (MS). The N-and C-terminals of peptides were modified with 5-FAM and an amine group (NH2, amidated C-terminus), respectively.\nRetention time of peptides\nThe retention time of the peptides were calculated by RP HPLC using an analytical SHIMADZU Inertsil ODS-SP (*250 mm* 5\u03bcm) column. A linear gradient of 0\u2013100% acetonitrile supplemented with % trifluoroacetic acid was used to elute peptides at a flow rate 1ml/minute for 30 minutes. The highest peak in 214 nm was considered as the retention time for each peptide.\nMinimum inhibitory concentration (MIC)\nThe antimicrobial activity of dicentracin-like peptide and moronecidin against the gram-negative bacteria[Escherichia coli (ATCC 25922), Pseudomonas aeruginosa(ATCC 10662)and Acinetobacterbaumannii (clinical isolate)], gram-positive bacteria [Staphylococcus aureus (ATCC 25923), Staphylococcus epidermidis(ATCC 1435) and Staphylococcus aureus (MRSA)] and yeast clinical isolate (Candida glabrata, Candida tropicalis, Candida albicans) was assessed according to the broth microdilution technique as described by a nature protocol for MIC evaluation of antimicrobial peptides [21]. Briefly, a series of two-fold dilutions of each peptide(300, 150, 75, , , ,  and \u03bcg/ml) was created with % acetic acid and % BSA (bovine serum albumin) and then 50 \u03bcl of each peptide dilution was added to each well of polystyrene flat bottom 96- well microplate (Sigma-Aldrich, Germany). Microbial suspension was diluted with BHI medium or RPMI medium to provide density of 1\xd7106 cell/ml and 50 \u03bcl of diluted microbial suspension was added to wells containing 50 \u03bcl of peptide solution, providing a final concentration of 5\xd7105 cell/ml and incubated for 18 hours at 37 \xb0C. The sterility control well contained 100 \u03bcl of BHI (or RPMI), while the growth control well contained 100 \u03bcl of microbial suspension (5\xd7105 cell/ml). The MIC values was defined as the lowest peptide concentration that prevented visible growth of the bacteria. Three independent tests were performed for each peptide concentration.\nIn the next step, the pH and salt concentration effect on MIC of AMPs were assayed. To evaluate the effect of cations on the antibacterial activity of AMPs, bacteria were cultured in the BHI medium containing increased concentrations of monovalent or divalent salt including NaCl (62,125,250 and 500 mM), MgCl2 (1,5, 10 and 30 mM), respectively.\nThe antibacterial activity of both peptides were assessed against Enterococcus faecalis, a bacteria resistance to alkaline environments (ATCC:6057), at different pH values (pH range: , , , or ) [22]. The bacteria were cultured in the BHI medium adjusted to varying pH values (pH range: , , , and ). After incubation at 37\xb0C for 18 hours, the MIC values were determined.\nTime-kill analysis\nTime-Kill assay was performed to investigate bactericidal activity of both peptides against antibiotic resistant bacteria including S. aureus (MRSA), and clinical A. baumannii isolate. For this purpose, overnight culture of bacteria were diluted with BHI in the wells of 96-well microplate (Sigma-Aldrich, Germany) to give final density of 5\xd7105 cell/ml in the presence of each peptide at concentrations of 2\xd7, 1\xd7 and 1/2 \xd7 MIC. Colony count was performed after incubation at 37\xb0C for 0, 2, 4, 8, 12 and 24 h by plating of 10-fold dilutions on LB agar. Minimum bactericidal concentration (MBC) was considered as the lowest concentration of antimicrobial that caused at least a % (equal to a \u22653-log10 reduction) decrease in the initial inoculum. The lower limit of detection for time-kill assays was 2 log10 CFU/ml.\nBinding affinity of AMPs to the gram-negative and the gram-positive bacteria\nAntimicrobial peptides bind to the bacterial cell wall through an electrostatic interaction between the positive charge of AMPs with the negative charge of the bacterial cell wall [23]. We evaluated the binding affinity of dicentracin-like and moronecidin to gram-negative and gram-positive bacteria using a cell-based fluorometric ELISA. To determine optimal binding conditions, different concentrations of the bacteria (\xd7107, 25\xd7107, 5\xd7108, 1\xd7109 cell/ml) and 5-FAM-labeled peptide (, , 5, and 10 \u03bcg/ml) were prepared. Bacterial suspension from each bacterial concentration was added to 4 wells of Maxisorp 96-well microplates (each well 100 \u03bcl) and incubated for 3 hours at 37\xb0C without agitation. The planktonic cells were carefully discarded by pipetting and the adherent cells were washed three times with PBS buffer (pH ). Bacteria were fixed with 100 \u03bcl of 4% paraformaldehyde and incubated for  hours at 37\xb0C. The paraformaldehyde was removed and the wells were washed three times with PBS buffer (pH ). The wells were air-dried and fixed cells were confirmed with an inverted microscope. Subsequently the wells were blocked with 200 \u03bcL/well of 5% (w/v) skimmed milk or 2% bovine serum albumin at 37\xb0C for 3 hours and were washed three times with PBS-T buffer (% Tween-20 in PBS); then 4 \xd7 100 \u03bcl of each 5-FAM-labeled peptide concentration (, , 5, and 10 \u03bcg/ml) were added to 4 wells containing bacterial dilution of each concentration (\xd7107, 25\xd7107, 5\xd7108, 1\xd7109 cell/ml) and incubated for 2 hours at 37\xb0C (plate was covered during incubation). After three washing steps with PBS-T buffer, the fluorescence intensity was measured using a fluorescence microplate reader (BioTek Synergy 4, USA) at 490/560 nm (Ex/Em). Cell-free wells blocked with 5% (w/v) skimmed milk or 2% BSA and treated with 5-FAM-labeled AMP were used as blank wells. The optimal conditions for evaluating binding affinity of AMPs to bacteria were determined as follow: \xd7106 cell/well,  \u03bcg/well peptide and 2% BSA (for blocking). Under the optimized conditions, the binding affinity of both peptides to bacteria was assessed.\nEvaluation of the pH effect on binding affinity of AMPs to bacteria\nThe binding affinity of the peptides to the cell wall of E. faecalis was evaluated in PBS adjusted to different pH values (pH range: , , , or ) by a cell-based fluorometric ELISA test. Like the previous step, bacteria were fixed on the well surface of microplate, blocked and washed. The 5-FAM-labeled AMPs were diluted in PBS buffers adjusted to varying pH values (pH range: , , , or ) to give a final concentration of \u03bcg/ml; then 100\u03bcl of diluted peptide was added to cell-fixed well (peptide,  \u03bcg/well) and incubated for 2 hours at 37 \xb0C. The wells were washed three times with PBS-T buffer. The fluorescence intensity were measured using a fluorescence microplate reader (BioTek Synergy 4, USA) at 490/560 nm (Ex/Em). The wells without fixed cell that were only blocked with 2% BSA were incubated with peptide and were used as blank wells.\nEvaluation of the salt effect on binding affinity of AMP to bacteria\nConsidering potential impact of salt on antimicrobial activity of AMPs due to their interference with the electrostatic interaction between AMPs and the bacterial cell wall [24, 25], investigation of the salt effect on the binding affinity to bacteria appears to be of importance for antimicrobial characterization of a given AMP. As described for analysis of pH effect, bacteria were fixed on the well surface of microplate, blocked and washed. The peptide solution was diluted with two-fold serial dilutions of monovalent (62, 125, 250, and 500 mMNaCl) or divalent salt (1, 5, 10, and 30 mM MgCl2) to provide a final concentration of \u03bcg/ml of peptide. 100-\u03bcl of diluted peptides (\u03bcg/ml) was added to cell-fixed well, and then microplate was incubatedat 37\xb0C for 2 hours. After three washing steps with PBS-T, the fluorescence intensity was measured using a fluorescence microplate reader (BioTek Synergy 4, USA) at 490/560 nm (Ex/Em). The wells without fixed cell that were only blocked with 2% BSA were incubated with peptide and were used as blank wells.\nAssessment of antiadhesive and antibiofilm activities of AMPs\nSurface attachment is the essential first step in effective colonization or biofilm formation of bacteria [26]. Existence of some certain factors such as teichoic acids and lipopolysaccharide appear to be crucial in this function [27]. Given the importance of surface attachment and biofilm formation, antiadhesive and antibiofilm activities of the peptides against  were evaluated, as described elsewhere [24, 25]. Protocols for evaluating antiadhesive and antibiofilm potency are similar; however the antibiofilm assay needs to incubate bacteria in the presence of AMPs for a longer time (24 hours), compared with the antiadhesive assay (1hour). Overnight cultures of bacteria were diluted with BHI to provide OD600 =  and then 1:100 suspended bacteria were added to wells containing BHI and the peptides. Overnight S. aureus suspensions were incubated in the presence of the peptides at subinhibitory concentrations of 1/2xMIC to 1/32xMIC for 1hour (antiadhesive assay) or 24 hours (antibiofilm assay) at 37\xb0C without shaking to allow bacterial binding. After incubation, the planktonic cells were carefully aspirated from wells, and then wells were washed three times with PBS (pH value = ). Fixing the attached cells by 200 \u03bcl of 4% paraformaldehyde and incubating microplate for 30 minutes at 37\xb0C were followed by the subsequent steps including removing paraformaldehyde, air-drying microplate, staining the fixed cells for 2 minutes (with 200 \u03bcl of % of crystal violet), removing the extra dye, washing wells with 200\u03bcl PBS three times, solubilizing crystal violet by 95% ethanol and shaking microplate for 10 minutes. A 100-\u03bcl of solubilized crystal violet solution was transferred to wells of a new microplate and its absorbance was measured at 595 nm using a microplate reader. The well without peptide was used as binding control. The alkaline pH effect on antiadhesive and antibiofilm activities of AMPs against E. faecalis were assayed. For this purpose, bacteria were cultured in the BHI medium adjusted to varying pH values (pH range: , , , and ) in the presence of the peptides at subinhibitory concentration of 1/32\xd7MIC. Then, antiadhesive and antibiofilm assay was performed as described above.\nHemolytic activity assay\nThe hemolytic activity of dicentracin-like peptide and moronecidinpeptide was assayed with human red blood cells (hRBCs) as described elsewhere [28]. After washing human RBCs with PBS, PBS was added to the pelleted RBCs to generate a RBCs suspension with a concentration of 4% v/v. Hemolytic activities of peptides were measured in concentrations of 75, , , , ,  and \u03bcg/ml. For this purpose, mixtures containing RBCs suspension (100\u03bcl) and peptide dilutions (100\u03bcl) were incubated at 37 \xb0C for 1 hour; then, RBCs were collected by centrifugation at 1000 g for 10 minutes. The supernatants of each dilution was divided into wells (100 \u03bcl/well) in a 96-well plate and the absorbance was read at 405 nm with the microplate reader (BioTek Synergy 4, USA). The triton X-100 (%) and the RBCs suspension were used as positive and negative hemolysis control, respectively. The percentage of hemolytic activity of AMPs was measured according to the following equation [29]:\nIn addition, the peptide concentration, with 50% hemolytic activity against human red blood cells (HC50), was estimated for both AMPs.\nStatistical analysis\nData analysis was performed using the Prism software (Version 6; GraphPad).\nANOVA test was used to analyse data and P values < were statistically considered significant.\nResults\nDatabase searching\nWhen the signal peptide of moronecidin (AMP from Moronesaxatilis) was used as a query in BLASTP against the Asian sea bass, only a putative novel AMP precursor with the name of dicentracin-like peptide () was found. The amino acid sequence of this AMP was used in BLASTP and it was revealed that its sequence is not very similar to other identified AMPs. Piscidin-4 and -5 precursors from M. chrysops and saxatilis hybrid (GenBank  and ), however, showed relative similarity with dicentracin-like peptide ().\nCloning, sequencing, and sequence analysis of dicentracin-like\nFollowing cDNA synthesis, the dicentracin-like coding sequence was inserted into pET28b vector and the recombinant plasmid pET28a was sequenced (S1 Fig). To define the motifs of the deduced dicentracin-like, its amino acid sequence was submitted in the motif finder, by which the two motifs including pleurocidin family (PF08107) and the testis-expressed sequence (PF15326) were determined (S1 Fig). A 22-amino-acid mature AMP was defined which had general properties of AMPs including cationic (total charge +6) and hydrophobic properties (%) [30]. Piscidin-4 (Epinepheluscoioides) [31] and cathelicidin (from Sarcophilusharrisii) were found to have the most similarity to dicentracin-like peptide, with a 52% similarity [32]. The alignment of dicentracin-like peptide with other known piscine AMPs revealed a high identity in the signal peptide sequence, but a high variability in the mature region of both AMPs (S2 Fig). Schiffer\u2013Edmundson helical wheel modeling and secondary structure prediction demonstrated that the hydrophobic and the hydrophilic residues are located on opposite sides in the alpha-helix structures of dicentracin-like and moronecidin, and these AMPs have amphipathic alpha-helix conformations (Fig 1).\nAn assessment of physicochemical properties of dicentracin-like and moronecidin indicated that dicentracin-like has more positive charge and higher water solubility, compared with moronecidin. Moronecidin possesses more hydrophobic properties than dicentracin-like, while both peptides have similar amphipathic properties (Table 1).\nTissue-specific expression of dicentracin-like peptide\nThe expression of dicentracin-like peptide was analyzed in fish tissues including the head kidney, the skin, the intestine, and the gill by semi-quantitative RT-PCR. The highest expression was observed in the head kidney. The relative expression level of dicentracin-like (relative to that of EF1\u03b1 gene as an internal control) in the head kidney, the skin, the gill, and the intestine were -, -, 1-, -, and -fold (S3 Fig).\nRetention time of peptides\nThe evaluation of RP HPLC retention time revealed that moronecidin was eluted with two peaks including a tiny peak in  minute and the main peak in  minute, while dicentracin-like was eluted only with one peak in  minute (Table 1).\nAntimicrobial activity\nThe antimicrobial activity of dicentracin-like peptide and moronecidin was evaluated against the gram-negative bacteria [E. coli (ATCC 25922),  (clinical isolate), P. aeruginosa (ATCC10662)], the gram-positive bacteria [S. aureus (ATCC 25923), S. epidermidis(ATCC 1435)] and yeast clinical isolate (, , C. albicans). The results showed that both AMPs have high activity against gram-positive bacteria (, ) and , while they showed low activity against other gram-negative bacteria including P. aeruginosa and  clinical isolate. S. epidermidis showed more sensitivity, while P. aeruginosa showed the lowest sensitivity to both peptides. The dicentracin-like peptide showed higher activity than moronecidin against all bacteria (except against ), whereas moronecidin was more potent than dicentracin-like peptide against the standard S. aureus strain and S. aureus (MRSA) (Table 2). Both peptides exhibited effective activity against C. albicans and , but not against . The results of time-kill assay against clinical  isolate demonstrated that bactericidal activity of dicentracin-like and moronecidin was relatively similar at suprainhibitory and inhibitory concentration of 2X and 1XMIC, however the dicentracin-like peptide displayed more potent activity than moronecidin at subinhibitory concentration of 1/2XMIC. Bactericidal activity of dicentracin-like and moronecidin was observed at concentration of 2X and 1XMIC after 2 and 4 hours of incubation, respectively (Fig 2).\nSalt can reduce antimicrobial activity of AMPs by disruption of the electrostatic interaction between AMPs and bacterial cell wall. AMPs should be able to tolerate physiological salt concentrations to become effective in the clinical condition [33].\nTherefore, we evaluated the effect of various salt concentrations on the MIC of both peptides against . Compared to monovalent salt (NaCl), divalent salt (MgCl2) possessed more antagonistic effect on antibacterial activity of peptides. Increasing concentration of the salt reduced the antimicrobial activities of both peptides, while any reduction in the activity of both peptides was not observed in physiological salt concentrations. In the presence of 5 mM and 10 mM MgCl2, the MIC value of the dicentracin-like and moronecidin peptides increased by 4- and 8-fold, respectively (Fig 3 and Table 3), whereas the MIC value of dicentracin-like and moronecidin peptides increased by 2-fold in the presence of 500 mM NaCl. Furthermore, the MIC of both peptides increased by 16-fold in the presence of 30 mM MgCl2 (Table 3).\nEvaluation of the effect of alkaline pH on antibacterial activity demonstrated that the increasing of pH value reduced antibacterial activity of both peptides, especially for moronecidin (Fig 4). The increasing of pH to  was caused a rapid decrease (4-fold) in antibacterial activity of moronecidin, whereas no reduction in antibacterial activity of dicentracin-like was observed. Overall, dicentracine-like was more potent than moronecidin against E. faecalis (ATCC:6057) at alkaline pH value.\nBinding affinity of AMPs to bacteria at different pH values\nThe pH value of healthy skin, and chronic and acute wounds are different. The natural skin surface is slightly acidic(pH value = \u2013), but infected wounds are alkaline (pH value = 6\u201310) [26, 27]. Here, we evaluated the effect of different pH values on the electrostatic interaction of the AMPs (moronecidin and dicentracin-like) against E. faecalis [25]. The obtained results demonstrated that the increasing of pH value to  leads to a rapid decrease in affinity binding of moronecidin to bacteria. In addition, dicentracin-like has significantly higher binding affinity to bacteria, especially in pH value of , compared to moronecidin (Fig 4).\nEffect of salt concentration on AMPs binding to bacteria\nElectrostatic interactions between AMPs and bacteria cell wall which is the prerequisite for antibacterial activity can be hindered by salt [24, 34]. We evaluated the binding of AMPs to bacteria cell at various salt concentrations. Results showed that the increasing concentration of monovalent cation (NaCl) decrease the binding affinity of moronecidin and dicentracin-like peptides to bacteria. Monovalent cation (NaCl) equally reduced the binding affinity of moronecidin and dicentracin-like peptide to bacteria, while  and -fold reduction were observed in affinity binding of dicentracin-like and moronecidin peptides to bacteria, respectively, in the presence of 10 mM MgCl2concentration(Fig 3). Like antibacterial activity, dicentracin-like exhibited greater affinity binding compared with moronecidin, in the presence of 10 mM MgCl2. No significant difference was observed in affinity binding of peptides in the presence of 30 mM MgCl2.\nInhibitory effect of AMPs on surface attachment and biofilm formation\nThe evaluation of the inhibition of bacterial attachment to inside well-surface by peptides revealed that wells containing higher concentration of peptides have less attached bacteria, compared with wells containing lower concentration of peptides. Antiadhesive and antibiofilm effects of both peptides were exerted in a dose-dependent manner, although greater effects were exhibited by disentracin-like, relative to moronecidin (Figs 6 and 7).\nFurthermore, investigation of the pH effect demonstrated that moronecidin significantly decreases the bacterial adhesion at pH  and biofilm formation at pH values from  to , relative to corresponding control, while dicentracin-like is able to significantly decrease the bacterial adhesion and biofilm formation at pH values from  to  (Fig 7). In addition dicentracin-like has higher antiadhesion and antibiofilm activity than mornecidin at pH values from  to , while no statically statistically significant difference was observed between activity of both peptides at pH value of .\nHemolytic assay\nCytotoxicity of some AMPs is the main barrier to the clinical use of them; the hemolytic activity of the dicentracin-like peptide against human red blood cells (hRBCs) was examined in comparison to moronecidin. Moronecidin showed higherhemolyticactivity than dicentracin-like peptide, the HC50 for moronecidin and dicentracin-like were 57 \u03bcg/ml and  \u03bcg/ml, respectively (Fig 8). Dicentracin-like did not show100% hemolytic activity even in the peptide concentration of 75 \u03bcg/ml.\nDiscussion\nOne of the most common health problems is the increasing resistance to conventional antibiotics among clinical microorganisms. To overcome this problem, researchers try to discover novel antimicrobial compounds lacking problems related to antibiotic resistance [30, 35, 36]. Antimicrobial peptides (AMPs) as a novel class of antibiotic agent have attracted the attention of researchers due to special antibacterial mechanism by which they directly disrupt the membrane structure. Given importance of cell membrane, the appearance of AMPs-resistance microorganism is very low [31, 32]. In the present study, the conserved signal peptide of moronecidin was used as a query in EST database against Asian sea bass (Latescalcarifer), resulting in the identification of a novel AMP, dicentracin-like. The amino acid sequence of mature dicentracin-like has very low similarity to other AMPs. Piscidin-4 (from Epinepheluscoioides) [37] and cathelicidin (from Sarcophilusharrisii) [38], with very low score similarity (52%), possessed the most similarity to dicentracin-like, so it was difficult to assign this peptide to any of the known classes of AMPs. In addition, the analysis of dicentracin-like gene expression in various tissues confirmed its expression in tissues involved in the immune system. Following the cloning and the sequencing of dicentracin-like, the mature dicentracin-like peptide and moronecidin were synthesized, followed by comparison of their antibacterial activity. Despite having broad-spectrum antimicrobial activity, both peptides exhibited more effective activity against gram-positive bacteria, relative to gram-negative ones. However, both peptides had a high-binding affinity to gram-negative bacteria, relative to gram-positive ones. A number of studies have revealed higher MICs of AMPs for gram-negative bacteria compared to gram-positive ones [39\u201341]. The outer membrane may be the reason behind the low antimicrobial activity of moronecidin and dicentracin-like against gram-negative bacteria, despite their high-binding affinity. LPS of the outer membrane of gram-negative bacteria has been particularly observed to have an active role in the function of AMPs [42\u201345]. Owing to the LPS barrier, there are fewer antibiotic candidates against multidrug resistant gram-negative strains [46, 47]. One of the mechanisms used by the LPS to decrease the efficacy of AMPs is induction of self-association of peptides [48\u201351] that may prevent the AMPs from passing through the cell wall to reach inner cell membrane [51\u201353]. On the other hand, since the surface negative charge of gram-negative bacteria is stronger than that of gram-positive ones [54], cationic AMPs may bind to gram-negative surfaces more easily. Compared to moronecidin, dicentracin-like showed higher activity against gram-negative bacteria, whereas moronecidin exhibited higher antibacterial activity than dicentracin-like peptide against S. aureus. The most likely reason for the difference in antibacterial activity against gram-negative bacteria between dicentracin-like and moronecidin may be related to their hydrophobicity. An analysis of data contained in the antimicrobial peptide database by Malanovic and Lohner revealed that the fraction of hydrophobic residues in the vast majority of AMPs is mostly between 30% and 50%, although it has been observed that AMPs being specific for gram-positive bacteria have a somewhat higher content of hydrophobic residues. However, it should be considered that the number of AMPs acting only against gram-positive bacteria is more than that against gram-negative bacteria. The above-mentioned data suggest that high hydrophobicity may prevent AMP from passing through the outer membrane and the cell wall to reach inner cell membrane [26]. Accordingly, since our results showed that the hydrophobicity of moronecidin is greater than that of dicentracin-like, the high hydrophobicity of moronecidin could explain its low activity against gram-negative bacteria, relative to dicentracin-like. Furthermore, in consistence with this finding, a previous study demonstrated, previous study demonstrated that the reduction of hydrophobic properties of non-polar face of moronecidin by the amino acid substitution on the non-polar face decreases its antibacterial activity against S. aureus [55]. In contrast, compared to moronecidin, dicentracin-like peptide exhibited more antiadhesive and anti-biofilm activity against S. aureus. Take together results indicated that a direct relationship between the binding affinity of peptides to bacteria and the inhibition of the surface attachment and biofilm formation, also the high antiadhesive and antibiofilm activities of dicentracin-like relative to moronecidin, may be related to its prominent positive charge and consequently its high-binding affinity to bacteria. Compared to moronecidin, dicentracin-like peptide showed more salt-resistant properties at salt concentration up to10mM, possibly because of its higher positive charge to compete with the positively charged ions (Mg2+) for binding to the bacterial cell wall. However, both peptides showed approximately equal reduction in antibacterial activity in the presence of 30 mM MgCl2, representing salt concentration at where the lowest difference was observed between bacteria- binding affinity score of both peptides. The positive charge of AMPs may be reduced in environments with alkaline pH such as the infected wounds [40]. The assessment of the binding affinity to bacteria and the antimicrobial and antibiofilm activity of AMPs under various pH values demonstrated that dicentracin-like peptide possesses higher affinity for bacteria, antimicrobial and antibiofilm potency than moronecidin at alkaline pH. This result is consistent with previous finding that the activity of histidine-rich antimicrobial peptides is dependent on an acidic environment. Furthermore, it demonstrated that replacement of histidine residue by arginine or lysine residue can increase their antibacterial activity at natural pH that this is because of very lower pka of side chain of histidine residue (imidazole groups, pKa = ) at neutral pH value [56]. Hence, the high- binding affinity to bacteria, antimicrobial and antibiofilm potency of the dicentracin-like peptide under alkaline pH and high salt concentration of environment can be due to more arginine and less histidine residues compared to moronecidin. These properties allow dicentracin-like peptide to retain its bacteria-binding, antimicrobial and antibiofilm activity under alkaline pH of chronic and acute skin infection [26, 27]. The time-kill kinetic assay was performed to assess the bactericidal potency of dicentracin-like against  (clinical isolate), which revealed that both peptides have rapid bactericidal activities against A. baumannii (clinical isolate).\nAmit Kumar et al. studied the effects of amino acid substitutions on the antibacterial and cytotoxic activity of moronecidin. In that study, it was demonstrated that replacement of isoleucine 9 and 16 (I9 and 16) at the center of the non-polar face by alanine (I16A-moronecidin), remarkably reduced hemolytic activity against hRBC and retained the antibacterial activity, leading to a highest therapeutic index compared to other moronecidin analogs. In addition, replacement of valine12 at the border of the non-polar face (Val 12) by a more hydrophobic residue, isoleucine (V12I), considerably increased the antimicrobial activity and toxicity of moronecidin [57]. Surprisingly, like moronecidin analgos (I9A,16A and V12I), residues 9,16 and 12 indicentracin-like peptides arealanine (A9, 16) and isoleucine (I12), respectively (Fig 9).\nResidues are numbered starting from the N-terminus. B: The alignment of dicentracin-like with moronecidin and its derivatives [57\u201359]. Red residues represent identical residues between dicentracin-like (Dic) and moronecidin (Mor) derivatives. Hydrophobic face residues in dicentracin-like and moronecidin are shown by rectangular.\nThe helical wheel projections revealed the integrity of the non-polar face on moronecidin, while the non-polar face of dicentracin-like peptide is broken by two low hydrophobic residues, alanine (Ala 9,16) that decrease hydrophobic property on non-polar face of moronecidin. It was demonstrated that substitution of residues at the center of the non-polar face by a hydrophobic residue (alanine) or a cationic residue (lysine, arginine) reduced hemolytic effect while retained antibacterial activity [57, 60\u201362]. Ina study conducted by Kumar et al, it was revealed that the increasing positive charge of moronecidin by the substitution of threonine(T) at position 15 and 21 by a cationic residue (moronecidin T15K, T21K) significantly reduced cytotoxicity while increased antibacterial activity [59]. Likemoronecidn T15K, T21K, the residue at position 21 of the dicentracin-like peptide is also a cationic residue (Fig 9).\nThese results in consistence with other studies [61, 63] confirm that the hemolytic activity of AMPs has a directed relation with retention time and the hydrophobic properties of non-polar face. In a study conducted by Son et al, it was demonstrated that all derivatives generated by Ala-scanning on the hydrophobic face, considerably exhibited decreased hemolytic activities [64].\nA number of antimicrobial characteristics of dicentracin-like peptide were investigated in the present study, while some other properties still remain to be evaluated, representing the limitations of the study. We are aware of the importance of them for a complete antimicrobial characterization of the AMP. Considering crucial role of biofilm mass in developing antibiotic resistance through acting as a barrier to prevent access of antibiotics to biofilm forming pathogens, there appears to be a need for designing therapeutic agents possessing ability to reduce or remove pre-existing biofilm. Accordingly, the lack of data on the efficacy of AMPs in removing pre-existing biofilm can be considered as a limitation of the current study.\nIn the present study in silico comparative sequence analysis and antimicrobial characterization led to describe a new, previously unrecognized antimicrobial function for named dicentracin-like peptide in comparison to moronecidin. This research really provides a descriptive report on functional characterization of the peptide. However potential mechanisms of antimicrobial action such as membrane leakiness, efflux of cell metabolites and inhibition of DNA synthesis need to be determined which can inform the design and conduct of future studies.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:14:59Z', 'description': u'by Stephan Ellmann, Victoria Langer, Nathalie Britzen-Laurent, Kai Hildner, Carina Huber, Philipp Tripal, Lisa Seyler, Maximilian Waldner, Michael Uder, Michael St\xfcrzl, Tobias B\xe4uerle\n\nMagnetic resonance imaging (MRI) allows non-invasive evaluation of inflammatory bowel disease (IBD) by assessing pathologically altered gut. Besides morphological changes, relaxation times and diffusion capacity of involved bowel segments can be obtained by MRI. The aim of this study was to assess the use of multiparametric MRI in the diagnosis of experimentally induced colitis in mice, and evaluate the diagnostic benefit of parameter combinations using machine learning. This study relied on colitis induction by Dextran Sodium Sulfate (DSS) and investigated the colon of mice in vivo as well as ex vivo. Receiver Operating Characteristics were used to calculate sensitivity, specificity, positive- and negative-predictive values (PPV and NPV) of these single values in detecting DSS-treatment as a reference condition. A Model Averaged Neural Network (avNNet) was trained on the multiparametric combination of the measured values, and its predictive capacity was compared to those of the single parameters using exact binomial tests. Within the in vivo subgroup (n = 19), the avNNet featured a sensitivity of % (95% CI: \u2013%), specificity of % (95% CI: \u2013%), PPV of % (\u2013%) and NPV of % (95% CI: \u2013%), significantly outperforming all single parameters in at least 2 accuracy measures (p < ) and performing significantly worse compared to none of the single values. Within the ex vivo subgroup (n = 30), the avNNet featured a sensitivity of % (95% CI: \u2013%), specificity of % (95% CI: \u2013%), PPV of % (\u2013%) and NPV of % (95% CI: \u2013%), significantly outperforming all single parameters in at least 2 accuracy measures (p < ), exceeded by none of the single parameters. In experimental mouse colitis, multiparametric MRI and the combination of several single measured values to an avNNet can significantly increase diagnostic accuracy compared to the single parameters alone. This pilot study will provide new avenues for the development of an MR-derived colitis score for optimized diagnosis and surveillance of inflammatory bowel disease.', 'title': u'Application of machine learning algorithms for multiparametric MRI-based evaluation of murine colitis', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206576', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Application of machine learning algorithms for multiparametric MRI-based evaluation of murine colitis\n\nFigures\nAbstract\nMagnetic resonance imaging (MRI) allows non-invasive evaluation of inflammatory bowel disease (IBD) by assessing pathologically altered gut. Besides morphological changes, relaxation times and diffusion capacity of involved bowel segments can be obtained by MRI. The aim of this study was to assess the use of multiparametric MRI in the diagnosis of experimentally induced colitis in mice, and evaluate the diagnostic benefit of parameter combinations using machine learning. This study relied on colitis induction by Dextran Sodium Sulfate (DSS) and investigated the colon of mice in vivo as well as ex vivo. Receiver Operating Characteristics were used to calculate sensitivity, specificity, positive- and negative-predictive values (PPV and NPV) of these single values in detecting DSS-treatment as a reference condition. A Model Averaged Neural Network (avNNet) was trained on the multiparametric combination of the measured values, and its predictive capacity was compared to those of the single parameters using exact binomial tests. Within the in vivo subgroup (n = 19), the avNNet featured a sensitivity of % (95% CI: \u2013%), specificity of % (95% CI: \u2013%), PPV of % (\u2013%) and NPV of % (95% CI: \u2013%), significantly outperforming all single parameters in at least 2 accuracy measures (p < ) and performing significantly worse compared to none of the single values. Within the ex vivo subgroup (n = 30), the avNNet featured a sensitivity of % (95% CI: \u2013%), specificity of % (95% CI: \u2013%), PPV of % (\u2013%) and NPV of % (95% CI: \u2013%), significantly outperforming all single parameters in at least 2 accuracy measures (p < ), exceeded by none of the single parameters. In experimental mouse colitis, multiparametric MRI and the combination of several single measured values to an avNNet can significantly increase diagnostic accuracy compared to the single parameters alone. This pilot study will provide new avenues for the development of an MR-derived colitis score for optimized diagnosis and surveillance of inflammatory bowel disease.\nData Availability: The Excel file containing the measurements as well as the Source Code for the Machine learning scripts written in R are available from the Open Science Framework database: https:///hg4xk///HG4XK.\nFunding: This work was in part funded by the Collaborative Research Center 1181 of the Deutsche Forschungsgemeinschaft DFG (CRC 1181; /), projects Z02 (T. B\xe4uerle) and B05 (K. Hildner), and DFG grants KFO257, FOR2438 (M. St\xfcrzl), and BR5196/2-1 (N. Britzen-Laurent), by the W. Lutz Stiftung (M. St\xfcrzl), and by the Interdisciplinary Center for Clinical Research (IZKF) of the Clinical Center Erlangen. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nInflammatory bowel diseases (IBD)\u2013mainly consisting of Crohn\u2019s disease (CD) and ulcerative colitis (UC)\u2013are persistent or recurrent intestinal inflammations affecting the entire gastrointestinal system or the colonic mucosa, respectively [1]. As a common pathomechanism, genetically susceptible hosts feature deregulated mucosal T cell responses to enteric bacteria [2]. The details of these genetic-environmental-immunological interactions are still not resolved. However, there is consent that CD is characterized by a rather Th1 immune response and submucosal T-cell-infiltration, whereas UC evokes a Th2-dominated immune response with mucosal infiltration [3,4]. However, typical Th1 cytokines like tumor necrosis factor alpha (TNF-\u03b1) and interferon gamma (IFN-\u03b3) also arise in UC [5,6].\nExperimental animal models are commonly used to investigate the pathogenesis of IBD. Specifically dextran sulphate sodium (DSS)-induced colitis is a commonly used model of murine colitis and many drugs used in IBD patients have been developed with the help of this model [7\u201310]. DSS-induced colitis in mice closely resembles the morphological and symptomatic features of human UC [11], with a predominant affection of the mucosa and the distal left colon, but often extending throughout the entire colon. As yet, the diagnosis of the disease\u2014in humans and animals\u2014is based on clinical characteristics as well as endoscopic and histologic mucosal features. Colonoscopy allows direct visualization of the colonic mucosa, but is invasive and can cause complications [12].\nIn recent years, imaging techniques are increasingly considered as a tool to improve diagnosis and surveillance of IBD patients. Whilst computed tomography (CT) is a widely available and fast method, it lacks sensitivity in terms of detection of early mucosal changes, and is associated with the risks of repeated radiation exposure. Due to the technical progress of the last years, magnetic resonance imaging (MRI) has become the imaging modality of choice in detection, surveillance, therapy monitoring and evaluation of the extent of IBDs in humans [13,14]. However, bowel imaging in animal models remains challenging.\nSeveral studies reported on the perspectives of MRI in murine colitis imaging [15\u201321]. Of note, these studies mainly investigated single variables like wall thickness or relaxation times, but did not investigate the additional benefit of multiple variables, parameter combinations and assets of machine learning algorithms.\nThis study describes in and ex vivo MRI protocols for imaging of DSS-induced colitis in mice, and presents a multiparametric approach for colitis detection based on a machine learning algorithm. By this approach, increased diagnostic accuracy as compared to single parameter analyses was obtained.\nMaterials and methods\nAnimals\nC57BL/6 mice were obtained from Charles River, Germany, and housed at the central animal facility of the University of Erlangen-Nuremberg. The animals were kept in standard laboratory cages in groups of three or four per cage. To avoid potential interfering infections, mice were kept isolated and were fed with pathogen-free food. Clinical symptoms including body weight, rectal bleeding, behavior, appearance and general health condition were monitored daily. All care and experimental procedures were performed in accordance with national and regional legislation on animal protection, and all animal procedures were approved by the State Government of Middle Franconia, Germany (reference numbers 54\u2013-12/12 and \u2013-37/14). For tissue histology and ex vivo imaging, mice were sacrificed by cervical dislocation under isoflurane anesthesia (2%, 2 L/min). In total, 43 mice were used.\nColitis induction\nAcute colitis was induced in sex-matched co-housed littermates with a minimal body weight of 20 g by administration of % DSS (36\u201350 kDa; MP Biomedicals) in the drinking water for a 7-day cycle, followed by 3 days of normal drinking water. Control animals received tap water only. Animals were randomly assigned to DSS- or sham-treatment. DSS-induced colitis was evaluated on day 9 by endoscopy while MRI was performed on day 10.\nIn addition, colon of control as well as DSS-treated animals were prepared from caecum to rectum and used for ex vivo MRI analysis and immunohistochemistry.\nColitis evaluation using endoscopy and clinical examination\nIn vivo endoscopy was used to evaluate the DSS-induced colitis grade. Mice were anaesthetized with isoflurane (2%, 2 L/min) and a high-resolution mini endoscope including a xenon light source and an air pump (Karl-Storz, Germany) was used to visualize the intestinal mucosa at the level of the rectosigmoid junction by blinded investigators (VL and CH). Disease activity was evaluated according to Becker et al. [22] with a disease specific scoring system using translucency of the colon wall, granularity of the mucosal surface, fibrin deposition, vascularization and stool consistency as parameters. Each parameter was given a score from 0 to 3, summing up to a maximum score of 15 indicative of strong colitis.\nHistology\nColon specimen of 21 mice were fixed overnight in 4% paraformaldehyde, embedded in paraffin and cut into 4 \u03bcm sections. Hematoxylin/Eosin staining was performed to visualize tissue morphology and inflammation. Slides were assessed for lymphocytic cell infiltration (0\u20133 points) and tissue damage (0\u20133 points) at the level of the rectosigmoid junction by a blinded investigator (MW). The resulting points were summed up to receive a histology score ranging from 0\u20136.\nEx vivo MRI\nThe colons of 30 sacrificed mice (18 mice with DSS-induced colitis, 12 controls) were prepared and embedded in agarose dissolved in saline solution (2%). Ex vivo imaging was performed on the same system as in vivo imaging with the sequences listed in Table 2.\nImage analysis\nImages were analyzed with Horos [24]. For in vivo as well as ex vivo imaging, region of interest (ROI) measurements were performed in the wall of the distal colon (n = 10 per animal). For this purpose, ROIs were placed within the bowel walls in the T2w sequences by a blinded investigator (SE), carefully avoiding the lumen of the colon or surrounding fat tissue (or agarose in case of ex vivo analyses). All measurements were acquired around the rectosigmoid junction (approx. \xb13 mm) where the colon was orientated perpendicular to slice orientation. The ROIs were copied to the other sequences (T1, T2, T2* and ADC Maps), and slightly adjusted if necessary (. due to bowel movements altering the distinct location of the bowel segment to measure). Measurement of the colon wall thickness was performed in the T2w sequences with the distance tool.\nStatistical analysis and machine learning\nStatistical analyses were performed using RStudio [25]. Normal distribution of data was assessed using Kolmogorov-Smirnov-tests. For the comparison of means between groups t-tests were applied for normally distributed data, and Mann-Whitney U tests to compare the medians of data that significantly differed from normal distribution. Linear correlations were calculated with the Pearson correlation method.\nMachine learning model development and implementation was performed using the caret package for R [26]. DSS-treatment was used as reference condition with the aim to predict the dichotomous outcome (DSS-treated vs. sham-treated) from the set of predictors wall thickness, T1-, T2-, T2*-relaxation times, apparent diffusion coefficient (ADC) and the type of examination (in vivo vs. ex vivo).\nTo assess the model\u2019s ability to predict unknown data, a modified Leave-one-out-cross-validation was applied: All measurements obtained from one animal were eliminated from the dataset and treated as a test-set, the model was trained with the remaining data (train-set) which was then used to predict the outcome of the formerly eliminated data. This was performed consecutively for all animals in a walk-through-fashion, so that in the end the complete dataset underwent prediction of the outcome by models trained with data not part of the test-set. Within this process, the partially correlated predictor parameters were subjected to a principal component analysis (PCA) to convert the set of observations into a set of values of linearly uncorrelated variables (S1 Fig). The resulting principal components were then fed into several machine learning algorithms to assess their diagnostic accuracy in discriminating between DSS-treated and sham-treated animals. Model Averaged Neural Networks (avNNet) were further evaluated due to their high accuracy in this screening procedure.\nNeural networks are combinations of neurons organized in layers with the predictors as the bottom layer, and the output as the top layer. The applied avNNet features one additional intermediate layer containing hidden neurons as nodes, receiving input from the predictors and forming the output. The inputs to each node are combined using a weighted linear combination. The result is then modified by a nonlinear function before being returned as output. The values of the weights have to be restricted to prevent them from becoming too large, and the parameter restricting the weights is referred to as decay. The initial weights are chosen randomly and updated during the training process using the observed data. Consequently, there is a certain amount of randomness in all predictions [26]. To account for this, the network was trained 5 times using different random starting points, and the resulting data were averaged.\nTo assess the predictive abilities of every single parameter alone, Receiver-Operating Characteristic (ROC) analyses were performed for the single predictors, and optimal sensitivity and specificity values were calculated from the ROC curves by the Youden method.\nThe avNNet and the predictive abilities of all single parameters alone were compared to each other by exact binomial tests using the R package DTComPair version  [27].\nIn all statistical tests, p-values < .05 were considered statistically significant.\nFinally, a model was trained on the complete dataset with a decay value of  and 7 hidden neurons. The training process was validated with a 10 times repeated 10-fold cross-validation. The resulting model was implemented into a publically accessible internet application using Shiny [28].\nResults\nMice with DSS-induced colitis and control animals were comparatively investigated using clinical evaluation methods, histology and MRI.\nSubjective MRI analysis\nIn an initial analysis of the image material, distal colonic segments were identified that were adequately filled with carbon gum solution and free from motion artifacts in all sequences (Fig 4). Those segments were used for relaxation time and ADC measurements within the acquired maps and determination of the colon wall thickness.\n(A) in vivo MR images of the distal colon in a T2-TSE sequence, T1-, T2- and T2*-mapping and an ADC map for a DSS-treated and a control animal (upper and lower row, respectively). The colon wall is marked with an arrow. The walls of DSS-treated animals featured increased thickness, higher T1- and T2-relaxation times and higher ADC values (compare Table 3 and Fig 5). (B) ex vivo MR images of the distal colon in a T2-TSE sequence, T1-, T2- and T2*-mapping and an ADC map for a DSS-treated and a control animal (upper and lower row, respectively). The walls of DSS-treated animals featured increased thickness, increased T2-relaxation times and reduced ADC values (compare Table 3 and Fig 5).\nCorrelation plots for the imaging parameters acquired in in vivo (A) and ex vivo measurements (B). Data from DSS-treated animals are displayed in black, while data from control animals are displayed in grey. Analyzed variables included wall thickness, T1-, T2- and T2*-relaxation times and the apparent diffusion coefficient (ADC). In the upper row boxplots following the Tukey definition are given to depict the distribution of the obtained parameters. Also compare Table 3A presenting p-values for the assessment of significant differences of the parameters between DSS-treated animals and controls. Frequency distribution plots along the diagonal and histograms in the left column aid to further visualize the distributions of the analyzed parameters. Dotplots below the diagonal illustrate the correlations of all possible parameter combinations, the corresponding correlation coefficients are given above the diagonal as 3 distinct r values (combined correlation Cor, controls only, DSS-treated only).\nHighest positive correlation in the in vivo measurements was observed between T1- and T2-relaxation times (r = , p < ). This correlation however vanished when only DSS-treated animals were analyzed (r = , p = ). No significant negative correlations were observable among the in vivo measurements (the only negative correlation between T1-relaxation time and ADC in the DSS subgroup was weak and non-significant (r = -, p = )).\nMoreover, differences between in vivo and ex vivo measurements were significant regarding wall thickness, T2- and T2*-relaxation times and ADC (DSS subgroup) and T1- and T2*-relaxation times and ADC (control subgroup, Table 3B).\nComparison of machine learning algorithms\nIn an initial screening procedure, avNNet featured high sensitivity and specificity, highest overall accuracy and the highest Youden-Index (Table 4). The Blackboost algorithm and Boosted Smoothing Splines however featured slightly higher sensitivities than avNNet, but considerably lower specificities and lower overall accuracy, so that the avNNet was further evaluated in the remainder of the study.\nROC curves are depicted for the single predictors wall thickness (black), T1- (blue), T2- (red), T2*- (green) relaxation times and ADC (orange) for in vivo (left) and ex vivo measurements (right). Optimal cutoff values were calculated via the Youden-Index and are listed in Table 5. The diagnostic values for the Model Averaged Neural Network (avNNet) are indicated with a black cross.\nIn the in vivo analysis, T2 time featured the ROC curve closest to the top-left edge (Fig 6), resulting in a sensitivity of %, specificity of %, PPV of %, and NPV of % when using the optimal cutoff of  ms (Table 5). T2 time as a single predictor was however significantly outperformed in terms of sensitivity and NPV by the avNNet with its accuracy measures of % sensitivity (p < ), % specificity (no significance), % PPV (no significance) and % NPV (p < , also compare Table 5). Regarding the in vivo analysis, the avNNet was slightly but not significantly outperformed by the ADC value as a single predictor in terms of sensitivity and NPV (% vs. % and % vs. %, respectively), but featured significantly higher specificity and PPV values (% vs. %, p =  and % vs. %, p = , respectively).\nIn the ex vivo analysis, wall thickness as the best performing single parameter (sensitivity %, specificity %, PPV %, NPV %) was outperformed by the avNNet in terms of sensitivity and NPV (avNNet sensitivity %, p = ; specificity %, no significance; PPV %, no significance; NPV %, p = . Also compare Table 5). The avNNet was not outperformed by any single parameter in the ex vivo analysis.\nA visual impression of the avNNet\u2019s performance in comparison to all single parameters is given in Fig 6, the detailed values and results of the statistical tests are listed in Table 5.\nOverall diagnostic accuracy (percent classified correctly) for the avNNet was % (95% CI: \u2013%). When defining the presence of colitis not by DSS-treatment but rather by disease specific scores \u22651, diagnostic accuracy was comparable (%; 95% CI \u2013%). When using a histology score of \u2265 2 as a criterion for colitis definition, diagnostic accuracy was slightly reduced (%; 95% CI \u2013%).\nFinal model development and preparation of an online tool for colitis assessment in mice\nDiscussion\nThe sensitive and quantitative analysis of structural changes of mouse colon tissues associated with experimentally induced IBD is urgently required for an objective evaluation of disease progression. However, evaluation of IBD in mice remains a challenging task due to the small structures involved in inflamed bowels. Analysis is moreover complicated by bowel movements during in vivo examinations that can only be partly suppressed by butylscopolamine application.\nThis study presents in vivo and ex vivo protocols to predict the presence of DSS-induced murine colitis using a machine learning algorithm that combines multiple parameters. Several studies have been published investigating MR imaging of IBD in mice [15\u201321]. These studies focused on single [16,17,20] or only few parameters [15,18,21] without combining them in a holistic approach. Wall thickness as a useful predictive parameter for the presence of colitis was confirmed in several studies [15\u201318,21]. In addition, T2w signal intensity could be shown to be a parameter related to disease activity [15,21], which is in accordance with our results (see Table 3A). An extensive MR imaging analysis was performed by Mustafi et al. [18], investigating T1- and T2-relaxation times in a mapping approach, wall thickness and dynamic contrast enhancement. Mustafi et al. also described increased T2-relaxation times for colitis, which was confirmed by our results (Table 3A). In contrast to our study, no significant differences between T1w values of inflamed and control colon were reported by these investigators [18].\nIn addition to already published studies, this study provides several aspects not covered by previous works: We provide a combined approach applicable for in vivo as well as ex vivo imaging, with an investigation of several parameters and their predictive capacities alone and in combination. The resulting model was cross validated to ensure generalizability and was made publicly available to be used by other researchers. However, machine learning algorithms largely function as "black box", and it remains unclear which features affect the final result to which specific extent.\nConcerning the single parameters within the presented study, a significant increase of wall thickness in colitis both in and ex vivo, an increase of T1-relaxation time in vivo and changes of diffusion capacity in vivo and ex vivo were observed. T2-relaxation times were increased in DSS-treated animals compared to sham-treated animals in both in vivo and ex vivo analyses. T2*-relaxation times between DSS- and sham-treated animals did not differ significantly, neither in in vivo nor ex vivo imaging. A striking finding was the increase of colon wall diffusion capacity in mice suffering from colitis in in vivo imaging. This has formerly been described for necrotizing enterocolitis in rodents [29] along with increased T2-relaxation times, pointing to a possible necrotizing component in DSS-induced colitis in mice. In contradiction to these in vivo findings, inflamed colon walls showed decreased ADC values in ex vivo imaging, which is in line with clinical studies in human patients describing a significant decrease of ADC values from normal colorectal tissue to healing lesions to active UC [30]. However, quantitative ADC measurements have also been described to feature poor discriminatory ability for segmental disease activity [31].\nOverall, wall thickness, T2*-relaxation time and ADC were determined significantly different between in and ex vivo analyses, T1-relaxation time differed significantly between in and ex vivo in the control group and T2-relaxation time in the DSS group (Table 3B).\nThese results altogether suggest components influencing the accuracy of the measurements, probably at least in part attributable to bowel movements and partial volume effects especially in the in vivo subgroup, or altered relaxation times and diffusion coefficients due to preparation and embedding of the colon, or due to the long-lasting overnight imaging (approx.  h) causing tissue alterations over time. The presented model however is able to distinguish between DSS-treated and control animals with high accuracy (Table 4). In this regard, diagnostic accuracy was even higher for in vivo than for ex vivo imaging. A reason to explain this might be that wall thickness as the most useful predictive parameter in the ex vivo analysis plays a more important role when bowel movements are absent, and is less reliable when measured in structures affected by peristaltic waves, which is not avoidable in the in vivo situation. Most probably, this disadvantage is more than compensated by relaxation times and diffusion capacity that can be determined more accurately in the in vivo situation under conditions of intact blood perfusion. This fact has been described in former comparisons between in vivo and ex vivo data with significant differences between relaxation times of live tissue and fresh tissue samples [32], as well as dependencies on tissue temperature [33]. In particular, the observed significant differences of T2* relaxation times between in and ex vivo measurements are not surprising, as T2* relaxation times depend on a variety of physiologic features including the ratio of deoxyhemoglobin to oxyhemoglobin in the blood, blood volume and blood flow [34,35]\u2013parameters altered by nature when performing ex vivo analyses. Additional tissue changes due to the embedding in agarose and the accompanying sudden temperature changes might also influence relaxation times and lead to more reliable measurements in the in vivo situation.\nWe are aware that our study has several limitations: The group of DSS-treated animals has to be considered heterogeneous with disease specific scores ranging from 1 to  (Fig 2A) and histology scores ranging from 1\u20136 (Fig 2B), possibly at least in part attributable to a known substantial variability in different lots of this substance [10]. In this pilot study, the heterogeneous group of DSS-treated animals was subsumed, and DSS treatment served as a reference condition chosen for mainly two reasons: 1) the model aimed to predict a dichotomous outcome, so that choosing the dichotomous variable of DSS-treatment seemed a reasonable approach, and 2) a definite gold-standard for IBD evaluation in mice remains to be established, as a plethora of different scoring systems exists [36]. Most scoring systems involve semi-quantitative or even subjective criteria, do not correlate perfectly with each other and offer no clear cutoffs for the presence of significant colitis. To add to these concerns, our study determined an only moderate correlation coefficient between clinical scoring and histology of  (Fig 3). Though Walldorf et al. calculated a slightly higher correlation coefficient of  [20], discrepancies similar to those of our study have also been described in humans: In human patients, histology scores were also moderately correlated to endoscopy scores, but especially mild disease activity in endoscopic scoring was distributed over the entire range of histologic grades [37]. The same tendency became apparent in this study\u2019s correlation analysis, with the most imperfect correlations observed in mice with disease specific scores \u2264 4, but histology scores scattered over the entire spectrum (Fig 3). Given the fact that several animals of our study featured high scores in histology but low scores in disease specific scoring, we felt that the most sensible, objective reference condition was DSS-treatment. When however choosing reasonable cutoffs for disease specific scores and histology scores, the model nonetheless performed accurate as well. We however did not aim to question or redefine different evaluation standards established by different groups, but to prove that a combination of multiple image parameters can increase diagnostic accuracy. The choice of a particular reference condition\u2013though of clinical importance\u2013should thus be regarded secondary in this context.\nCorrelations of image parameters with measures of disease activity have already been performed. Melgar et al. for example calculated correlations of colon wall thickness and T2w signal with a clinical scoring system and other parameters of disease activity, and speculated on the advantages of combining different parameters to a model [21]. We are well aware that the results of this pilot study with a model predicting a binary outcome represents just a first step on the long path of comprehensive IBD activity assessment. In future studies needing higher sample numbers, the model could be further improved to not only predict the dichotomous outcome of the presence of colonic inflammation, but to directly calculate MRI-derived colitis scores to quantify disease activity. This would of course require a valid gold standard, but have direct implications on diagnosis and offer results transferable to clinical questions as a non-invasive substitution for colonoscopic examinations. Though a quantitative MRI-based colitis evaluation will probably not be appropriate for high-thoughput screenings due to the need for animal preparation before starting the imaging protocol, it still offers a less biased technique to grade disease activity in contrast to endoscopic scoring, which largely depends on the experimentator\u2019s experience in colonoscopy.\nThe model of this study was validated with a modified Leave-one-out cross-validation, which is appropriate considering the relatively small sample number. With the animal numbers used for this study it was not possible to initially exclude a larger subset of data for testing while simultaneously being able to calculate reliable accuracy measures. It is common practice to then use resampling methods such as cross validation to estimate the generalizability of a model as done in this study [38,39].\nWe did not use dynamic contrast enhancement (DCE) and total contrast enhancement of colonic walls which have been described previously as parameters allowing visualization of inflammatory activity [15,18]. However, as contrast media application can only be performed during in vivo imaging, we did not include contrast-enhanced sequences in order to maintain comparison between the in and ex vivo subgroups. In future studies, the inclusion of DCE may further increase diagnostic accuracy in the in vivo subgroup.\nAs an outlook, the present work serves as a pilot-study with the future aim to develop an MR-derived colitis score. Such a score would allow more elaborate non-invasive, unbiased diagnosis including longitudinal assessments . under novel therapeutic agents. Up to now, it however remains unclear whether a quantitative model will be able to sufficiently judge on disease severity or progression. As a proof-of-concept, the presented online tool allows researchers from external groups to use this once created model for assessment and evaluation of their own measurements, without having to re-establish a model on their own. The presented tool is self-explanatory to use and requires no programming skills. Further extensions of this tool in future studies are planned.\nTo conclude, the advantages of combining multiparametric imaging with machine learning algorithms in a holistic approach is expandable to several other clinical and preclinical questions including inflammation, infection and oncology, and will lead to increased diagnostic accuracy.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:01Z', 'description': u'by Luke I. Larmour, Fiona L. Cousins, Julie A. Teague, James A. Deane, Tom W. Jobling, Caroline E. Gargett\nAim To develop a patient derived xenograft (PDX) model of cervical cancer and cervical dysplasia using the subrenal capsule. Methods Cervical cancer (12 Squamous Cell Carcinoma, 1 Adenocarcinoma, 1 Adenosquamous Carcinoma), 7 cervical dysplasia biopsy and normal cervical tissues were transplanted beneath the renal capsule of immunocompromised NOD/SCID/gamma mice. Resulting tumours were harvested and portions serially transplanted into new recipient mice for up to three in vivo passages. Parent and xenograft tumours were examined by immunohistochemistry for p16INK41, HPV, and CD-45. Single cell suspensions of mixed mouse and human, or human only cell populations were also transplanted. Results The overall engraftment rate for the primary cervical cancer PDX model was  \xb1% (n = 14). Tumours maintained morphological, histoarchitecture and immunohistochemical features of the parent tumour, and demonstrated invasiveness into local tissues. Single cell suspensions did not produce tumour growth in this model. Mean length of time ( +/-  weeks) for the transplanted tissue to generate a tumour in the animal was similar between successive transplantations. Three of four xenografted cervical dysplasia tissues generated microscopic cystic structures resembling dysplastic cervical tissue. Normal cervical tissue (4 of 5 xenografted) also developed microscopic cervical tissue grafts. Conclusion The subrenal capsule can be used for a PDX model of human cervical cancer with a good engraftment rate and the ability to model in vivo characteristics of cervical cancer. For the first time we have demonstrated that cervical dysplasia and normal cervical tissue generated microscopic tissues in a PDX model.', 'title': u'A patient derived xenograft model of cervical cancer and cervical dysplasia', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206539', 'keywords': '', 'ID_RSS': u'606', 'contents': u'A patient derived xenograft model of cervical cancer and cervical dysplasia\n\nFigures\nAbstract\nAim\nTo develop a patient derived xenograft (PDX) model of cervical cancer and cervical dysplasia using the subrenal capsule.\nMethods\nCervical cancer (12 Squamous Cell Carcinoma, 1 Adenocarcinoma, 1 Adenosquamous Carcinoma), 7 cervical dysplasia biopsy and normal cervical tissues were transplanted beneath the renal capsule of immunocompromised NOD/SCID/gamma mice. Resulting tumours were harvested and portions serially transplanted into new recipient mice for up to three in vivo passages. Parent and xenograft tumours were examined by immunohistochemistry for p16INK41, HPV, and CD-45. Single cell suspensions of mixed mouse and human, or human only cell populations were also transplanted.\nResults\nThe overall engraftment rate for the primary cervical cancer PDX model was  \xb1% (n = 14). Tumours maintained morphological, histoarchitecture and immunohistochemical features of the parent tumour, and demonstrated invasiveness into local tissues. Single cell suspensions did not produce tumour growth in this model. Mean length of time ( +/-  weeks) for the transplanted tissue to generate a tumour in the animal was similar between successive transplantations. Three of four xenografted cervical dysplasia tissues generated microscopic cystic structures resembling dysplastic cervical tissue. Normal cervical tissue (4 of 5 xenografted) also developed microscopic cervical tissue grafts.\nConclusion\nThe subrenal capsule can be used for a PDX model of human cervical cancer with a good engraftment rate and the ability to model in vivo characteristics of cervical cancer. For the first time we have demonstrated that cervical dysplasia and normal cervical tissue generated microscopic tissues in a PDX model.\nData Availability: All relevant data are within the paper and its supporting information files.\nFunding: This work was supported by National Health and Medical Research Council Senior Research Fellowship (1042298) (.), Royal Australian and New Zealand College of Obstetricians and Gynaecologists Research Foundation Mary Elizabeth Courier Scholarship (.), Monash University David Healy Memorial Scholarship () and the Victorian Government\'s Operational Infrastructure Support Program. Melbourne Pathology provided support in the form of salary for author ., but did not have any additional role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript. The specific roles of the authors are articulated in the "author contributions\u2019 section. The work performed by  was on her own time. The funding bodies had no role in any aspect of the study.\nCompeting interests: . is employed by Melbourne Pathology. Work on this project was performed on her own time, and the only support provided was salary. This does not alter our adherence to all PLOS ONE policies on data sharing and materials. We confirm that there are no other competing interests to declare.\nIntroduction\nCervical cancer is a leading cause of morbidity and mortality for women worldwide. It is the fourth most common cancer for women globally, with approximately 84% of cases occurring in the developing world [1]. Cervical screening programs have significantly reduced the incidence in developed countries. Early detection and prevention of cervical cancer is based on the existence of a clear premalignant state, cervical dysplasia, and that the Human Papilloma Virus (HPV) is essential to cervical cancer development [2]. Despite this, specific events that convert dysplasia into invasive cancer are unknown. Radiotherapy is the mainstay of treatment for women with advanced disease [3,4], and attempts to find new treatments have been unsuccessful [5]. There is a need for models to further study cervical dysplasia and cancer, and test new therapies.\nDue to the established importance of HPV in the development of nearly all cervical cancer in humans, transgenic mouse models have been developed to study oncogenic contributions of various HPV genes in vivo. These have elegantly shown that of the two HPV oncoproteins, E7 is more oncogenic than E6 for cervical malignancy. However, these models have limitations. For example, in these transgenic models the induced cervical cancers are estrogen dependant, whereas the contribution of estrogen to human cervical cancer does not appear essential. Further, it does not model human metastatic disease [6]. In addition, there are differences between the cellular mechanisms within cells that differ between mice and humans, for example telomerase activity in adult somatic cells[7]. The differences between human and mouse metabolism affect both tumour behaviour, and drug actions[8]. Hence, models involving human tissues by xenograft are more applicable to human disease.\nThe difference between murine and human cancers has been observed in other tumour types [9] and hence xenograft models using tissue taken from human cancers have been developed. Immortalised cell lines frequently used in xenograft models have higher engraftment rates compared to primary cell lines but do not represent the full diversity of cell types within a tumour [7]. Unfortunately, the cell culture process irreversibly alters primary tumour cells from their natural phenotype [10,11]. Patient derived xenograft (PDX) models better represent the range of human tumour phenotypes, maintain gene expression patterns of the parent tumour [12], and offer the potential for the future development of mouse "avatars" for human disease and personalised therapies [13]. For example, correlation between tumourigenicity of ovarian cancer xenografts and clinical progression shows their relevance to patient care [14]. PDX models also allow the observation of progressive genetic alterations in cancer samples over time [15]. PDX models have been established for cancers of the colon, stomach, breast, and ovary [16]. Interest in PDX models is increasing, with efforts to standardize model development underway [17]. The Mouse Tumour Biology database at the time of writing does not contain any entries for PDX models of carcinoma of the cervix uteri [17]. However, cervical cancer PDX models have been reported using the subcutaneous and orthotopic (cervical) models. Engraftment rates were 70% at the subcutaneous site, and 48\u201375% at the orthotopic [18\u201321]. Higher engraftment rates (up to 95%) have been reported for other tumour types in the sub-renal capsule compared with subcutaneous locations [22,23]. Successful engraftment is essential for a PDX model to become a reliable clinical tool. There are no models for dysplastic or normal cervical tissue. Here we describe a new PDX model for grafting both cervical dysplasia and cervical cancer using the sub-renal capsule location. Additional aims were to determine whether single cell suspensions from cervical cancer produced tumour growth.\nMethods\nEthics and tissue collection\nEthical approval for the collection of tissue and data from human participants was approved by the Monash Health Human Research and Ethics Committee (13113B). All patients (n = 26) gave written informed consent. Inclusion criteria were women over the age of 18 with a previous diagnosis of cervical cancer by histopathological examination of cytology or biopsy tissue. Fourteen women were recruited. Women underwent examination under anaesthesia for clinical FIGO staging as part of routine clinical care. Tissues were collected during the examination. Seven women, older than 18 years with a confirmed histological diagnosis of Cervical Intraepithelial Neoplasia 3 (CIN3) also participated. Tissue was taken prior to laser ablation of dysplasia, as planned by the treating unit. Tissue samples were also taken from the uteri of five women undergoing hysterectomy for benign indications, as a control cohort. The following clinical data were collected from participants: cervical pathological diagnosis, FIGO stage, age, gravidity, parity, smoking status, number of HPV vaccine doses received, oral contraceptive or hormone use, and medical history. All women were treatment na\xefve. Blood samples were collected in EDTA tubes and the buffy coat was extracted within twelve hours by centrifugation at 314g for 10 minutes in  TRIS/EDTA buffer. The cell pellet was resuspended in fresh TRIS/EDTA buffer re-centrifuged, supernatant discarded, and stored at -80\xb0C.\nBiopsy tissue was divided into four portions; one immediately frozen in OCT for histology, one fixed in 10% formalin for paraffin sections, one placed in RNAlater (Life Technologies, USA) for 24 hours at 4\xb0C, excess RNAlater decanted and then stored at -80\xb0C and one placed in Dulbecco\u2019s Modified Eagle Medium: Nutrient Mix F-12 (DMEM/F12, Gibco, USA) culture medium containing 10% fetal bovine serum (FBS),  mg/ml Primocin (Invitrogen, USA) and 1% glutamine on ice until xenotransplantation into a recipient mouse within five hours of collection, although it was up to eight hours for the three of the fourteen cancer samples, and three of seven dysplasia samples.\nAnimals\nAll animal experimentation was approved by the Monash Medical Centre Animal Ethics Committee A (MMCA2013/16), in accordance with guidelines of the National Health and Medical Research Council of Australia.\nPatient derived xenograft procedure\nMice were anaesthetised with intraperitoneal ketamine 100 mg/kg body weight and xylazine 10 mg/kg body weight (both Troy Laboratories, Australia). Mice were placed in the right lateral position and a 2 cm left loin skin incision was made. The peritoneal cavity was entered by an incision made in the abdominal wall overlying the left kidney (Panel A in S1 Fig). The kidney was gently exteriorised, and the renal capsule opened with a dental probe and space opened beneath the kidney capsule with fine forceps. 2\u20134 pieces (1 mm3) of biopsy tissue chips were inserted in up to four mice/patient sample (Panel B in S1 Fig). The kidney was returned to the abdomen and the skin closed with Michel clips (Fine Science Tools, USA).\nMice were housed for 2\u20138 months following transplantation until tumour growth was externally obvious and the mice were then euthanized. For the first four samples transplanted, animals were sacrificed at predetermined time points; 4, 12, 24, and 32 weeks, if prior adequate tumour growth was not apparent. This pilot evaluation of tumour size yielded an estimation of rate of growth and the maximum time from transplant euthanasia was set at six months.\nRetransplantation of PDX tissues\nThe explant tissue for retransplantation was cut up into small pieces and half was serially transplanted as described above, the remainder dissociated into a single cell suspension as described in S1 Text.\nImmunohistochemistry\nParaffin embedded sections of primary biopsies and xenografts were immunostained with mouse anti-p16 INK4a (Abcam ab54210), mouse anti-HPV (Abcam ab2417), rabbit anti-human cytokeratin 17 (Abcam ab53707), all at 1:100 dilution in 2% FBS/PBS and incubated overnight at 4oC. The antibody used to detect HPV was developed against the BPV L1 product, and has been shown to be reactive against L1 for HPV types 1, 6, 11, 16, 18, and 31 [26]. Mouse anti-human nuclear antibody (Merck-Millipore MAB1281) was incubated overnight at 4\xb0C at a dilution of 1:20, and mouse anti-human CD45 (Invitrogen MHCD4520) at a dilution of 1:50. The secondary antibody used for mouse primary antibodies was biotinylated goat anti-mouse (Vector BA9200) at a dilution of 1:500 incubated at room temperature for thirty minutes. The secondary antibody used for rabbit anti-cytokeratin 17 was goat anti-rabbit IgG F(a,b)2-b at a dilution of 1:500 for 30 minutes. This was followed by streptavidin HRP at 1:200 dilution. Chromogen development was with DAB in stable peroxidase substrate buffer (Thermo Scientific) for five minutes. Dako mouse IgG1 isotype negative control was used for mouse antibodies and rabbit IgG for rabbit antibodies. Slides were examined by bright field microscopy using an Olympus BX10 microscope and images captured with cellSense Standard software version  (Olympus, Japan). For immunofluorescence PE-conjugated rat anti-mouse CD45 (eBioscience 12-0451-82), was incubated at a concentration of 1:100 for 60 minutes. Nuclear staining was with Hoechst at 1:2000 dilution in PBS for three minutes. Immunofluorescence slides were imaged using a Nikon C1 confocal microscope. Haematoxylin-Eosin stained slides for all harvested tissues and primary biopsies were analysed by an anatomical pathologist (.) to confirm diagnoses and the presence or absence of invasive tumour or dysplasia in xenografted tissues.\nStatistical analysis\nMicrosoft excel version  was used for maintaining the database. GraphPad Prism Version  was used for statistical analysis. Demographic data was grouped according to whether a cancer, dysplasia, or normal sample. Tumour growth data was grouped by xenotransplantation number of the graft. Groups were tested for normal distribution with D\u2019Agostino and Pearson normality test. Groups were compared by non-parametric testing with the Wilcoxon signed-rank test and Kruskal-Wallis test followed by Dunn\u2019s post-hoc test. Statistical significance was taken as a p-value of <.\nResults\nDonor demographics\nThe demographic features of the 26 women recruited for this study are summarised in Table 1. The women with cervical cancer (n = 14) ranged from 28 to 76 years of age, with a median of 48 years. Both age groups of peak incidence (early 30s (n = 4) and >70 years (n = 3) [27]) were represented. Median parity was 2 births (range 1\u20136). Six (%) were smokers, two (%) had completed the full HPV vaccination protocol (Gardisil, Merck) and one had received a single dose, and two (%) were on the oral contraceptive pill (OCP). All but two of the tumours biopsied were squamous cell carcinomas (SCC), one showing an area of adenocarcinoma-in-situ. The other tumours were a low-grade villous adenocarcinoma and an adenosquamous carcinoma, which also showed Adenocarcinoma-in-situ. Most women (n = 13, %) were FIGO stage 1 at diagnosis. The most advanced case was FIGO stage 3B.\nThe 7 dysplasia samples were from women aged 24\u201367 years of age; median age was 32 years (Table 1). Half were nulliparous, however parity or gravidity was not significantly different to the cancer group. None were smokers or OCP users, and three had completed full HPV vaccination. All had been previously diagnosed with CIN3.\nThe 5 normal samples were from women undergoing hysterectomy for benign conditions unrelated to cervical neoplasia. The median age in this group was 47 years. Mean gravidity and parity did not differ from the other groups. 40% were smokers, and none were taking the OCP.\nDevelopment of the subrenal capsule PDX model for cervical cancer\nThe first sixteen samples were transplanted as part of a pilot phase to determine the optimum time for xenograft growth. S1 Table shows the ellipsoid volume for the xenografts collected from this pilot at pre-determined time points unless adequate tumour growth was achieved. Graft growth was not satisfactory at 4 and 12 weeks, however adequate tumour growth was observed by 24 weeks. The maximum time for graft development was determined to be 24 weeks, unless tumour growth was apparent earlier by palpation.\nOf the 14 biopsies xenografted, 10 generated harvestable primary tumours resulting in a primary tumour engraftment rate of  \xb1% (Table 2). One to four replicate transplantations were performed per sample depending on biopsy size. No difference in mean engraftment rate/sample was observed when grouped by replicate number, however only two of six samples (33%) grafted to one mouse produced tumours (Fig 1A). Only 6 of 94 xenografted mice failed to survive the postoperative period and two more perished in subsequent months from independent causes as necropsy showed no tumour growth.\nEngraftment rate A) in replicate animals for individual patient samples transplanted and B) for each sample according to FIGO stage, C) Tumour volume at harvest at each serial transplantation. D) Length of time between transplantation and cull of animal for each round of serial transplantation for all tumours produced. Bars are medians.\nNo difference in engraftment rate was observed when comparing stage of cancer at biopsy (Fig 1B), although numbers were small. Mean tumour volume did not increase over subsequent serial transplantations (Fig 1C), nor did the length of time of xenografts across serial transplantations (Fig 1D).\nThe histology of the tumours produced in the PDX model was generally consistent over subsequent generations of xenografts, with some notable variations from the expected histological grade (Table 3). Six patient samples showed increasing severity over one to three sequential transplantations from dysplasia or well-differentiated squamous cell carcinoma (WD SCC) to a poorly-differentiated variety. Interestingly, the biopsy of CC12 taken directly from the tumour generated a moderate-poorly-differentiated (M-PD SCC) PDX and CIN3. These examples demonstrate the diverse cellular populations preserved by this model that can generate histologically distinct tumour grades. The absence of immune surveillance in NSG mice may allow more rapid disease progression for tumour lines where grade increased.\nDeveloping a PDX model of cervical cancer using single cell suspensions\nSince the purpose of the PDX model was to maintain human cervical cancer tissues over time and expand the tissue without ex vivo culture, we examined whether single cell suspensions from dissociated primary xenografts could generate secondary tumours. We compared the capacity of primary xenograft cell suspensions (106 cells) with and without removal of mouse fibroblasts to examine the contribution of mouse stroma to the engraftment process. Several primary xenografts yielded >20 million human cells. However, xenografting doses of 106 cells/kidney failed to generate tumours, irrespective of the presence of mouse cells. In contrast, xenografting tissue chips (1mm3) yielded good tumour growth for up to three passages. Ability to re-engraft was limited by the size of the harvested xenograft. The optimal period for reliably generating tumours which provided sufficient tissue for characterisation and re-transplantation was approximately six months per serial transplantation.\nMorphological features by H&E staining were maintained between the parent tumour biopsy and subsequent xenograft explants (Fig 2A). Nests of cells with mitotic nuclei were observed and areas with similar patterns of collagen deposition in serially transplanted xenografts and the primary biopsy (Fig 2A). Similar immunostaining patterns for p16INK4a and HPV between the primary tumour and subsequent xenograft explants were observed (Fig 3). Widespread nuclear staining for p16INK4a was maintained between parent and graft. Nests of cells, or in some case sporadic cells, showed cytoplasmic staining for HPV (Fig 3). Xenograft samples showed negative staining for both human CD45 antibody (Fig 2B), indicating a lack of human or mouse leukocytes, confirming that the xenografts are neither transplanted human, nor virally induced murine lymphoma as have been described in other models [17,28,29]. Local invasion of the murine kidney and into the peritoneal cavity by the xenograft was observed in four of eight patient samples yielding tumour growth. Only one case of peritoneal metastasis was observed (CC5).\nDeveloping a PDX model for cervical dysplasia\nSeven dysplasia samples were transplanted as described above. At necropsy, no obvious macroscopic tumour growth was observed. However, microscopic examination of the kidney demonstrated epithelial-lined cystic structures in 3 of 7 patient samples (Fig 4A). The lining epithelium immunostained with human nuclei antibody, indicating the cells were of human origin (Fig 4A). The epithelium in 2 of 3 cysts were positive for p16INK4a, with patchy HPV staining (Fig 4A). This data suggests that these two cysts represent persistent survival and growth of cervical dysplasia tissue xenografted beneath the renal capsule.\nWe also examined whether normal cervical tissue survived transplantation under the kidney capsule. Four of five samples survived for four months under the kidney capsule, resulting in microscopic growths similar to the cervical dysplasia samples (Fig 4B), however the tissue that persisted appeared to be stroma rather than the epithelium from which cervical squamous carcinoma arises. These xenografts immunostained for anti-human nuclear antibody and suggest growth of normal cervical tissue in an animal model for the first time. Sporadic p16INK4a immunostaining was observed in all samples. HPV staining was not seen in the stromal cervical xenograft tissue (n = 3) (Fig 4B), consistent with its stromal appearance and stromal tissue is not typically infected by HPV. However, in a single sample typical squamous epithelial cells were observed, and these were HVP positive (Fig 4B ii). This sample may be a previously undetected case of dysplasia, however no dysplastic histological features were seen.\nDiscussion\nThe main finding of this study was our demonstration for the first time that fresh cervical cancer, cervical dysplasia, and normal cervical tissues can grow beneath the renal capsule of highly immunocompromised mice. Tumours from cervical cancer xenografts recapitulated parent tumour architecture and immunohistochemical profiles for p16 and HPV for at least 3 passages in vivo. Generated tumours were invasive but metastases were rare in our model. We demonstrated for the first time that cervical dysplasia tissues generate microscopic cystic growth under the murine renal capsule showing features expected of dysplasia for key markers of cervical cancer [30]. Similarly, we demonstrated for the first time that the NSG renal capsule permitted the survival and microscopic growth of normal human cervical tissue in vivo. Human cervical cancer tissue grew slowly, requiring 6 months to generate adequate tumours for serial transplantation and characterisation. The renal capsule site provides a unique approach for the biological study of cervical dysplasia conversion into cervical cancer, albeit a lengthy process. Key tumour characteristics preserved in this model were histological morphology, and cervical cancer markers p16INK4a and HPV. The sub-renal capsule is highly conducive to transplantation of xenograft samples and opens possibilities for studying the natural history of cervical neoplasia or for assessing new treatments. The microscopic size of the dysplasia and normal tissue grafts may hinder the clinical applicability of these aspects of this model.\nThe finding that two of four dysplastic samples resulted in microscopic growth of human tissue with immunohistochemical features consistent with cervical dysplasia is significant. To our knowledge this is the first time that dysplastic tissue has been intentionally cultivated in a xenograft model. Growth of premalignant cells has rarely been described, and reported only once as a serendipitous finding in a prostate cancer PDX model [22]. These cells have subtler variations from normal and are much less tumorigenic. Importantly our PDX model offers the opportunity to examine the development of cervical cancer from its premalignant state. There is potential for dysplastic tissue growing in a PDX model to be harvested for use in future studies, although the small size of the xenograft will make this technically challenging. Lesions that eventually progress to carcinoma after multiple passages in vivo could be examined to determine changes at a molecular level that allowed the dysplastic cells to become invasive. In addition, the successful growth of microscopic normal cervical tissue in a PDX model is described here for the first time.\nPDX models likely select more tumorigenic cell subpopulations within tumours with capacity to thrive in the murine milieu and respond to murine growth factors, particularly in animals without a competent host immunity [7]. Our sub-renal capsule PDX model shows this occurred for the majority of samples. A key difference between this model and other cervical cancer PDX models is the mouse breed. Nude or Scid mouse models have been used previously [18,20,21]. However, we used NSG mice, which are more profoundly immunosuppressed, lacking natural killer (NK) cell immunity [24]. NK cells mediate their function through Major Histocompatability Complex (MHC) recognition, and destroy non-self cells [31]. Without this surveillance, neoplastic, dysplastic, and normal xenografted tissue growth was enabled, a major advantage with our model, although only cancer biopsy samples produced large cell masses. The inability to recognise MHC molecules likely greatly improves the engraftment of human cells, however, the study of tumour cell interactions with host innate immunity is a limitation of this model.\nA lower engraftment rate was obtained for sub-renal capsule xenografts compared with prostate and endometrial cancers [22,23] for reasons that remain unclear. A few samples had a longer time to engraftment, which would potentially lower engraftment success. These were earlier samples when skill acquisition necessitated a longer procedural duration. However, these earlier PDX did not have a lower engraftment rate. Although published PDX models of non-cervical cancers have allowed even longer windows for transplantation of up to 24 hours[32], future applications of this model should aim for engraftment of freshly obtained samples within the first few hours to ensure maximum tissue viability. The engraftment rate of this model was comparable to a subcuticular PDX model for cervical cancer of 70% [18], and the recently described orthotopic PDX model at 75% [20] suggesting engraftment rates are tissue and tumour specific. At the commencement of this study the highest rate achieved by an orthotopic PDX model of cervical cancer was only 48% [18\u201321]. Another group has since published a PDX model using the sub-renal capsule as transplantation site and achieved an engraftment rate of %, which is comparable to our own rate [33].\nPDX models require the combination of high engraftment rates, technical ease, and maintenance of in vivo tumour characteristics. Subcutaneous models provide easy access to the xenograft site for monitoring tumour growth [7], but do not accurately model in vivo tumour behaviour as they become encapsulated [18]. Further, direct comparison between the subcutaneous and orthotopic sites for the same patient sample showed that orthotopic transplantation, but not subcutaneous, mimics the metastatic pattern observed in the patient [20,34]. A high engraftment rate is essential for clinical application. Our study suggests that engraftment success can be maximised by engrafting at least 2 animals for each sample. Our finding that subsequent passages of PDX grafts sometimes yielded varied tumour grades suggests that multiple replicate transplantations of each sample should improve preservation of cell population diversity of a patient\u2019s tumour. Hence, to ensure the best use of this resource in a potential future "patient avatar\u2019 situation at least two animals should be transplanted for each patient sample.\nNo growth was achieved from the transplanted cervical cancer cell suspensions, despite a previous application of cell suspensions to orthotopic xenografting, [21]. The inability of cervical cancer cell suspensions to produce tumours compared to other reproductive tract tumours such as endometrial carcinoma [23] may be due to the extensive collagen laid down by SCC of the cervix. Harsher digestion is required which damages cells by stripping adhesion molecules on the tumour cells. Cell suspensions from stomach cancer xenografted to the orthotopic location yielded lower metastatic rates than tissue pieces surgically grafted to that location [16]. This may also be due to better preservation of multiple cell populations required for tumour growth and that non-tumour human cells provide growth factors and signalling mechanisms that improve cancer cell survival and proliferation. Alternatively, transplantation of tumour pieces may better preserve cell cues by maintaining the tumour microenvironment and microarchitecture.\nA limitation of the sub-renal capsule model is difficulty monitoring tumour growth. As the tumour grows beneath the kidney surface, tracking of tumour size at early stages is difficult compared with the subcutaneous site. Tumour growth is often not apparent until the tumour is of considerable size. We used palpation of the flank, in combination with a pilot phase to assess lesion size at necropsy, to assess for tumour growth. The pilot phase also suffers from the limitation of being conducted through the skill acquisition phase, which may have reduced the success of some engraftments. The difficulty in creating a single-cell suspension inhibited our ability to transfect the cells with luciferase for bioluminescence imaging. The model could be strengthened, however, with the addition of other modalities of non-invasive imaging such as ultrasound or MRI. Future applications of this model should make use of these technologies to monitor the variability of individual tumour growth rates that are a feature of PDX models.\nHowever, sub-renal capsule transplantation overcomes problems of xenograft encapsulation and low rates of metastasis compared to the subcutaneous site. The long latency time of this model is not unexpected or unique to this particular PDX model [15]. It does, however present difficulties to the clinical application of PDX models as "patient avatars" [13]. In this concept, the PDX animal bearing the graft of an individual patient could undergo sample treatments to determine the optimal regimen for the donor patient. Cancer treatments cannot wait six months, suggesting that the best application of this model may be for recurrent or resistant disease once standard therapies fail.\nConclusion\nThe subrenal capsule provides an excellent alternate model for generating PDX for the study of tumour progression and evaluating therapies in cervical cancer. The ability to detect cervical dysplasia and normal cervical tissue cells is novel and provides models for the study of tumour initiation and progression.\nSupporting information\nA) photograph showing the position of the animal, with the left kidney exteriorised through the abdominal wall incision, B) post-mortem kidney specimen showing the location of xenograft as indicated by the arrow showing a 4 mm long tumour on the kidney surface.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:03Z', 'description': u'by Ka Pui Sharon Yau, Anthony B. Murphy, Ling Zhong, Anne Mai-Prochnow\n\nCold atmospheric-pressure plasma (CAP) is a relatively new method used for bacterial inactivation. CAP is ionized gas that can be generated by applying an electric current to air or a feeding gas. It contains reactive species and emits UV radiation, which have antibacterial activity. Previous data suggests that CAP is effective in microbial inactivation and can decontaminate and sterilize surfaces, but its exact mode of action is still under debate. This study demonstrates the effect of CAP on the whole proteome of Pseudomonas aeruginosa PAO1 biofilms, which is a dominant pathogen in cystic fibrosis and medical device-related infections. Liquid chromatography-mass spectrometry (LC-MS) was used to identify differentially regulated proteins of whole cell P. aeruginosa extracts. A total of 16 proteins were identified to be affected by plasma treatment compared to the control. Eight of the identified proteins have functions in transcription and translation and their expression changes are likely to be part of a general physiological response instead of a CAP-specific adaptation. However, CAP also affected bacterioferritin (Bfr), Isocitrate dehydrogenase (Idh), Trigger factor (Tig) and a chemotaxis protein, which may be involved in P. aeruginosa\u2019s specific response to CAP. We confirm that bacterioferritin B plays a role in the bacterial response to CAP because \u0394bfrB mutants of both PAO1 and PA14 are more susceptible to plasma-induced cell-death than their corresponding wild-type strains. To our knowledge, this is the first study showing the effect of plasma on the whole proteome of a pathogenic microorganism. It will help our understanding of the mode of action of CAP-mediated bacterial inactivation and thus support a safe and effective routine use of CAP in clinical and industrial settings.', 'title': u'Cold plasma effect on the proteome of Pseudomonas aeruginosa \u2013 Role for bacterioferritin', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206530', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Cold plasma effect on the proteome of Pseudomonas aeruginosa \u2013 Role for bacterioferritin\n\nAffiliations\nCommonwealth Scientific and Industrial Research Organisation (CSIRO) Manufacturing, Sydney, New South Wales, Australia,\nSchool of Biotechnology and Biomolecular Sciences, University of New South Wales, Sydney, New South Wales, Australia\nFigures\nAbstract\nCold atmospheric-pressure plasma (CAP) is a relatively new method used for bacterial inactivation. CAP is ionized gas that can be generated by applying an electric current to air or a feeding gas. It contains reactive species and emits UV radiation, which have antibacterial activity. Previous data suggests that CAP is effective in microbial inactivation and can decontaminate and sterilize surfaces, but its exact mode of action is still under debate. This study demonstrates the effect of CAP on the whole proteome of Pseudomonas aeruginosa PAO1 biofilms, which is a dominant pathogen in cystic fibrosis and medical device-related infections. Liquid chromatography-mass spectrometry (LC-MS) was used to identify differentially regulated proteins of whole cell P. aeruginosa extracts. A total of 16 proteins were identified to be affected by plasma treatment compared to the control. Eight of the identified proteins have functions in transcription and translation and their expression changes are likely to be part of a general physiological response instead of a CAP-specific adaptation. However, CAP also affected bacterioferritin (Bfr), Isocitrate dehydrogenase (Idh), Trigger factor (Tig) and a chemotaxis protein, which may be involved in P. aeruginosa\u2019s specific response to CAP. We confirm that bacterioferritin B plays a role in the bacterial response to CAP because \u0394bfrB mutants of both PAO1 and PA14 are more susceptible to plasma-induced cell-death than their corresponding wild-type strains. To our knowledge, this is the first study showing the effect of plasma on the whole proteome of a pathogenic microorganism. It will help our understanding of the mode of action of CAP-mediated bacterial inactivation and thus support a safe and effective routine use of CAP in clinical and industrial settings.\nFunding: This work was partially funded by a CSIRO OCE postdoctoral fellowship to AM-P. The specific roles of this author are articulated in the "author contributions\u2019 section. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nOver the last century, the widespread use of antibiotics has quickly given rise to multi-drug resistant bacteria [1]. The Centre of Disease Control estimates 2 million people succumb each year to antibiotic-resistant bacterial infections, resulting in 23,000 deaths, and has suggested inappropriate prescription and use of antibiotics are major contributors to the increase in resistance [2]. Frequent use of antibacterial treatments places bacteria under biological pressure, which results in genetic alterations that subsequently improve its survival against antibiotics.\nPseudomonas aeruginosa is an opportunistic pathogen with an intrinsically high antibiotic resistance. Cystic fibrosis (CF) patients suffer from chronic bacterial pulmonary infections with P. aeruginosa as the predominant respiratory pathogen [3]. The recurring infections have been proven to be difficult to treat with current antibiotic regimens; this has been thought to be due to the formation of P. aeruginosa biofilms in the CF patient\u2019s airways [3]. In addition to secretion of actin and extracellular DNA from the extracellular polymeric substance (EPS), formation of biofilms in the airways produce an excess amount of mucous that coats the airway, creating a low oxygen environment ideal for enhanced bacterial growth [4].\nBiofilm formation is a characteristic microbial development that was shown to increase antibiotic resistance in microorganisms [4, 5]. Biofilms are a group of microbial cells enclosed in a matrix of EPS that are attached to a surface [4]. This specific structure serves to cement the whole biofilm community, instead of individual cells, to a surface [5]. It was demonstrated that biofilm cells show a higher resistance to antimicrobial methods due to a range of differences from their planktonic counterparts, including the presence of the EPS, oxidative stress response, differential gene or protein expression, and the presence of persister cells [6\u20138]. A higher resistance means that biofilm killing often needs longer treatment times than killing of planktonic cell cultures of the same species in a direct comparison [9\u201311].\nCold atmospheric-pressure plasma (CAP) has been investigated for its anti-bacterial, -fungal and -viral properties in in vitro models [11\u201313]. CAP is partially ionized gas created by applying high voltage electricity to a gas at atmospheric pressure. The electrons are at high temperature, while the heavy species (molecules, atoms and ions) remain close to room temperature. CAP contains reactive species including excited molecules radicals and ions, and emits UV radiation [14, 15]. Depending on operating conditions and the choice of gas, a mixture of reactive oxygen and nitrogen species (RONS) is produced that has antibacterial effects. Some studies have included high oxygen content gases in combination with atmospheric oxygen and nitrogen species, which introduces a higher diversity of RONS . hydrogen peroxide (H2O2), nitric oxide (NO) and peroxinitrate (O2NOO-) [14\u201316]. Along with the above plasma components, electrons and neutral atoms target cellular and metabolic processes in microorganisms that can cause oxidative stress resulting in cell damage [17, 18]. Bacteria have developed several mechanisms of regulating oxidative stress to increase cell survival under these conditions. This includes the increased expression of P. aeruginosa MexXY-OprM multidrug efflux system, which is commonly associated with aminoglycoside resistance in cystic fibrosis isolates, following increased peroxide exposure [19, 20].\nSeveral CAP studies have been conducted on well-known human pathogens such as P. aeruginosa, Escherichia coli and several Staphylococcus spp. Application of plasma to bacterial cells has proven effective in microbial inactivation, decontamination and sterilization of surfaces and wound healing [11, 21\u201323]. However, only limited data regarding the mechanism of CAP-induced cell death is available and in particular the effects on bacterial genomes and/or proteomes remain to be elucidated.\nIn this study, we investigated the effect of CAP treatment on the proteome of P. aeruginosa biofilm cells. We identified 16 differentially regulated proteins following CAP treatment using LC-MS/MS. Eight proteins involved in ribosomal machinery were found to be upregulated following plasma treatment. Interestingly, bacterioferritin Bfr was also highly expressed after 3 min plasma exposure. Further studies into the role of Bfr in biofilm survival upon CAP treatment showed that a \u0394bfr transposon mutant strain was more susceptible to CAP treatment than its wild-type counterpart, suggesting a role for ferritin in CAP-induced cell death, possibly due to oxidative stress.\nBiofilm formation\nBiofilms were grown in a Centre for Disease Control Biofilm Reactor (CBR, Biosurface Technologies, Bozeman, MT, USA) according to the standard protocol [26]. Briefly, bacteria were inoculated with 10 ml of overnight culture in tryptic soya broth (20g l-1 "Tryptic Soya Broth\u2019 powder; Oxoid; TSB) grown at 37\xb0C in a shaking incubator. Samples were grown on stainless steel coupons in a bioreactor containing 500 ml of TSB (600 mg l-1), the bioreactor was then switched to continuous-flow ( ml min-1) with fresh TSB (100 mg l-1) media once cells had attached to the coupons. After overnight growth, the coupons were aseptically removed from the encasing rods and placed into 24-well plates. Coupons were rinsed twice with 1 ml phosphate buffer saline (PBS) solution to remove non-adhered cells.\nCold atmospheric-pressure plasma (CAP) treatment\nPlasma treatment was performed using the kINPen med (Neoplas tools GmbH, INP Greifswald, Germany) as previously described [11]. Briefly, coupons were placed 1 cm away from the plasma and the kINPen was operated with argon at  slm. Plasma treatment was conducted in triplicates for two time-points, 3 or 10 min, respectively. As a control, coupons were treated with non-ionized argon gas for 10 min at  slm; the plasma does not ignite for flow rates below  slm.\nAfter treatment, coupons were submerged in 1 ml PBS solution to rehydrate surviving cells. Biofilms were scraped from the coupon surface using a flat-edge spatula. In addition, coupons and all liquids were sonicated for 5 min to dissolve possible cell clumps and encourage remaining biofilm to detach from coupon surface. The removal of cells from coupons was confirmed by microscopy and plate count (data not shown).\nPreparation of whole cell samples\nSamples derived from plasma-treated biofilms were processed at the Bioanalytical Mass Spectrometry Facility (BMSF) at the University of New South Wales. Biofilm samples for LC-MS/MS were stored as pellets pooled from 24 coupons. Samples were centrifuged in an Eppendorf MiniSpin centrifuge (12,000 \xd7 g, 3 min). The cell pellets were washed once in PBS and then frozen at -20\xb0C. Cells were lysed using 40 \u03bcl of 2% sodium dooxycholate (SDC), 1 \u03bcl 100 mM dithiothreitol (DTT) and 1 \u03bcl protease inhibitor (MMSAFE) followed by 30 min of sonication (Unisonics). Cellular debris was removed by centrifugation in an Eppendorf MiniSpin centrifuge (12,100 x g, 5 min) and the supernatant discarded.\nQuantification and in-solution digestion of proteins\nThe protein concentration in the lysates was measured using a 2-D quantification kit as per the manufacturer\u2019s instructions (GE Healthcare Life Science). Briefly, proteins were incubated at 37\xb0C in reduction (1 \u03bcl 5mM DTT) and alkaline (2 \u03bcl 5mM iodoacetamide) buffers for 15 and 20 min, respectively. Residue SDC was removed by the addition of 10 \u03bcl 10 mM ammonium bicarbonate, 5 \u03bcl Millipore water and further extracted using  \u03bcl 10% trifluoroacetic acid (TFA) and centrifuged in an Eppendorf MiniSpin centrifuge (12,100 \xd7 g, 10 min). Finally, the peptides were desalted and concentrated using a StageTipsTM C18 microcolumn according to the manufacturer\u2019s instructions (Thermo Scientific).\nInitial data validation and analysis\nPeak lists were generated using Mascot Daemon/Mascot Distiller (Matrix Science, London, England) using default parameters, and submitted to the database search program Mascot (version , Matrix Science). Search parameters: precursor tolerance 4 parts per million (ppm) and product ion tolerances \xb1  Da; Met(O) carboxyamidomethyl-Cys specified as variable modification, enzyme specificity was trypsin, 1 missed cleavage was possible and the non-redundant protein Pseudomonas database from NCBI (Jan 2015) searched. Peptide and protein identifications generated from the peaks were validating using Scaffold (version , Proteome Software Inc., Portland, OR). Peptide identifications were accepted if they could be established at greater than % probability using the Scaffold delta-mass correction. Protein identifications were accepted if they could be established at greater than % probability and contained at least 2 identified peptides. Statistical analysis of proteins detected at each plasma time point was completed using the t-test (p < ) in addition to significance in fold-change to compare changes in protein levels across samples. Functional information proteins of significance were gathered from the Pseudomonas Genome Database [27]. The basic alignment search tool (BLAST) was used to search for sequence similarities to hypothetical or unknown proteins using UniProt accession numbers and protein sequences database [28]. Protein\u2013protein interaction networks were built using the Search Tool for the Retrieval of Interacting Genes/Proteins (STRING, v10) with a medium confidence level () and all available predication methods [29].\nCAP treatment of P. aeruginosa PAO1 and PA14 \u0394bfrB mutants\nTo further investigate upregulation of bacterioferritin following CAP treatment, the susceptibility to plasma treatment of PAO1 and PA14 wild-type strains and their respective \u0394bfrB mutants was measured to examine potential differences between strains. Biofilms were allowed to form on stainless steel coupons placed in 24 well plates with nutrient broth for 48 h. Coupons were aseptically removed and washed twice with PBS before plasma treatment was performed and cells removed from the coupon as described above. Cells were serial diluted in PBS and plated onto nutrient agar. Plates were incubated overnight at 37\xb0C before counting colony forming units.\nResults and discussion\nFrom Scaffold, a total of 16 proteins were identified to be of significance (p > ) in total spectrum counts and fold change between plasma treatment duration (Table 1). Eight out of 16 of the identified proteins have functions in transcription and translation, including RplR, RplB, RpsL, Rho, Efp, RpsQ, RpoB and InfB. Two of the identified proteins (SucC, Idh) are involved in the energy metabolism of the cell, one protein is a chemotaxis protein and one protein (PyrG) is important for nucleotide biosynthesis. Interestingly, two proteins, trigger factor (Tig) and bacterioferritin (BfrB), are important for adaptation and protection of the cell. STRING was used to identify protein\u2013protein interaction networks present in plasma-treated samples, as depicted in Fig 1. The protein interaction networks indicated extensive connections between proteins that were associated with genomic and metabolic processes, and in the removal of reactive species. Additionally, a functional annotation analysis using Database for Annotation, Visualization, and Integrated Discovery (DAVID ) was also conducted (Fig 2) on all proteins identified (S1 Table). This shows that out of 317 identified proteins, 137 (42%) have roles in metabolic pathways. A table listing all 317 proteins identified from the LC-MS/MS data is provided in the supplementary material (S1 Table).\nInteractions were detected by STRING (29). Lines indicate known or predicted protein\u2013protein interactions. Black lines indicate proteins that are co-expressed, green lines indicate proteins within the same gene neighbourhood, blue lines indicate proteins that may be functionally linked based on gene co-occurrence. These networks show the interactions between proteins associated with metabolic processing.\nThe highest number of proteins that were found to be upregulated after plasma treatment are involved in transcription and translation processes and are ribosomal proteins (Table 1). Changes in the expression level of these proteins are unlikely to be a specific response to CAP. Instead, the changes could be a reflection of general metabolic shift and changes in cell physiology due to stress. Additionally, the very high abundance of ribosomal proteins in the bacterial cell making a significant change in expression levels more likely due to higher change of random variations occurring for larger samples.\nTwo of the proteins upregulated after CAP treatment are succinyl-CoA synthetase (SucC) and isocitrate dehydrogenase (Idh). Both proteins have functions in the energy metabolism in the cell. Changes in expression of proteins that are involved in energy metabolism have been observed as a response to antibiotic stress, in particular when a subpopulation of cells become persister cells [30]. In P. aeruginosa, SucC, as part of the sucCD operon, preferentially synthesizes ATP and GTP, but is also capable of generating UTP or CTP. It was shown that the resulting GTP can serve as an alternative source for alginate, an important exopolysaccharide for biofilm formation, as well as for the synthesis of other macromolecules requiring GTP such as RNA and protein [31]. It could be speculated that changes in energy metabolism protein levels after CAP treatment may indicate a response of the cell to ensure survival of a subpopulation of cells.\nInterestingly, two of the upregulated proteins can be categorized as having adaptation and protection functionality. One of the proteins is trigger factor (Tig). The Tig protein, is together with DnaK, involved in folding of newly synthesized proteins, and it has been shown that cells without Tig and DnaK are not viable above 30\xb0C [32]. The other protein is bacterioferritin (BfrB). The possible involvement in protection from CAP-induced oxidative stress regulation is discussed below.\nBacterioferritin is upregulated after CAP treatment\nBacterioferritin B (BfrB) was highly upregulated after CAP treatment (Table 1). This family of proteins has functions in adaptation, protection or transport of small molecules. Bacterioferritins are important for the regulation of the intracellular iron concentration and were shown to play a role in regulating an oxidative stress response via the iron metabolism.\nIn prokaryotes, iron is an important cofactor of many enzymatic reactions necessary for survival. Soluble iron (Fe2+) is moderately required for respiration but, due to incomplete O2 reduction under aerobic conditions, it produces a range of toxic reactive oxygen species [33, 34]. Ferritins and bacterioferritins (Bfr) are iron storage proteins that P. aeruginosa procures to store iron and regulate intracellular iron concentration. In P. aeruginosa, two different types of bacterioferritin exist: bacterioferritin-A (with \u03b1-subunit) and bacterioferritin-B (with a \u03b2-subunit) [35]. These molecules oxidize Fe2+ into Fe3+. The iron is stored in the form of ferrihydrite or ferric phosphate, depending on the presence of phosphate, and released under iron-limiting conditions. P. aeruginosa also makes use of DNA-binding proteins that protect the chromosome from iron-induced hydroxyl damage [36]. Bacterioferritins consists of a ferroxidase centre made up of histidine and glutamine acids that binds and oxidizes Fe2+ to Fe3+, which is then stored in the central cavity. Superoxides have been observed to mobilize the stored iron to its reactive Fe2+ state and cause oxidative damage. Other reports suggest that hydrogen peroxide and superoxide anions may activate the iron regulator protein [37].\nIn murine models, cells treated with RONs-producing drugs have shown a 6-fold increase in ferritin production and cells exposed to iron-containing substances, . haemin, were able to reduce cytotoxic responses to high doses of hydrogen peroxide [37]. Orino et al. showed that increased synthesis of ferritin occurs in HeLa cells exposed to oxidative stress and that an overexpression of ferritin reduced the accumulation of ROS in response to oxidant challenge [37]. These reports suggest the role of ferritin as a protection against reactive species. The oxidative stress response in bacteria is coordinated with iron homeostasis, as reviewed by [38]. In P. aeruginosa biofilms, the importance of exogenous iron plays a significant role in biofilm formation. This is shown by the use of the mammalian iron chelator lactoferritin, which induced continuous twitching motility and a reduced biofilm thickness [39].\nTo show whether bacterioferritin plays a role in the bacterial response to cold plasma treatment, we investigated two P. aeruginosa strains (PAO1 and PA14) and their corresponding \u0394bfrB mutants for survival after CAP treatment (Fig 3). We hypothesized that if the resulting oxidative stress from plasma treatment leads to an increase in ferritins as a protection, mutations in ferritin genes may result in lower survival of the strains upon CAP treatment. Indeed, our results show that both P. aeruginosa wild-type strains have a higher survival rate after 10 min CAP treatment compared to the \u0394bfrB mutants (Fig 3). CAP treatment only led to a small () log reduction in CFU numbers in P. aeruginosa PAO1 wild-type (from  x 103 CFU control to  x 102 after plasma treatment) and  log reduction in P. aeruginosa PA14 wild-type, respectively (from  x 103 CFU control to  x 102 after plasma treatment). In contrast, for both P. aeruginosa PAO1 and PA14 \u0394bfrB mutants, 10 min CAP treatment completely eliminated the biofilms with no viable cells detected after treatment (Fig 3B). These results suggest that BfrB has a protective effect for the cells against CAP-induced oxidative damage in P. aeruginosa.\n(A) Number of log10 CFU recovered from biofilm coupons of control (black bar) and after 10 min CAP treatment (grey bar) for all four strains; n. d. = not detected. Values represent average of three coupons per treatment and error bars show the standard deviation. Data is shown as significant with either p <  (95% confidence, *) or p <  (99% confidence, **), based on a Student\u2019s t-test (2 tailed, homoscedastic). (B) CFU log reduction after 10 min CAP for all four strains.\nLack of functional bacterioferritins in P. aeruginosa will reduce the microorganism\u2019s ability to provide iron required for respiration. In addition, the ability to regulate intracellular iron concentrations would be reduced in \u0394bfrB mutants compared to the wild-type with fully functional bacterioferritin genes. Thus, it is likely that the higher cell death in the bfrB mutants may be due to the synergistic effects of the CAP-induced oxidative stress and the toxic compounds derived from reactive Fe2+.\nConclusions\nBiofilms are increasingly being recognized by the public health community as an important determinant in persistent chronic microbial infections. Additionally, biofilms can be problematic for many industries by fouling surfaces and contaminating food. CAP has the potential to eliminate biofilms that are resistant to conventional antimicrobial methods in a fast and reliable way. Our results show that the mode of action of CAP is linked to oxidative stress regulation in P. aeruginosa. We identified bacterioferritin B as one of the proteins affected by CAP and further results suggest that BfrB gives protection to P. aeruginosa upon CAP exposure. This is consistent with observations of the role of bacterioferritins in the response to oxidative stress of other organisms Identifying the mode of action of CAP in treating bacteria is an important step towards the routine use of CAP in industry and healthcare settings.\nSupporting information\nS1 Table. A list of proteins that are identified in plasma-treated biofilm samples from LC-MS/MS data.\nProteins identified are recognised based on number of unique peptides detected across 3 biological replicates (, Rep. 2, Rep. 3) each from 3 different treatment conditions: 10 min gas treatment, 3 min plasma treatment and 10 min plasma treatment. Percentage of average sequence coverage refers to the percentage of all the amino acids in the protein sequence that were covered by identified peptides detected in the sample. Proteins identified to be of significance (p > ) in total spectrum count and fold change based upon 10 min gas treatment vs. 10 min plasma treatment and 10 min gas treatment vs. 3 min plasma treatment are presented in Table 1.\n15.\nLaroussi M, Leipold F. Evaluation of the roles of reactive species, heat, and UV radiation in the inactivation of bacterial cells by air plasmas at atmospheric pressure. International Journal of Mass Spectrometry. 2004;233(1\u20133):81\u20136.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:05Z', 'description': u'by Laurent Abi-Rached, Philippe Gouret, Jung-Hua Yeh, Julie Di Cristofaro, Pierre Pontarotti, Christophe Picard, Julien Paganini\n\nDefining worldwide human genetic variation is a critical step to reveal how genome plasticity contributes to disease. Yet, there is currently no metric to assess the representativeness and completeness of current and widely used data on genetic variation. We show here that Human Leukocyte Antigen (HLA) genes can serve as such metric as they are both the most polymorphic and the most studied genetic system. As a test case, we investigated the 1,000 Genomes Project panel. Using high-accuracy in silico HLA typing, we find that over 20% of the common HLA variants and over 70% of the rare HLA variants are missing in this reference panel for worldwide genetic variation, due to undersampling and incomplete geographical coverage, in particular in Oceania and West Asia. Because common and rare variants both contribute to disease, this study thus illustrates how HLA diversity can detect and help fix incomplete sampling and hence accelerate efforts to draw a comprehensive overview of the genetic variation that is relevant to health and disease.', 'title': u'Immune diversity sheds light on missing variation in worldwide genetic diversity panels', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206512', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Immune diversity sheds light on missing variation in worldwide genetic diversity panels\n\nFigures\nAbstract\nDefining worldwide human genetic variation is a critical step to reveal how genome plasticity contributes to disease. Yet, there is currently no metric to assess the representativeness and completeness of current and widely used data on genetic variation. We show here that Human Leukocyte Antigen (HLA) genes can serve as such metric as they are both the most polymorphic and the most studied genetic system. As a test case, we investigated the 1,000 Genomes Project panel. Using high-accuracy in silico HLA typing, we find that over 20% of the common HLA variants and over 70% of the rare HLA variants are missing in this reference panel for worldwide genetic variation, due to undersampling and incomplete geographical coverage, in particular in Oceania and West Asia. Because common and rare variants both contribute to disease, this study thus illustrates how HLA diversity can detect and help fix incomplete sampling and hence accelerate efforts to draw a comprehensive overview of the genetic variation that is relevant to health and disease.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: This work was supported by an ATIP-Avenir grant to -R and by the French Government under the " Investissements d\u2019avenir " (Investments for the Future) program managed by the Agence Nationale de la Recherche (ANR, fr: National Agency for Research), (reference: M\xe9diterran\xe9e Infection 10-IAHU-03). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests:  and  are employees of Xegen. This does not alter the authors\u2019 adherence to PLOS ONE policies on sharing data and materials.\nIntroduction\nDefining worldwide human genetic variation at a genomewide level promises breakthroughs to reconstruct human evolution [1] and to define how genetic variation contributes to disease, hence paving the way towards precision medicine [2]. By decreasing sequencing costs by orders of magnitude [3], Next-Generation sequencing (NGS) facilitated the development of large scale genome sequencing projects [4\u20136] aimed at fulfilling this goal. Notably, the 1,000 Genomes Project is currently the reference panel for human genetic diversity [7], having targeted 2,693 individuals from 26 worldwide populations (S1 Fig), with the aim to define common genetic variants whose frequency is higher than 1% in populations. Although completion of the 1,000 Genomes Project represents a milestone for human genomics, there is currently no metric to assess how representative such reference panels for genomewide variation are and sampling bias in particular remains a concern [8]. Here we propose to use Human Leukocyte Antigen (HLA) diversity as a benchmark to perform this assessment. Indeed, because of their critical role in immunity and reproduction, HLA genes evolved to become the most polymorphic human genes, with over 11,000 distinct protein variants encoded by the five most variable HLA loci (HLA-A, -B, -C, -DRB1 and -DQB1) [9], hence making them superb markers of human diversity [10]. Their impact on health and disease [11] and in transplantation medicine [12\u201314] in particular also ensured that HLA sampling is second to none, with hundreds of populations and millions of individuals studied worldwide [15]. The HLA system is thus both the most polymorphic and the most studied genetic system (Fig 1A), and HLA sampling is second to none and considerably more widespread than that of the 1,000 Genomes Project panel for example (Fig 1B). HLA variation can therefore provide a high resolution picture of the representativeness of reference panels for genomewide diversity [15].\nFig 1. HLA sampling (A) is much more widespread than that of the 1,000 Genomes Project (B), which represents the current reference panel of human genomewide diversity.\nA. Circles represent the populations that were HLA typed. Colors and size of the circles correspond to the number of common alleles observed in each population (scales in the bottom left corner). B. Circles represent the region of origin for each of the 26 populations of the 1,000 Genomes Project. Each population has a color that corresponds to the associated geographical region: Europe (blue), Africa (yellow), Americas (red), South Asia (purple), and East Asia (green). A-B. Maps were generated using the ggplot2 package in R [16] and the world database.\nMaterials and methods\n1,000 Genomes Project sequence data\nExome sequence data for all 2,693 individuals forming the 1,000 Genomes Project was obtained (S1 Fig) and then spilt into two groups: a first set of 992 exomes for which there was already available HLA typing data [17] and a second set of 1,701 exomes for which there was no HLA typing data. HLA typing was then performed with the Polymorphisms to Phenotypes for Medicine (PolyPheMe) software, an in silico solution to perform highly-accurate HLA typing from any type of NGS data (see S1 File). In this study, the first set of data was used to evaluate PolyPheMe\u2019s performance and the second set was used for de novo, in silico HLA typing.\nPolyPheMe HLA typing tool\nThe PolyPheMe software (Xegen, France) can perform high accuracy HLA typing for five genes (HLA-A, -B, -C, -DRB1, and -DQB1) for a wide range of sequence data, including whole exome or whole genome data (see S1 File for details about PolyPheMe). All analyses were performed with PolyPheMe  on exome sequences using the IMGT  database [9] as reference.\nEvaluation of PolyPheMe performance\nTo investigate the performance of PolyPheMe, we first analyzed the subset of the 1,000 Genomes Project for which there was already available HLA typing data [17]. In silico typing was thus performed for the HLA-A, -B, -C, -DRB1, and -DQB1 genes for 992 individuals. 294 individuals were excluded for the HLA-DQB1 analysis due to lack of data likely linked to enrichment issues and a total of 9,332 types were generated.\nThe types obtained with PolyPheMe were then compared to those already established [17], and three categories were defined: 1/"concordant\u2019 when the result with PolyPheMe is precise (only one type isolated) and compatible with previously established types, 2/"imprecise\u2019 when the result with PolyPheMe includes multiple possible types but at least one of them is contained in the list of previously established types, and 3/"discordant\u2019 when the results are not compatible (S2 Fig).\nResults initially labelled as"imprecise\u2019 or"discordant\u2019 were further investigated through manual inspection of the sequence reads. For 21 individuals, genomic DNA was also obtained from Coriell Institute and a new HLA typing was performed with a commercial kit (Holotype, Omixon) using NGS. Results were directly analyzed both with commercial Omixon software and PolyPheMe software. This verification step confirmed that 105 typing results initially identified as"discordant\u2019 and four typing results initially identified as imprecise were in fact correctly typed by PolyPheMe (S3 Fig).\nAfter verification of the typing results, the performance of PolyPheMe reaches a precision of % (9,300/9,332) and only % of the types are erroneous (32/9,332) (S2 Fig). Analysis of these 32 cases shows that 29 of them represent unique cases and all 29 of these unique variants were observed in the panel in other individuals (S1 and S2 Tables). This shows that these errors are not biased towards particular variants. Instead, analysis of these cases indicate that the problem stems from under or overrepresentation of one of the two alleles of the locus.\nAfter validating the performance of PolyPheMe, the complete panel of the 1,000 Genome Project was investigated (S4 Fig).\nDefining common HLA variants\nFor each of the five target HLA genes, we established a list of the variants having an allele frequency >1% in at least one population in the Allele Frequency Net Database [15]. Populations with a low sample size can produce incorrect estimates of the real allele frequencies and, conversely, setting too high a limit for the minimum population size can eliminate populations and lead to a lack of coverage for certain geographical regions. Thus a threshold must be selected to reduce the noise produced by populations with low sampling and to maximize geographical coverage. Using this approach, we selected a minimum population size of 150 individuals (S5 Fig) and 340 distinct alleles were defined as common (S3 Table). As an alternative, we also performed an analysis where the number of times an allele was observed in populations is used as a measure of how common it is (S6 Fig).\nDefinition of the common HLA haplotypes\nCommon five-genes haploypes (HLA-A, -B, -C, -DRB1, and -DQB1) were defined as those having a frequency >1% in at least one population in the National Bone Marrow Program reference panel [18] (S7 Fig), the largest source of HLA haplotype data, with a total of 74,425 different haplotypes already observed in one or more population.\nHLA haplotype prediction for the 1,000 Genomes Project panel\nThe PolyPheMe software integrates a module for haplotype prediction based on a previously described methodology [19]. Briefly, using the precise, five-locus HLA genotype, all haplotype combinations are first generated (S4 Table). Then, in selecting the most likely haplotype structures, a priority is given to combinations maximizing the frequency observed in a single population. If a genotype cannot be explained by a haplotype combination in a unique population, the combination that maximizes frequency across all populations is selected. If no haplotype combination can explain the observed genotype, the haplotype with the best frequency is selected and the other haplotype is predicted.\nResults\nAs a first step to compare the HLA diversity observed in the 1,000 Genomes Project to that commonly observed in worldwide populations, we set to define the HLA types of all 2,693 individuals forming the 1,000 Genomes Project panel (S1 Fig) at the five most polymorphic HLA loci: HLA-A, -B, -C, -DRB1 and -DQB1. This analysis used the Polymorphisms to Phenotypes for Medicine (PolyPheMe) software, an in silico solution to perform highly-accurate HLA Typing from any type of NGS data (see Methods and S1 File). As an initial test, PolyPheMe\u2019s performance was first assessed on the 992 individuals of the panel that had already been HLA typed using standard methodology [17]. This comparison revealed a % concordance between PolyPheMe\u2019s results and previous HLA typing (S2 Fig), but after careful sequence inspection and targeted resequencing (S3 Fig), the accuracy was estimated to be higher, reaching % (S2 Fig, S1 Table). Following this validation step, PolyPheMe was then used to determine the HLA types for the remaining 1,701 individuals for whom there was no prior information (S4 Fig, S2 Table). Out of the 26,342 cases of in silico typing performed, only 132 types (%) were not precisely resolved (. defined without ambiguities at a two-field level) and for an additional 32 cases (%), no alleles were identified (S4 Fig). Thus 26,178 precise types (%) were obtained and represent 414 distinct variants: 84 for HLA-A, 160 for HLA-B, 67 for HLA-C, 31 for HLA-DQB1, and 72 for HLA-DRB1.\nTo assess how well the variants observed in the 1,000 Genomes Project panel represent common HLA variation, we used data from the Allele Frequency Net Database to define a common set of variants corresponding to those whose frequency is higher than 1% in populations with sufficient sampling (n>150 individuals, see Methods and S5 Fig). From the analysis of 256 such populations, 340 HLA variants were observed (S3 Table): comparison of these 340 variants to the 414 variants observed in the 1,000 Genomes Project panel shows that the two sets only share 266 variants in common (Fig 2). Thus 74 of the 340 common HLA variants (22%) are missing in the 1,000 Genomes Project panel. That the missing fraction is homogenously distributed across the five HLA genes investigated, ranging between 17 and 28%, shows that this number is not due to a sampling issue with a given gene but is rather a general representation of the common HLA variation missing in the 1,000 Genomes Project panel.\nFig 2. The HLA diversity in the 1000 Genomes Project panel only represents 78% of the expected diversity for the alleles with a frequency >1%.\nThe top part of the figure shows the % match (Y axis) between the expected HLA diversity at different frequency cutoffs (X axis) and the HLA diversity observed in the 1,000 Genomes Project panel. For each frequency cutoff, the number of expected alleles is displayed at the top of each histogram. The bottom part of the figure displays the same information on a locus by locus basis for the 1% cutoff.\nTo understand why 74 common HLA variants are not present in the 1,000 Genomes Project panel, we investigated their geographical and population distribution (Fig 3A). This analysis illustrates two limitations of the 1,000 Genomes Project sampling: missing populations and undersampled regions. The former refers to populations in regions of the world that are not represented in the 1,000 Genomes Project sampling. Indeed, ten and eleven of the missing variants originate for example from populations in Oceania and West Asia, respectively, two geographical regions that are not represented in the 1,000 Genomes Project sampling. Importantly, in those regions, the missing variants can be extremely common, with frequencies higher than 10% (Fig 3B). The latter, "undersampled regions\u2019, corresponds to regions where the sampling does not fully grasp the population diversity of the region. This category includes both a lack of depth in the sampling in terms of the number of individuals studied and an insufficient geographical sampling within a region. For example, while five European populations are included in the 1,000 Genomes Project, fifteen common variants were missed: ten whose frequency is 1\u2013% and that might have been characterized with more sampling depth, and four whose frequency is >% (\u201310%) that were likely missed due to the limited geographical sampling within the region.\nFig 3. The common HLA alleles that are missing in the 1,000 Genome Project panel define a worldwide distribution with variable frequencies that range from low (1\u2013%) to high (>10%).\nA. Worldwide distribution of the populations harboring alleles that are missing in the 1,000 Genomes Project. Colors and size of the circles correspond to the number of common alleles observed in each population (scale on the bottom left corner). The map was generated using the ggplot2 package in R [16] and the world database. B. Geographical distribution of the alleles that are missing in the 1,000 Genomes Project. For each region, the number of distinct alleles is given together with their maximum frequencies.\nThus, while a large fraction (78%) of the common HLA alleles are observed in the 1,000 Genomes Project panel, the HLA benchmark underlines two important areas of improvement. First, a significant fraction (7%) of the very common variants (frequency >10%) are missing in the 1,000 Genomes Project panel. Second, the representativeness of the panel drops dramatically when less common HLA variants are considered: to 33% for example if a larger set of expected alleles with frequency >% is considered (Fig 2). A similar result is obtained if, instead of using a fixed frequency cutoff, the reference set of expected variants is set to include all the variants observed at least five times in populations, as only ~29% of them are observed in the 1,000 Genomes Project panel (S6 Fig). Likewise, assessing the 1,000 Genomes Project in terms of HLA haplotype diversity, a relevant unit for disease association studies, shows that only 37 of the 58 haplotypes (%) whose frequency is >1% in the largest HLA haplotype database (National bone marrow program database [18]) are observed in the 1,000 Genomes Project panel (S7 Fig). That 20 of the 21 missing haplotypes are associated with native populations from the USA or from Oceanian populations, two groups already identified as "missing\u2019 (Fig 3), shows that "missing populations\u2019 are also the main source of missing haplotypes.\nDiscussion\nWorldwide HLA diversity is thus a helpful metric to assess the representativeness of panels of human genetic diversity, as it can define both the common and rare genetic variation that is missing, with both types of variation having potential to impact expression and contribute to individual disease risk [20\u201322]. The approach isolated coverage issues in a reference panel as widely used as the 1,000 Genomes Project panel. While some of the results are intuitive, like the missing variation linked to regions of the world that were not sampled, HLA variation can help assess how much is missing and isolate missing information that is more difficult to predict, like undersampling in particular geographical regions. This information can in turn be used to improve existing panels and assess how relevant are new panels, a critical step to produce an exhaustive catalogue of human variation [23] and develop new therapeutic solutions [24]. This is important because while genomics is a critical step to understand human diversity [25], it is still failing due to historical bias in sampling that focused too much on individuals of European ancestry [8]. The 1,000 Genomes Project was the first to attempt to provide genomewide data on global human diversity but complementary projects that attempt to increase sample size [26] or focus on specific populations [6, 27] are also developing, together with approaches that gather and compile data from multiple sources [28]. Yet all these approaches to generate a better overview of human genetic variation require a metric to assess how successful they are and we show here that HLA variation is a compelling system to perform that assessment.\nSupporting information\nThe 1,000 Genomes Project sampling is given on a regional basis (top part) or on a population basis (bottom part). In both cases the number of individuals used to evaluate PolyPheMe\u2019s performance is also given (performance test column).\nS2 Fig. PolyPheMe\u2019s performance before and after the verification steps.\nPolyPheMe\u2019s performance was assessed on a subset of 992 individuals of the 1,000 Genomes Project panel who were already HLA typed using standard methodology. This figure summarizes the concordant/correct, imprecise, and discordant/erroneous results obtained before and after the validation step (S3 Fig).\nPolyPheMe\u2019s performance was assessed on a subset of 992 individuals of the 1,000 Genomes Project panel who were already HLA typed using standard methodology. 192 HLA types out of 9,332 were initially characterized either as imprecise or discordant comparing to existing results (S2 Fig). For 109 of these 192 cases, we could show that the PolyPheMe results were correct: this figure summarizes the validation steps used for those 109 cases.\nThis figure summarizes the total number of in silico HLA types realized by PolyPheMe on a locus-by-locus basis. For each locus, the number of precise and imprecise types is given, together with the number of cases for which no type was obtained.\nS5 Fig. Impact of the population size threshold (horizontal axis) on the number of populations used (vertical axis on the left, blue line), on the number of common HLA variants defined (vertical axis on the left, orange line), and on the fraction of common HLA variants observed in the 1,000 Genomes Project panel (vertical axis on the right, grey line).\nA threshold of at least 150 individuals per population was used for the final analysis (dotted line).\nS6 Fig. More than 70% of the HLA variants observed at least five times in populations are missing in the 1,000 Genomes Project panel.\nFor each occurrence threshold (minimum number of observations of a given allele in populations), the number of alleles of HLA-A, -B, -C,\u2013DQB1, and\u2013DRB1 observed with this minimum occurrence is given (line "1.\u2019). The second line ("2.\u2019) indicates how many of the alleles listed in 1. are also observed in the 1,000 Genomes Project panel. Finally the third line corresponds to the fraction "2./1\u2019. For example, 1,202 HLA-A, -B, -C,\u2013DQB1, and\u2013DRB1 alleles are observed at least five times in populations. Out of those 1,202 alleles, 354 are also observed in the 1,000 Genomes Project panel, which corresponds to a fraction of .\nThis figure summarizes the common HLA haplotypes and the populations that harbor them with frequency > 1%. The third column gives the number of observations of the haplotypes in the 1,000 Genomes Project panel. Population codes correspond to those described in S8 Fig. Two haplotypes that are not observed in the 1,000 Genomes Project are in bold because they carry common HLA variants (HLA-C*08:06 and HLA-DRB1*14:08).\nThis file provides the results of the analysis with PolyPheMe for the subset of the 1,000 Genomes Project for which there was already available HLA typing data. For 928 of the 992 individuals, the PolyPheMe results were "correct\u2019 for all loci (first tab "Correct typing\u2019). In some cases (marked by asterisks), the PolyPheMe typing was validated through manual verifications (see Methods). For 64 of the 992 individuals (tab "Others\u2019), at least one HLA type was either imprecise (marked in orange) or erroneous (marked in red). The correct type was obtained through manual verifications (see Methods) and is given in green below the imprecise or erroneous type.\nThis Table provides the predicted five-locus HLA haplotypes (HLA-A, -B, -C, -DRB1, -DQB1) for the donors of the 1,000 Genome Project. For each donor, the two haplotypes are given, together with the population where each was observed with the highest frequency (population codes are given in S8 Fig).\nAcknowledgments\nThis work was supported by an ATIP-Avenir grant to -R and by the French Government under the " Investissements d\u2019avenir " (Investments for the Future) program managed by the Agence Nationale de la Recherche (ANR, fr: National Agency for Research), (reference: M\xe9diterran\xe9e Infection 10-IAHU-03). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:06Z', 'description': u'by Marco Parolini, Cristina Daniela Possenti, Andrea Romano, Manuela Caprioli, Diego Rubolini, Nicola Saino\n\nConditions experienced during early-life can cause the onset of oxidative stress, resulting in pervasive effects on diverse life-history traits, including lifespan. In birds, maternally-transferred egg substances may exert positive or negative influence over the offspring phenotype. Among these, testosterone can upregulate the bioavailability of certain antioxidants but simultaneously promotes the production of pro-oxidants, leading to an oxidative stress situation, which is one of the main forces causing telomere attrition However, no study has investigated the role of this androgen on telomere dynamics in birds and little is known about the effects of yolk testosterone on oxidative status in early-life of these species. We physiologically increased the levels of yolk testosterone by in ovo injections in yellow-legged gull (Larus michahellis) to evaluate the effects induced by this androgen on hatchlings plasma total antioxidant capacity, amount of pro-oxidant molecules and telomere length at hatching. Testosterone supplementation did not increase hatchling body growth, did not result in the overproduction of pro-oxidant molecules nor a reduction of antioxidant capacity. Accordingly, telomere length at hatching was not affected by testosterone treatment, although hatchlings from the third-laid eggs showed shorter telomeres than their siblings from first- and second-laid eggs, independently of testosterone treatment. Our results suggest that injection of physiological levels of testosterone does not induce oxidative stress to hatchlings and, consequently do not affect telomere dynamics during early post-natal periods.', 'title': u'Physiological increase of yolk testosterone level does not affect oxidative status and telomere length in gull hatchlings', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206503', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Physiological increase of yolk testosterone level does not affect oxidative status and telomere length in gull hatchlings\n\nFigures\nAbstract\nConditions experienced during early-life can cause the onset of oxidative stress, resulting in pervasive effects on diverse life-history traits, including lifespan. In birds, maternally-transferred egg substances may exert positive or negative influence over the offspring phenotype. Among these, testosterone can upregulate the bioavailability of certain antioxidants but simultaneously promotes the production of pro-oxidants, leading to an oxidative stress situation, which is one of the main forces causing telomere attrition However, no study has investigated the role of this androgen on telomere dynamics in birds and little is known about the effects of yolk testosterone on oxidative status in early-life of these species. We physiologically increased the levels of yolk testosterone by in ovo injections in yellow-legged gull (Larus michahellis) to evaluate the effects induced by this androgen on hatchlings plasma total antioxidant capacity, amount of pro-oxidant molecules and telomere length at hatching. Testosterone supplementation did not increase hatchling body growth, did not result in the overproduction of pro-oxidant molecules nor a reduction of antioxidant capacity. Accordingly, telomere length at hatching was not affected by testosterone treatment, although hatchlings from the third-laid eggs showed shorter telomeres than their siblings from first- and second-laid eggs, independently of testosterone treatment. Our results suggest that injection of physiological levels of testosterone does not induce oxidative stress to hatchlings and, consequently do not affect telomere dynamics during early post-natal periods.\nData Availability: All relevant data are within the manuscript and its Supporting Information files.\nFunding: The author(s) received no specific funding for this work.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nThe conditions experienced during early-life can result in pervasive fitness consequences through diverse physiological mechanisms, one of which involves telomere dynamics [1]. Telomeres are conserved repeated sequences of the TTAGGG nucleotide motif at the end of chromosomes that protect genomic integrity [2]. Telomeres shorten throughout life, and short telomeres at birth or rapid telomere attrition are associated with negative effects on diverse fitness traits [3,4]. Telomere attrition is more pronounced during early-life [4], possibly because intense metabolic activity underlying rapid body growth exposes the organism to the detrimental effects of oxidative stress [5]. In fact, oxidative stress, . the imbalance of the equilibrium between the production of pro-oxidant molecules and antioxidant defences in favour of the former [5], has been identified as a crucial mechanism affecting telomere length [6].\nIn birds, mothers transfer diverse extra-genomic substances to their eggs, which exert a profound influence on offspring phenotype [7]. Whilst the allocation of exogenous antioxidants serves to protect the offspring against detrimental effects of oxidative stress [8] and can help to maintain telomere integrity during early-life periods [9], the transfer of steroid hormones can impair the oxidative status and negatively affect telomere length of the progeny [10]. Testosterone is a maternally-transferred androgen [11,12] playing a pivotal role in the regulation of embryo differentiation and development of diverse phenotypic traits [11]. As other androgens, testosterone is anabolic for muscle and skeletal growth [13\u201315] and supports post-natal body mass gain [16\u201318], although some other studies have returned none or opposite outcomes regarding its effect on post-natal growth [19\u201321]. Some investigations have shown that variations in the exposure to testosterone altered the oxidative balance of birds, with contrasting outcomes. For instance, high amounts of maternally transferred androgens, including testosterone, may represent a cost for offspring in terms of increased susceptibility to oxidative stress due to the accelerated metabolism [11,12]. Enhanced developmental rate mediated by androgens transferred by mothers to the eggs is associated with an increase of cell metabolism and a concomitant overproduction of reactive oxygen species (ROS) [12], with a subsequent shift of the balance between ROS and antioxidants [22]. Moreover, experimental findings have supported the idea that testosterone may also affect the antioxidant machinery [23,24]. A study of zebra finch whose egg testosterone levels were artificially elevated produced male chicks, but not female, with lower plasma antioxidant capacity [25]. Conversely, an experimental increase of testosterone levels of wild male red grouse (Lagopus lagopus scoticus) resulted in high levels of circulating antioxidants and high lipid peroxidation in plasma [26]. A similar manipulations of red-legged partridge (Alectoris rufa) produced mixed responses [27,28], while testosterone supplementation in the yolk of yellow-legged gull (Larus michahellis) eggs increased plasma antioxidant capacity and reduced lipid peroxidation in hatchlings during early post-natal periods [7]. Considering the capability of testosterone to affect both sides of the "oxidative stress\u2019 medal, this androgen might alter the individual oxidative balance and lead to an oxidative stress situation, which can consequently change telomere dynamics. However, the effects of testosterone on telomeres have never been reported in any bird species to date, neither under captive or natural conditions. Thus, to shed light on the capability of testosterone to induce oxidative stress and to elucidate its potential contribution to telomere dynamics, we assessed the effects of a physiological increase in yolk testosterone concentration on oxidative status markers (. the plasmatic amount of pro-oxidant molecules and the total antioxidant capacity) and telomere length in yellow-legged gull hatchlings. We expect that testosterone supplementation would promote the oxidative cost of growth in hatchlings, boosting the production of pro-oxidants and/or decreasing the total antioxidant capacity, and consequently reducing telomere length. In addition, we expect that telomere length would be positively correlated with plasma antioxidant capacity or negatively correlated with the concentration of pro-oxidant molecules.\nMaterials and methods\nField procedures\nThe present study was performed on a large breeding colony (> 400 breeding pairs) of yellow-legged gull in the Comacchio lagoon (NE Italy 44\xb020\u2019 N\u2013 12\xb011\u2019 E). The colony was visited every second day to check for any new nests and newly laid eggs. When a new egg was found, it was marked to monitor the progress of laying and to identify laying sequence and temporarily removed from the nest for experimental manipulation. Removed egg was temporarily replaced with a \'dummy\' egg to prevent any potential change in parental brooding behavior. Eggs were transferred to a nearby tent for manipulation and then they were brought back within two hours from the collection.\nWe aimed at increasing the concentration of testosterone by 1 standard deviation (SD) of the concentration measured in the yolk of yellow-legged gull eggs from the same colony [29], by the injection of a physiologically appropriate volume of a testosterone solution. As the yolk testosterone concentration in the yellow-legged gull eggs varies according to egg size and position in the laying sequence, we scaled the dose due to be injected accordingly. We grouped first- (a-), second- (b-) or third- (c-) laid eggs into three classes (. tertiles) of size depending on the egg mass. Then, we calculated the standard deviation (SD) of the testosterone concentration in the yolk for each tertile within each position in the laying sequence. We estimated the yolk mass for each class size and position in laying sequence according to the following equation: yolk mass =  ( SE) egg mass +  ( SE); F1,88 = , P < ). We computed the amount of testosterone due to be injected as the product of the SD (expressed in ng/g) of testosterone concentration for each tertile and position in the laying sequence and the estimated yolk mass. The injected testosterone doses were as follows (laying order: class of size according to egg mass (g), amount of testosterone (T) injected (ng per egg)): a-eggs: 84\u201391 g: 57 ng, 92\u201395 g: 59 ng, 96\u2013108 g: 42 ng, b-eggs: 80\u201388 g, 74 ng, 89\u201392 g, 73 ng, 93\u201399 g: 81 ng; and c-eggs, 75\u201382 g, 95 ng, 82\u201387 g, 84 ng, 88\u201398 g, 76 ng. The amount of testosterone injected in the yolk of yellow-legged gull eggs was in the same range of other previous studies [7,21].\nTestosterone was injected in the egg yolk according to a previously validated procedure [30]. Before the injection, the egg was weighed and placed with the longitudinal axis vertical. After eggshell disinfection, a hole close to the acute pole was drilled using a sterile pin. Injection was performed using 1-mL sterile syringe with a  \xd7 30 mm needle, while the egg was held firmly with its longitudinal axis vertical. The hole was sealed with a drop of epoxidic glue and a small piece of eggshell superimposed to the hole soon after the injection. Testosterone solutions were prepared in sterile vials dissolving the hormone in corn oil to the final concentration required. Each vial contained the concentration of testosterone to be injected in egg yolk depending on egg mass and position in the laying sequence. We adopted a within-clutch design, whereby both control and testosterone-treated eggs were established within each clutch. We sequentially assigned the treatment schemes to the clutches, according to the order in which the first egg was found (nest, a-, b-, c-egg) as follows: nest 1, testosterone injection (T), control injection (C), T; nest 2, C-T-C; nest 3, T-C-C; nest 4, C-T-T and so forth with the following nests. Testosterone-treated eggs were injected with 30 \u03bcl of the appropriate testosterone solution, while control eggs were injected with the same volume of corn oil only.\nAfter the in-ovo injection, all the nests were visited every day and eggs were monitored until hatching. Because normally up to two days elapse between the time when the egg reaches the pipping stage and hatching, we assigned chicks to their original egg injecting in the pipping egg a small drop of a food dye (either blue or green). Upon the first daily visit to the nest when any individual chick was found to have hatched, the chick was weighed (to the nearest g) and its tarsus was measured (to the nearest  mm). Finally, a blood sample (about 70 \u03bcl) was collected in heparinized capillary tubes after puncturing the hatchling ulnar vein. Blood samples were centrifuged at 11,500 rpm for 10 min to separate red blood cells from plasma, which were both stored at\u2013 20 \xb0C until biochemical and telomere length analyses. Molecular sexing of chicks was performed by the amplification of a section of the CHD gene [31].\nEthics statement\nThis study was conducted under the permission of the Parco Regionale del Delta del Po (#252015, 20 February 2015), which allowed both the manipulation of the eggs biochemical quality and the withdrawal of a blood sample from hatchlings. Blood samples (50\u2013100 \u03bcl) were collected by slightly puncturing the brachial vein with sterile needles and the puncturing site was carefully disinfected. No obvious negative consequences of handling hatchlings were detected.\nMethods of oxidative status markers\nTotal antioxidant capacity (TAC) and the amount of total oxidant status (TOS) were measured in plasma of chicks hatched from both control and T-injected eggs. TAC was measured according to a colorimetric method developed by Erel [32]. The color of 2,2\u2019-azinobis-(3-ethylbenzothiazoline-6-sulfonic acid) radical cation (ABTS*+) bleaches depending on the concentration of antioxidants in the sample. The reaction is monitored spectrophotometrically and the final absorbance is inversely related to TAC of the sample. The assay was calibrated with a standard curve of Trolox and the results were expressed as \u03bcM Trolox equivalent. Mean TAC intra-assay coefficient of variation (CV) was  \xb1 % (n = 5 replicates), while the mean inter-assay CV was  \xb1 % (n = 3 assay plates). TOS was measured according to the colorimetric method developed by Erel [33] in order to assess the amount of pro-oxidant molecules in the sample. The oxidants in the plasma oxidize the ferrous ion-o-dianisidine complex to the ferric ion, which reacting with xylenol orange gives a blue complex. Coloration (proportional to the oxidant molecules in the plasma) was measured by a spectrophotometer at \u03bb = 535 nm. The assay was calibrated by using a standard curve made with hydrogen peroxide (H2O2). The results were expressed as \u03bcM H2O2 equivalents. The mean TOS intra-assay CV was  \xb1 % (n = 5 replicates) and the inter-assay CV was  \xb1 % (n = 3 assay plates).\nTelomere length analysis\nTelomere length (TL) analysis was performed according to the method described by Parolini and coauthors [34]. Genomic DNA was extracted from 10\u201320 \u03bcl of red blood cells using 1 mL TNSE buffer (10 mM Tris HCl, 400 mM NaCl, 100 mM EDTA and % SDS) and a standard phenol/chloroform method. We measured the quantity and purity of the extracted genomic DNA using a Nanophotometer (IMPLEN). Telomere length was measured by the monochrome multiplex quantitative PCR method (MMQPCR) using an iQ5 real-time PCR detection systems (BioRad). PCR reactions were prepared using 20 ng of genomic DNA as template, Quantitative Master Mix 2X SYBR Green (Genespin), telomere and CTCF primers at a final concentration of 1,000 nM and 500 nM each, respectively. The sequences of telomere primers for MMQPCR were (telg 5\u2019-ACACTAAGGTTTGGGTTTGGGTTTGGGTTTGGGTTAGTGT-3\u2019 and telc 5\u2019-TGTTAGGTATCCCTATCCCTATCCCTATCCCTATCCCTAACA-3\u2019), while the single copy sequence used as control was a fragment from the 12th exon of the swallow CTCF gene (CCCTC-binding factor zinc finger protein). The CTCF primers used were: forward (5\u2019-CCCGCGGCGGGCGGCGCGGGCTGGGCGGCTCCCAATGGAGACCTCAC-3\u2019) and reverse (5\u2019-CGCCGCGGCCCGCCGCGCCCGTCCCGCCCATCACCGGTCCATCATGC-3\u2019). The CTCF primers are composed of a swallow genomic sequence and a GC-clamp at the 5\u2019 end (underlined) to increase the melting temperature of the PCR product. Since the melting temperature of PCR products of telomeres and CTCF are different, both primer pairs were used in the same reaction. Cycling parameters for the PCR reactions were previously described by Parolini et al. [34] and were: Stage 1: 15 min at 95 \xb0C; Stage 2: 2 cycles of 15 sec at 94 \xb0C, 15 sec at 49 \xb0C; and Stage 3: 35 cycles of 15 sec at 94 \xb0C, 10 sec at 62 \xb0C, 15 sec at 74 \xb0C with signal acquisition, 10 sec at 84 \xb0C, 15 sec at 88 \xb0C with signal acquisition. Four-fold serial dilutions (from 10 to 100 ng) of a yellow-legged gull hatchling reference sample (DNA was extracted by blood of a coeval chick not included in the experiment) were included in each plate to produce a standard curve to measure reaction efficiency and quantify the amount of telomeric repeats and single copy gene in each sample. We used the same reference sample in each plate. All reactions were run in triplicate and six plates containing 20 samples each were performed. The testosterone and control samples were equally distributed within each plate. Five samples were replicated in each plate to assess repeatability of telomere measures. Telomere length was measured as the T/S ratio, corresponding to the ratio between the mean values of the amount of telomeric repeats (T) and of a single copy gene (S), which was then related to the T/S value of the reference sample. Thus, telomere length was expressed as relative telomere length (RTL). The mean reaction efficiencies for both CTCF and telomere amplifications were greater than 88% and 94%, respectively. In MMQPCR performed to measure relative telomere length lower efficiencies of amplification is expected compared to standard real time qPCR because the primers contain mismatches relative to a perfect TTAGGG repeat. This strategy, which is used to favor the synthesis of PCR products with homogeneous size, gives rise to lower efficiencies during the first cycles. For the control qPCR, primers containing GC clamps/adapters are used to increase melting temperature of the products allowing detection of both PCR reactions in a single well. Also in this case a relatively low reaction efficiency is expected during the first cycles. The mean intra-and inter-plate coefficient of variation (\xb1 SD) of RTL measures was  \xb1 % and  \xb1 %, respectively. The inter-plate coefficient of variation for RTL was not negligible and could be due to differences in qPCR efficiencies occurring among plates, affecting the RTL measurements, and enlarging the coefficient of variation of our measurements. However, considering that the effect of T treatment is far from significance, we are confident that inter-plate variability was not responsible for the absence of significant results. The intra- and inter-plate repeatability of RTL measures, expressed as intra-class correlation coefficient (ICC), was  and , respectively.\nStatistical analysis\nThe effect of testosterone injection on oxidative status markers and RTL was analyzed in linear mixed models (LMM), including clutch identity as a random factor. Treatment, hatchling sex and egg-laying order were included as categorical fixed-effect factors with their two-way interactions. Only non-significant (P > ) interaction terms were excluded from the models in a single step. Complete models are reported in Supporting Information (S2 Table). Moreover, as oxidative stress is a driving force of telomere attrition, in order to investigate the possible covariation between RTL and oxidative status markers, we re-run the same LMM including TAC or TOS as a covariate. Complete models are reported in Supporting Information (S3 Table). Levels of TAC and TOS could not be measured in some (3\u20137) hatchlings because of plasma scarceness (3 samples from control group and 4 samples for testosterone treated group). We also excluded from the analyses a statistical outlier for RTL from an individual of the testosterone treated group (RTL = ) after performing the Grubbs\' test, also called the ESD method (extreme studentized deviate). LMM analyses were performed by SAS  PROC MIXED.\nResults\nWe inoculated 201 eggs, whose hatching success significantly differed between the control (proportion of hatched eggs = 43/97 = ) and T-injected (67/104 = ; \u03c721 = , P = ) groups. The sample of hatchlings included 110 individuals from 67 clutches (mean number of hatchlings per clutch:  ( SD)), with 2 clutches only (3%) containing three hatched chicks, 37 (55%) and 28 (42%) containing two and one chick, respectively. The sex ratio of hatched chicks (proportion of males) did not significantly differ between experimental groups (control eggs: 27/43 = ; T-injected eggs: 28/67 = ; \u03c721 = , P = ), although a marginally non-significant increase of females in T-treated eggs was found. At laying, egg mass did not significantly differ between the two experimental groups (F1, = , P = ; S1 Table). However, egg mass significantly declined with the position in the laying sequence (F2, = , P < ; estimated marginal means (SE): first-laid eggs:  () g; second-laid eggs:  () g; third-laid eggs:  () g), with significant pairwise differences between the first- and third-laid eggs, as well as between second- and third-laid eggs (LSD test; P <  in both the cases). Testosterone supplementation did not affect the incubation time (F1,59 = , P = ), the body mass (F1,76 = ; P = ) and tarsus length (F1,85 = , P = ) of hatchlings, after controlling for sex and laying order (S1 Fig and S1 Table). Testosterone treatment did not significantly affect neither the levels of pro-oxidant molecules nor the total antioxidant capacity in models controlling for laying order and sex effects (Table 1 and S2 Table). However, the amount of pro-oxidants depended on laying order, with hatchlings from second-laid eggs having smaller values than those from first- (P = ) and third-laid (P = ) eggs. Testosterone treatment did not significantly affect RTL (Table 1 and S2 Table), although it was found to vary with laying order (Fig 1), with RTL from last-laid eggs being smaller than RTL from first- (P = ) or second-laid eggs (P = ). Separate LMM of RTL including TAC or TOS as a covariate returned qualitatively similar results compared to original models (S3 Table) and did not reveal any significant covariation between RTL and TAC or TOS (F <  P >  in both the cases; S3 Table).\nClutch identity was included in the models as a random intercept effect. The non-significant effects of the two-way interactions between fixed factors were excluded from the final model. C = control; T = testosterone-injected (the amount of hatchling per each experimental group is reported in brackets). Significant effects are reported in bold.\nDiscussion\nOur results showed that an experimental increase of physiologically-relevant yolk testosterone levels did not cause an overproduction of pro-oxidant molecules nor changes in the antioxidant capacity of hatchlings. Accordingly, telomere length was not affected by the experimental treatment. However, regardless of testosterone injection, we found that telomere length decreased with the position in the laying sequence, with chicks hatched from the last-laid eggs having shorter telomeres compared to their siblings.\nDuring early-life development, avian embryos experience a rapid increase in body mass, which is related to an increase in metabolic rate [35,36] and, consequently to the onset of an oxidative stress situation [11,12]. Some studies postulated that high amounts of maternally transferred androgens, including testosterone, may represent a cost for offspring in terms of increased susceptibility to oxidative stress. In fact, the enhancement of the developmental rate mediated by maternally-transferred androgens boosts cell metabolism and causes the consequent overproduction of ROS, which are produced during normal metabolic processes and can cause severe toxic effects to cellular macromolecules. Moreover, the risk of oxidative stress increases as embryonic growth proceeds because of the higher oxygen diffusion through the shell to support metabolism. In addition, the exposure to high concentrations of atmospheric oxygen at hatching as a consequence of the transition from a chorioallantoic to a pulmonary respiration causes oxidative stress [37]. Thus, the pre- and early postnatal conditions mentioned above can contribute to an excess of pro-oxidants that cannot efficiently be counteracted by antioxidant defenses and repair mechanisms. This would ultimately leads to an imbalance of the hatchling oxidative status and, consequently, to telomere loss [38].\nEffects of testosterone on body mass and offspring sex ratio\nContrary to our expectations, testosterone supplementation did not boost somatic growth of hatchlings. Opposite results were obtained by a previous companion study of the yellow-legged gull investigating the effects of a physiological increase of yolk testosterone levels on the phenotype of developing embryos [39], showing that embryos from testosterone-treated eggs had a larger body size and a smaller amount of residual yolk mass compared to controls [39]. These previous findings suggest that testosterone (1) enhances body size, accelerating yolk absorption and/or (2) possesses anabolic effects that are already expressed during late embryonic stages [39]. Moreover, in a previous manipulative experiment of egg testosterone levels performed on the same yellow-legged gull colony, a negative effect of testosterone was found on body mass four days after hatching [21]. Thus, the positive effect of testosterone on pre-natal body size seems to vanish at birth and turns into negative during post-natal growth. These findings are consistent with a previous study of the spotless starling (Sturnus unicolor), showing stronger effects of testosterone treatment during embryo development with respect to the nestling period [40]. Interestingly, T-treatment induced a marginally non-significant deviation of hatchling sex ratio towards females. These findings were partly in agreement with previous studies of birds that returned contrasting results. Whilst long-term implants of testosterone produced more male offspring in the homing pigeon [41] and spotless starling [42], and short-term injection increased the number of males in the zebra finch [43] and the white leghorn chicken [44], a correlative study of the Japanese quail showed that high circulating levels of testosterone produced more female offspring [45]. Thus, these studies showed that testosterone has the potential to mediate offspring sex ratios under natural conditions, although the mechanism by which the adjustment in sex ratio occurred in these species remains unclear.\nEffects of testosterone on oxidative status and telomere length\nConversely to findings on embryos that showed a testosterone-induced overproduction of pro-oxidant molecules in the brain and the liver [39], the supplementation of yolk testosterone did not boost the production of oxidizing compounds and did not affect the total antioxidant capacity of hatchlings. These findings are consistent with a previous study showing that the experimental manipulation of yolk testosterone did not affect neither plasmatic ROS levels nor antioxidant capacity in 1-day old yellow-legged gull chicks hatched from the last-laid eggs [7]. However, the same study showed a significant enhancement of antioxidant capacity in testosterone-treated chicks at 5 and 9 days, associated with a decrease of lipid peroxidation, suggesting that yolk testosterone may induce a mobilization of antioxidants during development and/or produce a stress during early developmental periods that could promote a compensatory response later in life [46]. Thus, a pre-natal physiological increase of yolk testosterone did not cause an oxidative stress situation to hatchlings, which consequently did not affect telomere length in our study. However, since in the yellow-legged gull the consequences of testosterone supplementation on the oxidative status emerged in late post-natal period [7], we cannot exclude an effect on telomere length in later life stages. For instance, a positive effect of a subcutaneous injection with vitamin E and methionine on telomere length was found in blue tit nestlings only one year after the treatment [40].\nVariation of telomere length according to the position in the laying sequence\nRegardless of testosterone treatment, hatchling telomere length decreased with the position in the laying sequence (Fig 1). In the yellow-legged gull there is a clear laying order in the eggs produced within a clutch, with a decrease in egg size and changes in the egg composition (. antioxidant and hormonal content) within broods [29]. The shortening of telomere length with laying order suggests that, at least during early-life periods, last-hatched chicks within a clutch experienced a faster rate of cellular senescence than their siblings [47]. Because in the yellow-legged gull the amount of maternally-transferred antioxidants decreases with the laying order [29], shorter telomere length of last-hatched chicks may be due to the lower amount of antioxidants compared to their siblings from first- and second-laid eggs, which do not efficiently safeguard their telomere integrity. These results are consistent with previous studies of passerine birds, showing a decrease in early postnatal telomere length between the first- and the last-hatched nestlings [47,48]. For instance, maternally-derived antioxidants such as vitamins or carotenoids decline with laying order in the zebra finch [49]. As the antioxidants play a crucial role in protecting embryos from oxidative stress during prenatal development [50,51], it is plausible that embryos from the last-laid eggs suffer high levels of oxidative stress during development, resulting in shorter telomeres compared to their siblings. Lastly, although later embryos within a clutch has higher levels of maternally-transferred testosterone [29] that might contribute to imbalance the oxidative status and affect telomere length, the present study revealed that this androgen does not contribute to the onset of an oxidative stress situation and to the consequent telomere loss at birth.\nAlthough our investigation did not show any significant effect of a physiological increase of yolk testosterone levels, some previous experimental studies have demonstrated that maternally-transferred androgens can affect various traits of offspring phenotype, from embryonic stage to adulthood (reviewed in [52]). Considering the contrasting outcomes returned by manipulative studies of testosterone levels, an unequivocal interpretation of the effect due to maternally-transferred testosterone is difficult to be formulated [12,52\u201354]. The inconsistency of results might be due to differences in the experimental approach used to modulate yolk testosterone levels, which can be performed by manipulating mothers or their eggs [54]. Whilst the manipulation of mothers prevents risk of damaging the egg or affect embryo development, this experimental approach returns some shortcomings [53,54] that can complicate the interpretation of the results. Podmok\u0142a and coauthors [52] showed that the manipulation of androgen levels in the mothers did not significantly affect physiology, reproduction, survival and maternal traits of bird species because the female might limit the transfer of circulating steroids to the eggs through diverse mechanisms (., selective uptake of hormones into the oocyte or by barriers to passive diffusion [55]. In addition, the maternal manipulations of testosterone can affect not only the quantity of this focal androgen transferred to the egg, but also egg and/or maternal quality [53,55]. For instance, androgens and antioxidants (. vitamin E) are co-adjusted within bird eggs [56]. Thus, the administration of testosterone to the mother could result in an increased allocation of antioxidants, which might prevent or limit the direct and indirect effects due to prenatal T exposure on oxidative stress [56], and consequently on telomere dynamics. For these reasons, the injection of known amounts of hormone into the egg appears to be more appropriate method to be used in order to investigate the effects of hormones on offspring phenotype [52\u201354] regardless some shortcomings, namely the selection of the appropriate dose due to be injected, the choice of the solvent to be used as vehicle of the hormone and the timing of egg manipulation [52]. Thus, to investigate the possible effects of testosterone on hatchling growth, oxidative status and telomere length, we strived to prevent such limitations by 1) adjusting the testosterone dose due to be injected into the yolk according to the levels naturally occurring in the eggs of yellow-legged gull breeding in the same colony visited in the present study [29]; 2) using a lipophilic, non-toxic [20,34,39] solvent (. corn oil) allowing to completely solubilize testosterone and to prevent differential distribution and bioavailability of the hormone in the yolk; and 3) manipulating the levels of testosterone at the time of laying, before the developing embryo starts producing its own hormones, in order to mimic the natural situation in which only maternal hormones occur in the egg. Thus, the lack of significant effects due to testosterone treatment cannot be ascribed to the experimental design we used. However, a recent meta-analysis [52] highlighted that the dose injected into the eggs represents the crucial factor accounting for the effects due to testosterone on offspring phenotype. Whilst no effect of solvent used, time of manipulation and site of egg injection was pointed out, the effect due to androgen (mainly testosterone) supplementation greatly depended on the injected dose. In fact, several studies highlighted a significant effect on diverse phenotypic traits after injecting a dose exceeding the natural testosterone concentration into the yolk by a couple of standard deviations, or a pharmacological dose (>5 SD up to 2,000 SD). In contrast, other studies injecting very low doses (\u2264 1 SD) returned no effects due to hormonal manipulation [52], accordingly to our results. Thus, we suppose that the lack of significant effects on offspring body growth, oxidative status and consequently telomere length could be simply due to the low amount of testosterone we injected into the egg yolk. At the same time, we cannot exclude that a larger supplementation of testosterone into the yolk results in a higher growth rate and in an unbalance of offspring oxidative status due to ROS overproduction, causing telomere shortening.\nIn conclusion, our study showed that a physiological increase in testosterone yolk concentration has no effects on plasma oxidative status and telomere length on hatchlings. However, considering the contrasting outcomes from previous studies investigating the effects of testosterone on birds, testosterone-mediated effects may enforce trade-offs in body size and oxidative status at different ontogenetic stages (. embryonic and postnatal periods). Thus, we cannot exclude that testosterone may affect body growth and imbalance the oxidative equilibrium affecting the telomere integrity in later postnatal stages, resulting in long-term consequences to the offspring.\nSupporting information\nS1 Data. The file summarizes all the relevant data that have been used in the statistical analyses.\nS1 Fig. Mean (\xb1SD) of body mass and tarsus length of hatchlings according to the position in the laying sequence.\nS1 Table. Linear mixed models of egg mass at laying and incubation time in relation to testosterone treatment, sex, and laying order.\nClutch identity was included in the model as a random intercept effect. The non-significant effects of the two-way interactions between fixed factors were excluded from the final model. C = control; T = testosterone-injected. Significant effects are reported in bold.\nClutch identity was included in the model as a random intercept effect. The non-significant effects of the two-way interactions between fixed factors were excluded from the final model. C = control; T = testosterone-injected. Significant effects are reported in bold.\nTotal Antioxidant Capacity (TAC) and amount of pro-oxidant molecules (TOS) were singularly included in the models as a covariate. Clutch identity was included in the model as a random intercept effect. The non-significant effects of the two-way interactions between fixed factors were excluded from the final model. Significant effects are reported in bold.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:08Z', 'description': u"by Chukwuma David Umeokonkwo, Patricia Nonye Aniebue, Chima Ariel Onoka, Adaoha Pearl Agu, Muawiyyah Babale Sufiyan, Lawrence Ogbonnaya\nIntroduction HIV and AIDS care requires frequent visits to the hospital. Patient satisfaction with care services during hospital visits is important in considering quality and outcome of care. Increasing number of patients needing treatment led to the decentralization of care to lower level hospitals without documented patient perception on the quality of services. The study determined and compared patient satisfaction with HIV and AIDS care services in public and private hospitals and identified the factors that influence it. Method This was a cross-sectional comparative study of patients receiving antiretroviral treatment in public and private hospitals in Anambra State. The sampling frame for the hospitals consisted of all registered public and private hospitals that have rendered antiretroviral services for at least one year. There were three public urban, nine public rural, eleven private urban and ten private rural hospitals that met the criteria. One hospital was selected by simple random sampling (balloting) from each group. Out of a total of 6334 eligible patients (had received ART for at least 12 months), 1270 were recruited by simple random sampling from the hospitals proportionate to size of patient in each hospital. Adapted, validated and pretested Patient Satisfaction Questionnaire (PSQ18) was interviewer-administered on consenting patients as an exit interview. A Chi-square test and logistic regression analysis were conducted at 5% level of significance. Result There were 635 participants each in public and private hospitals. Of the 408 patients who had primary education or less, 265(%) accessed care in public hospitals compared to 143(%) who accessed care in private hospital (p<). Similarly, of the 851 patients who were currently married, 371 (%) accessed their care in public compared to 480 (%) who accessed care in private (p<). The proportion of participants who were satisfied were more in public hospitals (%) compared to private hospitals (%). The difference in proportion was statistically significant (\u03c72 = , p <). Good retention in care [AOR: , 95%CI: \u2013] was the only predictor of satisfaction in public hospitals while primary education [adjusted odds ratio (AOR); , 95%CI: \u2013], residing in rural area [AOR: , 95%CI: \u2013], and once-daily dosing [AOR: , 95%CI: \u2013] were independent predictors of patient' satisfaction among private hospital respondents. Conclusion Satisfaction was higher among patients attending public hospitals. Patient\u2019s satisfaction was strongly associated with retention in care among patients in public hospitals. However, in private hospitals, it was influenced by the patient\u2019s level of education, place of residence, and antiretroviral medication dosing frequency.", 'title': u'Patients\u2019 satisfaction with HIV and AIDS care in Anambra State, Nigeria', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206499', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Patients\u2019 satisfaction with HIV and AIDS care in Anambra State, Nigeria\n\nFigures\nAbstract\nIntroduction\nHIV and AIDS care requires frequent visits to the hospital. Patient satisfaction with care services during hospital visits is important in considering quality and outcome of care. Increasing number of patients needing treatment led to the decentralization of care to lower level hospitals without documented patient perception on the quality of services. The study determined and compared patient satisfaction with HIV and AIDS care services in public and private hospitals and identified the factors that influence it.\nMethod\nThis was a cross-sectional comparative study of patients receiving antiretroviral treatment in public and private hospitals in Anambra State. The sampling frame for the hospitals consisted of all registered public and private hospitals that have rendered antiretroviral services for at least one year. There were three public urban, nine public rural, eleven private urban and ten private rural hospitals that met the criteria. One hospital was selected by simple random sampling (balloting) from each group. Out of a total of 6334 eligible patients (had received ART for at least 12 months), 1270 were recruited by simple random sampling from the hospitals proportionate to size of patient in each hospital. Adapted, validated and pretested Patient Satisfaction Questionnaire (PSQ18) was interviewer-administered on consenting patients as an exit interview. A Chi-square test and logistic regression analysis were conducted at 5% level of significance.\nResult\nThere were 635 participants each in public and private hospitals. Of the 408 patients who had primary education or less, 265(%) accessed care in public hospitals compared to 143(%) who accessed care in private hospital (p<). Similarly, of the 851 patients who were currently married, 371 (%) accessed their care in public compared to 480 (%) who accessed care in private (p<). The proportion of participants who were satisfied were more in public hospitals (%) compared to private hospitals (%). The difference in proportion was statistically significant (\u03c72 = , p <). Good retention in care [AOR: , 95%CI: \u2013] was the only predictor of satisfaction in public hospitals while primary education [adjusted odds ratio (AOR); , 95%CI: \u2013], residing in rural area [AOR: , 95%CI: \u2013], and once-daily dosing [AOR: , 95%CI: \u2013] were independent predictors of patient\' satisfaction among private hospital respondents.\nConclusion\nSatisfaction was higher among patients attending public hospitals. Patient\u2019s satisfaction was strongly associated with retention in care among patients in public hospitals. However, in private hospitals, it was influenced by the patient\u2019s level of education, place of residence, and antiretroviral medication dosing frequency.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nHIV is the fifth leading cause of global Disability Adjusted Life Years (DALY) in 2010 [1,2]. An estimated % of adults aged 15\u201349 years worldwide are living with HIV, although the burden of the epidemic continues to vary considerably between countries and regions [3\u20135]. Sub-Saharan Africa remains most severely affected, with nearly 1 in every 20 adults (%) living with HIV and accounting for 69% of the people living with HIV worldwide [3]. Nigeria had  million people living with HIV infection [6]. In Anambra State, the prevalence of HIV infection has more than doubled in the last few years. According to the Nigeria National HIV sentinel survey of 2010, the prevalence of the disease rose to % from the previous % in 2003, while the national prevalence declined from % to % within the same period [7].\nOver 17 million people were receiving treatment globally as at the end of 2015 [8]. By 2015, in Nigeria, only 28% of those infected were accessing antiretroviral therapy[6]. In Anambra State, the number needing treatment has been on the rise [7].\nHIV and AIDs has evolved over the years from an acute deadly disease to a chronic disease requiring regular clinic visits for medical consultation, laboratory testing and medication refills [9\u201311]. The patient needs to be self-motivated and satisfied in order to remain committed to these activities. Patient satisfaction is a multidimensional construct that focuses on different aspects of health service delivery and outcome [12]. It is a potent tool for evaluating care services and validating the quality of care provided. Information obtained therein helps health administrators to identify areas of improvement such as patient education, health worker-patient relationship, program planning, follow up and clinic organization in order to rapidly improve the quality of health service delivery and its expected outcome [13]. Patient\u2019s satisfaction can be used as an indicator of health care quality because the more satisfied patient is the more likely patient to cooperate with the health care provider and have a higher level of continuity with the provider which in turn improves clinical outcome [14,15].\nIt has been argued that patients\u2019 satisfaction rating is both a measure of care and a measure of the person that provided the rating [16]. Patient satisfaction rating can measure the different aspects of the medical services received or different specific dimensions of the satisfaction or the overall level of satisfaction of total package often referred to as global satisfaction. There are eight dimensions of patient satisfaction frequently reported in most satisfaction surveys and these dimensions include; interpersonal manner, technical quality, accessibility/convenience, finance, efficacy/outcome, continuity, physical environment and availability[16].\nCertain patient characteristics are known to correlate with the global patient satisfaction rating. Older age patients were significantly more satisfied than younger patients [17\u201320]. This, however, is not completely linear, as it has been found that the global patients\u2019 satisfaction rating start declining from the age of 65\u201380 years of life [18]. Healthier patients and those with less education were significantly more satisfied than patients with poorer health status or more education [17,20]. Living in the rural or urban area was significantly associated with younger patients but not with older patients [17]. However patient characteristics like gender, living alone or with others, or whether or not the questionnaire was self-administered or interviewer-administered were not known to be associated with patients\u2019 satisfaction [17,19].\nThere are many studies on patient satisfaction with health care services in general and HIV services in particular. Most studies were carried out on patients receiving treatment from one hospital [13,21\u201324]. A study in Tanzania compared patient satisfaction with HIV related laboratory services in public and private laboratories while another study in north-central Nigeria compared patient satisfaction among public and private secondary level hospital and found no difference [25,26]. This study was conducted to determine and compare the level of satisfaction with HIV and AIDS care services among participants accessing care in public and private hospitals and to identify the factors that influenced their satisfaction.\nMethods\nStudy sites\nThe study took place in Anambra State, southeast Nigeria (Fig 1). Anambra State was the only State in the South East that had a prevalence of over 8% increase from the prevalence of % in 2008 to % in 2010 and one of the five states in the country that had prevalence of over 8% (Akwa Ibom %, Bayelsa %, Benue % and FCT %) [7]. Anambra is one of the most densely populated states and among the most urbanized areas in the country [27]. The urban/rural comparison of HIV prevalence rate in Anambra shows a wide variation of % urban against % rural prevalence. The state prevalence has consistently remained above the median national prevalence since 2008 [7].\nThe hospital system in Nigeria is categorized based on the complexity of the services they provide into primary, secondary and tertiary hospitals. The primary level hospitals are the first level of contact of the population to the health system. They provide preventive, health promotion services and less complex curative services. They usually manned by a medical doctor where available but mostly by nurses and community health officers in most places. The secondary level hospitals are the second level of care. More specialized care is provided here. They have laboratory support, surgery, and other specialist services. Cases needing more than primary care are referred to these hospitals. They often cover wider catchment areas like Local Government Areas and Districts. Tertiary hospitals provide the highest level of specialized care in the health system. They include the teaching and specialist hospitals. In addition to care, they also exist to carry out research and training of doctors and other health workers.\nThe public hospitals are funded and managed by Government primarily to provide health services to the populace. Whereas, the private hospitals are funded by individuals and organizations to provide health services as well as make a profit. In Nigeria, the treatment of HIV started with few tertiary hospitals but later cascaded down to public secondary hospitals and then to private secondary hospitals. These hospitals were all supported by partners to provide free HIV treatment. HIV drugs have remained free in both public and private hospitals. However, following the withdrawal of funding for some laboratory tests, patients have to pay for these services in both public and private facilities. The amount paid for laboratory services was lower public hospitals due to government subsidies than in private hospitals.\nThere were 51 secondary level hospitals in Anambra State that provide comprehensive HIV services. Eighteen hospitals were just recently activated about the time for data collection and had provided HIV services for less than one year and were excluded. The remaining 33 were stratified into publicly and privately owned. In each group, they were also stratified based on the location of practice\u2013urban and rural. There were three public urban, nine public rural, eleven private urban and ten private rural hospitals. In each of these strata, one hospital is selected by balloting to participate in the study. In all two public and two private hospitals were selected for the study.\nThese were two publicly-owned hospitals (General Hospital Onitsha and General hospital Ekwulobia) and two privately-owned, faith-based hospitals (St Joseph\u2019s Hospital Adazi and St Charles Borromeo Hospital Onitsha). These hospitals received technical support from Non-Governmental Organizations.\nGeneral Hospital Onitsha commenced comprehensive ART care and treatment in 2007, runs HIV Clinics twice weekly and had 2438 patients on antiretroviral treatment at the time of the study. St Charles Borromeo Specialist Hospital Onitsha commenced HIV comprehensive care and treatment in July 2005, runs daily HIV clinics and had a total of 2482 patients receiving antiretroviral treatment for HIV infection. General Hospital Ekwulobia commenced provision of comprehensive HIV services in March 2007, runs the HIV clinic twice weekly and had 509 patients currently on antiretroviral treatment. St Joseph\u2019s Hospital Adazi commenced HIV comprehensive care and treatment services in 2007, runs an integrated HIV clinic twice weekly, and had 905 patients on antiretroviral treatment.\nStudy design and sampling\nThe cross-sectional comparative study was conducted between April and August 2015 among adult HIV positive outpatients who had taken antiretroviral treatment for at least one year. The sample size was estimated using the formula for two sample proportion,[28] a power of 80%, the minimum effect size of %, 95% confidence level and proportion of satisfaction among public hospital participants of % as reported in a previous study,[25] and a 15% non-response rate. A total of 635 participants were recruited per group.\nA list of secondary level hospitals offering comprehensive HIV treatment services in Anambra State was obtained and four hospitals were recruited to participate in the study as described above. The list of all patients who are currently on ART (antiretroviral treatment) in each hospital was generated using the facility-based National ART Register. The patient unique ART numbers were captured into a Microsoft Excel workbook for the hospital and ordered in ascending order. This formed the sampling frame for this stage of sampling. The sample size for each group\u2013public and private, were proportionally allocated to the facilities based on the number of patients that were currently receiving ART. These were: General Hospital Onitsha (2438), General Hospital Ekwulobia (509), St Charles Borromeo Hospital Onitsha (2482) and St Joseph\u2019s Hospital Adazi (905). The proportionate allocation of the sample size for each hospital (nh1) was determined using the formula:\nWhere xh1 = number of eligible patients in an index hospital, xht = total number of eligible patients in the hospital group (. private hospitals), and nst = calculated sample size for the hospital group. Hence, the sample sizes used for the study were 525, 110, 465 and 170 for GHO, GHE, SCBHO, and SJHA, respectively.\nA table of random numbers was used to select the sample for each hospital. The first number was selected by dropping a pencil at the center of the table of random numbers and moving down the columns from the top down thereafter. Groups of four digits were used. The pool selected was subsequently matched against the appointment list on each clinic day. Those that attended clinic were approached by trained research assistants after consultation with their clinicians. The study was introduced to them, written informed consent was obtained and the interview was conducted in a room with audio-visual privacy. Before administering the questionnaire, the participants were asked if they had been previously approached for the same study in the last three months. In addition, information about their previous visits, regimen type, and dosing frequency, was extracted from participants\u2019 case notes. The numbers of those interviewed and those that declined participation were struck out from the list. After the first two months, those that did not attend the clinic were replaced using the simple random sampling with a table of random numbers described above.\nStudy instrument\nMarshall and Hays\u2019 Patient Satisfaction Questionnaire short form (PSQ 18)[29]was adapted to assess satisfaction and it was pretested among adult HIV positive outpatient receiving treatment in Ebonyi State (a state in the same geographic region, but situated about 180km away from the study sites). The pretesting led to further modification of the questionnaire before use. The reliability of the tool used to assess satisfaction was tested with Cronbach alpha and the result was . The questions were on a 5-point Likert scale; each domain has positively and negatively structured questions, with a minimum of two and a maximum of four questions. The seven domains of satisfaction were assessed together with patient socio-demographic and clinical information. The study instrument also assessed adherence to antiretroviral treatment using patient self-report. Retention in care was estimated using a 3-month visit constancy method [30\u201332].\nData analysis\nEpi Info version  was used for the data analysis. The responses to the questions in each domain were scored, aggregated and categorized as described by developers of the tool [29]. Participants that scored at least 80% of the maximum expected scores for each domain were classified as satisfied while those with scores less than 80% were classified as dissatisfied.\nThe participants were asked how many doses they had missed in the preceding four-week period. The dosing frequency and the reported number of missed doses were used to estimate the rate of adherence to antiretroviral treatment (ART) calculated as a percentage using the formula[33\u201335] below:\nwhere\nThose that had adherence greater than or equal to 95% were classified as good adherence, otherwise, they were classified as poor adherence.\nThree months visit constancy method was used because the appointment scheduling team in the study area schedules refill appointments every two months. Three months method is more sensitive compared to a four-month method which is usually used in a context where refill visits are scheduled every three months. The 3-month visit constancy method counts the number of the 3-month interval with at least one "kept clinic visit\u2019 during a measurement period. The measurement period was one year prior to the study time. A "kept clinic visit\u2019 was defined as a scheduled visit in which the patient attended, met with and received antiretroviral (ARV) drugs prescription from a health worker who is qualified to prescribe ARV drugs to the patients. The information was extracted from the participants\u2019 record to avoid recall bias and ensure accuracy. The participants were scored 1, 2, 3, or 4 depending on the number of quarters with at least one kept visit. A participant that had at least one kept visit each in three quarters scored 3 out of a total of 4 possible scores for example. For the purpose of further analysis, the scores were categorized into "adequate retention\u2019 (those that scored 4) and "inadequate retention\u2019 (those that scored less than 4).\nThe proportions were compared across public and private hospitals using chi-square test. We assessed the relationship between overall satisfaction and sociodemographic/clinical characteristics using Chi-square test. The factors that were associated with overall satisfaction in bivariate analysis were examined with a multiple logistic regression model at 5% level of significance.\nEthical consideration\nEthical approval number 12/02/2015-23/02/2015 dated 23rd February 2015 was obtained from the Research and Ethics Committee (REC) of Federal Teaching Hospital Abakaliki, (FETHA) Ebonyi State Nigeria. Permission was also obtained from the Anambra State Ministry of Health through the Health Management Board and from the managers of the private hospitals. We obtained written informed consent from all the participants. The exit interviews were conducted in rooms with audio-visual privacy. The participants\u2019 data were anonymized and handled with utmost confidentiality throughout the study.\nResults\nThe mean age of the participants was  (\xb1 ) with females constituting %, % were urban dwellers, % were currently employed and only % had attained post-secondary education. Participants that accessed care in public hospitals were comparable in their sociodemographic characteristics to those that accessed care in private hospitals, except with regards to their marital status and educational level. (Table 1)\nPatients in the public health facilities reported better satisfaction in all the seven domains of satisfaction assessed [Table 2]. On the general satisfaction domain, public hospital patients were more satisfied (%) than those in private hospitals (%) and the difference between them was statistically significant (p <). In both hospital types, however, less than 50% of the participants were satisfied with the technical quality of their health care providers [public (%), private (%)] and time spent with the doctor [public (%), private (%)]. A higher level of satisfaction in the manner of approach of the health care providers and effective communication in both hospital types. The widest variation was observed in the cost of services received: more participants from the public hospitals were satisfied (%) compared to those from private health facilities (%) and this difference was statistically significant (p <). [Table 2]\nTable 3 relates satisfaction to socio-demographic/clinical characteristics of participants in public and private hospitals. To understand how these variables interact with each other, a logistic regression model was used to examine variables that interacted with satisfaction at 10% level of significance [Table 4]. Based on the logistic regression model, only retention in care remained significantly associated with patient\u2019s satisfaction (p<). Participants who had good retention in public hospitals were twice more likely to be satisfied with services received from the hospitals compared to those who had poor retention.\nUnlike in the public hospitals, the level of education, place of residence and ART medication dosing frequency were significantly associated with patient\u2019s satisfaction in private hospitals [Table 4]. Participants that had primary education or less had higher odds (AOR:, 95%CI: \u2013) of being satisfied with services received compared those that had secondary education or higher among the private health facilities. Additionally, participants living in rural area had higher odds (AOR:, 95%CI: \u2013) of being satisfied compared to those that were living in urban areas and those participants who took their medication once daily had higher odds (AOR:, 95%CI: \u2013) of being satisfied compared to those that took their medications twice in a day.\nDiscussion\nThis study set out to examine the difference in satisfaction with services among patients receiving care in public and private hospitals across various domains namely, general satisfaction, technical quality, time spent with the doctor, the manner of approach, effective communication, cost of services received and accessibility and convenience. Overall, the analysis shows a higher level of patients\u2019 satisfaction with services across all domains examined among study participants receiving care in public hospitals, and the influence of various socio-demographic and clinical characteristics on satisfaction.\nGenerally, the high level of satisfaction with services observed among the participants from the public hospitals compares with earlier studies focused on public hospitals reported in Nigeria[23,25] and elsewhere in Cameroon and Zambia [24,36] Comparatively, the difference in the level of satisfaction reported by participants is significant and contrasts with findings from earlier studies in Nigeria [25,37]. Two major attributes of these hospitals relate to the findings, namely, the availability of public subsidies and the characteristics of the users.\nRegarding subsidies, it has been argued that where services are largely subsidized by the government, users generally report a high level of satisfaction due to their little expectation from the system, covering various domains examined. Users are also likely to accept levels of services they may not have accepted if the services were fully paid for as obtains in private hospitals. While the influence of cost on satisfaction was generally noted as negative, the relationship was stronger for private hospitals that have no subsidies for laboratory services. The effect of the cost of services received on the level of satisfaction has been reported [22]. While drugs remain free or hugely subsidized, the implications of the cost of laboratory services is that unsubsidized care does not only affect satisfaction but has the potential to drive households into poverty.\nRegarding the characteristics of users, individuals with higher educational status were less likely to use public hospitals and were also less likely to be satisfied. It is also known that people that are more able to pay, those with better education and living standards, prefer the more sheltered private hospitals. Satisfaction has been opined as the difference between expectation and experience, which on its own is affected by users\u2019 socio-demographic characteristics. The higher education one gets, the more one expects from a system. In this population, individuals with higher education (secondary school and higher) were more likely to access their services from private hospitals. This finding is keeping with that earlier reported [17,19,20] but differs with other findings [17,18]. Issues such as place of residence (urban and rural) were also significant determinants of satisfaction for participants in the private hospitals.\nThere were also similarities in patients\u2019 satisfaction in specific domains that warrant attention. The proportions that were satisfied were less than 50% in both public and private hospitals in technical quality and time spent with the doctor domains. This could mean the patients\u2019 perception of the technical competency of their clinicians were suboptimal. It is also an indicator that most of the patients were not satisfied with the amount of time they spent interacting with their clinicians in both hospital types. These aspects warrant further research exploration to understand its relationship with attitudes of caregivers, motivation, as well as adequacy and workload.\nFinally, this study also showed that participants with better satisfaction in the public hospitals had better retention attributes. This finding supports earlier studies that established the relationship between retention in HIV care and patient satisfaction [21,38]. Also, retention has been previously documented as less of a problem in private hospitals than in public hospitals in the same region of Nigeria [39]. Ensuring retention is very important in HIV programming because retention in care is a critical quality indicator in HIV management. In the private hospitals, dosing frequency was more of a problem with regards to patient experiences. The findings suggest the need to transition patients who can take drugs with fewer dosing schedules to such regimen.\nConclusion\nPatients\u2019 satisfaction was significantly higher among the participants accessing HIV care in public hospitalsin Anambra State compared with their counterpart in the private hospitals. Retention in care was the only factor significantly associated with patients\u2019 satisfaction among the public health facilities\u2019 participants, while place of residence, education, and HIV medication dosing frequency were predictors of patients\u2019 satisfaction among the private hospitals. Cost remains an important determinant of satisfaction and given the chronic need for treatment, subsidies are still necessary for patients in private hospitals. Programme managers in public hospitals should examine and ensure recognized interventions that influence retention, given the relationship with satisfaction, in order to bring this important quality indicator to an optimum level. Positive experiences promoting satisfaction in both public and private hospital should be shared across various facility types to optimize the quality of life of all persons living with HIV and AIDS.\nSupporting information\nAcknowledgments\nWe will like to acknowledge the management of the St Charles Borromeo Hospital Onitsha, St Joseph\u2019s Hospital Adazi, General Hospital Onitsha and General Hospital Ekwulobia for allowing us to use their facilitiesfor the study. We also acknowledge the Dr. Ifeyinwa Okafor, Dr. Ijeoma Alex-Okedo, Dr. Rowland Utulu, Dr. Kingsley Okeke, Dr. Christian Akpa and Dr. Azuka Adeke for their roles in the pre-testing of the questionnaire. Prof Patricia Nonye Aniebue passed away before the submission of the final version of this manuscript. Chukwuma David Umeokonkwo accepts responsibility for the integrity and validity of the data collected and analyzed.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:10Z', 'description': u'by Maharajan Raman, Rachel J. Middleton, Philip A. Kalra, Darren Green\nBackground The benefits of dialysis in older people with ESKD are not clear. We prospectively evaluated whether dialysis has survival advantage compared to conservative care (CC) in older people who were medically suitable for dialysis therapy. Methods This was a prospective observational study of CKD patients aged \u226575 years when eGFR first reached \u226415ml/min/. Hazard ratios (HR) for death were compared between patients who chose dialysis versus conservative care (CC) from when first seen in pre-dialysis clinic (eGFR \u226415ml/min/), and when initiation of dialysis was first considered (eGFR \u226410ml/min/). Patients with co-morbidities likely to significantly reduce life expectancy such as advanced heart failure, advanced dementia, and malignancy, were excluded. Results There were 204 patients (123 dialysis, 81 CC). 115 went on to record eGFR of \u226410ml/min/ (73 dialysis, 42 CC). The median survival from eGFR first \u226415ml/min/ for the dialysis and CC groups were 42 (33\u201350) months and 31 (21\u201341) months. The adjusted hazard ratio (HR) for death in the dialysis group compared to CC was  (\u2013, p = ). The median survival from eGFR first \u226410ml/min/ for dialysis and CC group were 36 (25\u201347) months and 12 (0\u20135) months. The adjusted HR for death in the dialysis group compared to CC was  (\u2013, p <). Conclusion Dialysis confers a survival benefit in older patients medically suitable for dialysis. This study is novel in being both prospective and in excluding patients with co-morbidities which may limit suitability for dialysis and life expectancy. A future focus on quality of life is needed to establish the true benefits of dialysis in older people.', 'title': u'Outcomes in dialysis versus conservative care for older patients: A prospective cohort analysis of stage 5 Chronic Kidney Disease', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206469', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Outcomes in dialysis versus conservative care for older patients: A prospective cohort analysis of stage 5 Chronic Kidney Disease\n\nFigures\nAbstract\nBackground\nThe benefits of dialysis in older people with ESKD are not clear. We prospectively evaluated whether dialysis has survival advantage compared to conservative care (CC) in older people who were medically suitable for dialysis therapy.\nMethods\nThis was a prospective observational study of CKD patients aged \u226575 years when eGFR first reached \u226415ml/min/. Hazard ratios (HR) for death were compared between patients who chose dialysis versus conservative care (CC) from when first seen in pre-dialysis clinic (eGFR \u226415ml/min/), and when initiation of dialysis was first considered (eGFR \u226410ml/min/). Patients with co-morbidities likely to significantly reduce life expectancy such as advanced heart failure, advanced dementia, and malignancy, were excluded.\nResults\nThere were 204 patients (123 dialysis, 81 CC). 115 went on to record eGFR of \u226410ml/min/ (73 dialysis, 42 CC). The median survival from eGFR first \u226415ml/min/ for the dialysis and CC groups were 42 (33\u201350) months and 31 (21\u201341) months. The adjusted hazard ratio (HR) for death in the dialysis group compared to CC was  (\u2013, p = ). The median survival from eGFR first \u226410ml/min/ for dialysis and CC group were 36 (25\u201347) months and 12 (0\u20135) months. The adjusted HR for death in the dialysis group compared to CC was  (\u2013, p <).\nConclusion\nDialysis confers a survival benefit in older patients medically suitable for dialysis. This study is novel in being both prospective and in excluding patients with co-morbidities which may limit suitability for dialysis and life expectancy. A future focus on quality of life is needed to establish the true benefits of dialysis in older people.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nOlder people with CKD have an accumulation of co-morbidities and lower life expectancy compared to younger patients. This contributes to the current lack of clarity around whether dialysis is beneficial in older people. One year mortality for prevalent RRT patients aged 75 to 79 years is high at 200 per 1000 patient years, and higher still for the age group > 85 years at 371 per 1000 patient years [1]. This compares with 75 per 1000 patient years in the age group 60 to 65 years, and 127 per 100 patient years in patients aged >85 years without CKD.\nIt has been suggested that older age has been used covertly to ration dialysis [2]. However, according to the United Kingdom (UK) Renal Registry, the incident rate of commencing renal replacement therapy (RRT) is actually highest among the age group 75 to 79 years, at approximately 500 per million population in the UK.\nThe aim of this study was to establish whether dialysis confers a survival benefit compared to conservative therapy for older patients from two time points: a) when eGFR first falls below 15mL/min/, and b) when eGFR first falls below 10mL/min/. These time points were chosen as they respectively reflect two important time points on the patient journey through outpatient renal services. The first being the point at which pre-dialysis counselling and modality discussions typically begin, and the second is point at which dialysis itself would typically begin or be considered to be appropriate.\nWe also selected only patients who first developed stage 5 CKD in an outpatient setting, omitting AKI requiring dialysis and "crash-landers" who presented to hospital with stage 5 CKD as an acute medical emergency.\nCollectively, these criteria produce an analysis which could be used to provide patients with information about their future care and prognosis, specifically in the context of a pre-dialysis clinic or home visit, the places where decisions about whether or how to dialyse are typically made, such that they may be able to make a clear informed decision.\nAs secondary analyses, we compared any apparent survival benefit conferred by dialysis with the number of extra in-patient and out-patient hospital days faced by dialysis patients. We also observed whether any demographic factors significantly influenced the decision to dialyse or choose conservative care (. being widowed or living alone), and whether there is any survival difference between those who selected haemodialysis and peritoneal dialysis.\nMaterials and methods\nThis was a sub-study of the Salford Kidney Study; a single centre prospectively collected observational study of outcomes in Chronic Kidney Disease in the United Kingdom. Patients who are referred to the Nephrology Secondary Care outpatient clinic at Salford Royal NHS Foundation Trust, or admitted to the Nephrology inpatient ward were approached for inclusion in the study, and were enrolled if written informed consent was gained. Patients underwent annual review including detailed clinical phenotyping and event reporting. Phenotype and outcome data were collected from patient self-reporting, Hospital Electronic Patient Records, primary care records, and mortality data from the Office for National Statistics. The study complies with the declaration of Helsinki and local ethical approval was obtained from the South Manchester Ethics Committee, UK (current REC reference 15/NW/0818).\nPatients were retrospectively selected for this sub-group analysis who first recorded an outpatient eGFR \u226415mL/min/ when aged \u226575 years. Exclusion criteria retrospectively applied were: NYHA 3 or 4 heart failure, previous cardiac arrest, solid organ malignancy diagnosed in the 5 years before eGFR \u226415mL/min/, a Karnofsky performance score <60, any dementia diagnosis, dialysis solely for acute kidney injury (AKI), end stage kidney disease (ESKD) presenting as an emergency hospital admission, and patients with a planned pre-emptive live donor transplant.\nBaseline data were collected for age, gender, eGFR, co-morbidities, Karnofsky Performance Score, marital status, prior occupation, habitation, and co-habitation details. All future outpatient eGFR measurements were recorded. Patients were assigned to either a dialysis group or conservative care group depending on the initial modality choice made by the patient after a home visit or face to face discussion with a pre-dialysis specialist nurse. Patients were excluded from the final analysis if they died before making a modality decision. In the results section, "dialysis patients" refers to patients who chose dialysis over conservative care rather than specifically those patients who began maintenance dialysis.\nFollow up was from the date of first outpatient eGFR measurement of \u226415mL/min/ in the first analysis, and from date of first outpatient eGFR measurement of \u226410mL/min/ in the second analysis. In both cases, follow up was until death or 30th April 2015. Date and cause of death data were obtained from the Office for National Statistics via the Health and Social Care Information Centre. We also compared survival in the period between eGFR 15 and eGFR 10mL/min/ to determine if survival was comparable between the two groups in what would be the "pre-dialysis" period. This latter analysis was to determine if there was any signal of selection bias between groups . whether the dialysis group had improved survival compared to the CC group even before initiation of renal replacement therapy. We also compared rate of change of eGFR between groups during this period.\nData were collected during follow up for inpatient and outpatient hospital days. Outpatient days included routine haemodialysis sessions, drop in visits, outpatient imaging, and outpatient clinic attendances. Inpatient days included day case surgery and procedures, and emergency department visits, as well as ward based inpatient stays. Data were also collected for the number of renal related invasive procedures. These included siting of temporary and tunnelled haemodialysis catheters, removal of tunnelled catheters, arteriovenous fistula formation, open or percutaneous insertion of peritoneal dialysis catheters, renal biopsies, and any procedure necessary as a result of a complication of any of these.\nBetween group comparisons of baseline characteristics in dialysis versus conservative care patients were undertaken using chi square tests, un-paired t-tests and Mann Whitney U tests depending on the characteristics and distribution of each variable.\nSurvival analyses were performed comparing dialysis patients versus conservative care patients using a Cox proportional hazard model adjusted for any variable which statistically differed between groups on the between group comparisons described above and which may influence survival. Further analyses compared outcomes in the population sub-groups of those aged \u226585 years, and patients with prior atherosclerotic cardiovascular events. Within the dialysis group, we compared patients who chose haemodialysis versus those who chose peritoneal dialysis.\nSurvival analysis was then repeated using propensity score matching. Propensity scores were created using clinical co-variates (age, gender, eGFR, diabetes, smoking status, individual cardiovascular co-morbidities, Karnofsky Performance Score, marital and co-habitation status). These were inputted into a logistic regression model with "dialysis patients" as the dependent variable. Dialysis and conservative care patients were then manually matched 1:1 with a calliper width of . Un-matched patients were excluded. Logistic regression was then used to calculate odds ratios for mortality at 1, 3, and 5 years after eGFR first <15 mL/min/, and 1, 3, and 5 years after eGFR first <10 mL/min/ in the dialysis versus CC matched patients.\nThe number of inpatient and outpatient days and the number of invasive procedures are expressed as annualised figures and compared between groups.\nResults\nThere were 258 patients in the final study group of patients who were aged \u226575 years at the point of first outpatient eGFR \u226415mL/min/. 54 patients had not made any decision regarding dialysis versus conservative care during the follow up period and either died before any decision was made or remained undecided at the end of follow up. These were excluded.\nOf the final 204 patients, 123-chose dialysis (60%), and 81 elected for conservative care (40%). A flowchart outlining the exclusion of patients is shown in Fig 1. Patients who chose conservative care over dialysis were older ( \xb1  years versus  \xb1  years, p <), and more likely to live alone and have peripheral vascular disease (PVD). A full outline of baseline characteristics comparing the dialysis and conservative care groups is found in Table 1. Table 1 also compares baseline characteristics of dialysis patients who chose haemodialysis versus those who chose peritoneal dialysis. There was no difference seen between these groups.\nOver a mean follow up from first eGFR \u226415 mL/min/ of  \xb1  months, 52 of the dialysis patients (%) started dialysis. For these patients, the median time to dialysis from first eGFR \u226415 mL/min/ was  months (IQR, \u2013). No patients who chose conservative care switched to dialysis during follow up. Likewise, there were no transplants during follow up. In the dialysis group there were 72 deaths (%), of which 44 (62% of deaths) were in patients who had not yet started dialysis. In the conservative care group there were 67 deaths (%). There was no difference in the rate of change of eGFR between groups. The annualised mean rate of change of eGFR in dialysis patients was - \xb1  mL/min/ per year, compared with - \xb1  mL/min/ per year in the conservative care group.\nThe survival analysis from first eGFR \u226415 mL/min/ using a Cox proportional hazard model was adjusted for age, PVD and living alone as per Table 1. The adjusted hazard ratio for death in the dialysis group compared to the conservative care group was  (95% confidence intervals \u2013, p = ). An adjusted survival curve comparing groups is shown in Fig 2. In the propensity score matching, 40 pairs were matched (mean propensity score in dialysis group =  \xb1 , in CC group =  \xb1 ). In these matched pairs, one year after eGFR first <15 mL/min/, the OR for mortality in the dialysis group compared to the conservative care group was  (\u2013). At three years, the OR was  (\u2013), and at 5 years was  (\u2013). These are shown in Table 2.\nDuring follow up from first eGFR \u226415mL/min/, the dialysis group spent statistically more inpatient and outpatient days at hospital compared to the conservative care group. The median annualised hospital days for dialysis patients was  (interquartile range [IQR], 10\u2013) compared with 10 (IQR, \u2013) for conservative care (p < ). Dialysis patients also underwent more invasive renal procedures, and also more invasive non-renal procedures. Detailed comparisons of hospital activity are found in Table 3. For dialysis patients, Table 3 is further divided into those who chose haemodialysis versus those who chose peritoneal dialysis. Herein, patients who chose haemodialysis spent more time at hospital and underwent more procedures than peritoneal dialysis patients. In a Cox regression survival model comparing dialysis modalities, the HR for death in haemodialysis patients compared to peritoneal dialysis patients was  (\u2013, p = ).\nTable 3. Comparisons of annualised number of hospital days and invasive procedures between dialysis and conservative care, and between haemodialysis and peritoneal dialysis from the baseline of first outpatient eGFR \u226415 mL/min/ and first outpatient eGFR \u226410 mL/min/.\nOf the 204 patients in the final study group, 115 survived to record an eGFR \u226410mL/min/. Of these, 73 had chosen dialysis (63%), and 42 elected for conservative care (37%). The baseline characteristics at this point, including between group comparisons for dialysis versus conservative care and haemodialysis versus peritoneal dialysis, are found in Table 4. Again, conservative care patients were older and were more likely to have PVD.\nFrom first eGFR \u226410 mL/min/, 47 of the dialysis patients (64%) started dialysis over a mean follow up of  \xb1  months. The median time to dialysis from first eGFR \u226410 mL/min/ was  months (IQR, \u2013). In the dialysis group there were 45 deaths (62%) of which 19 (42% of deaths) were in patients who had not yet started dialysis. In the conservative care group there were 39 deaths (93% of conservative care patients who recorded an eGFR \u226410 mL/min/).\nThe survival analysis from first eGFR \u226410 mL/min/ using a Cox proportional hazard model was adjusted for age, and PVD. The adjusted hazard ratio for death in the dialysis group compared to the conservative care group was  (\u2013, p = <). An adjusted survival curve comparing groups is shown in Fig 3. In the propensity score matched cohorts, at one year after eGFR first <10 mL/min/, the OR for mortality in the dialysis group compared to the conservative care group was  (\u2013). At three years, the OR was  (\u2013), and at 5 years was  (\u2013). These are shown in Table 2.\nA comparison of annualised rates for hospital visits and procedures is shown in Table 3, including a comparison of haemodialysis versus peritoneal dialysis. Dialysis patients had more outpatient days than conservative care patients ( [IQR, \u2013] days versus  [IQR, \u2013] days, p <), but there was no difference in in-patient days ( [IQR, \u2013] versus  [IQR, \u2013, p = ). As expected, haemodialysis patients had more out patient days than peritoneal dialysis patients. In a survival model comparing dialysis modalities adjusted for baseline eGFR, the HR for death in haemodialysis patients compared to peritoneal dialysis patients was  (\u2013, p = ).\nWe analysed outcome in the sub-group of very advanced age, \u226585 years (n = 38 [dialysis = 6, conservative = 32). Here, the HR for death after eGFR first <15mL/min/ in the dialysis group compared to conservative care was  (\u2013, p = ). In this age group, the HR for death after eGFR first <10mL/min/ in the dialysis group compared to conservative care was  (\u2013, p = ). In this age group, dialysis patients had a statistically significantly greater number of both renal and non-renal invasive procedures. They did not experience a higher burden of outpatient visits from eGFR first <15mL/min/ but did so after eGFR first <10mL/min/. They did not demonstrate a higher number of inpatient days from either point.\nWe also analysed outcome in the sub-group of patients with previous atherosclerotic vascular events (myocardial infarction, coronary revascularisation including bypass, intervention or amputation for PVD, stroke) (n = 100 [dialysis = 67, conservative = 33). Here, the HR for death after eGFR first <15mL/min/ in the dialysis group compared to conservative care was  (\u2013, p = ). In this sub-group, the HR for death after eGFR first <10mL/min/ in the dialysis group compared to conservative care was  (\u2013, p = ). In this sub-group, dialysis patients had a statistically significantly greater number of both renal and non-renal invasive procedures than the conservative care group from both time points, and both inpatient and outpatient hospital visits from eGFR first <15mL/min/ but not so from eGFR first <10mL/min/.\nWe also performed survival analysis comparing dialysis versus CC group when their eGFR was between 15 and 10 ml/min/. The Kaplan Meier estimates of median survival during this period for dialysis and CC groups were  months (95% CI = \u2013) and  months (95% CI = \u2013) respectively. The adjusted HR for death in the dialysis compared to the CC group was  (95% CI = \u2013), p = . An adjusted survival curve comparing groups is shown in Fig 4.\nWe had also anticipated separately comparing dialysis with conservative care in those patients who were excluded from the primary analysis on the basis of medical illnesses, which could be used as a rationale for selecting conservative care. However, of the 24 patients who fulfilled this exclusion criterion (16 heart failure, 7 malignancy, 1 cardiac arrest), only 2 had initiated dialysis during follow up. Of these 2, 1 died within 12 months. 22 of the 24 patients died during a median  months (IQR \u2013) follow up.\nDiscussion\nIn this prospectively collected study of older patients with stage 5 CKD who were medically suitable for dialysis, we have shown a statistically significant survival advantage in those patients who chose dialysis. Importantly, this survival benefit was consistent across two statistical methodologies. Both methods also found that the greater survival advantage occurred in the period after eGFR fell below 10mL/min/. Although is not direct proof of dialysis being the reason for survival advantage, it is very likely that it a major factor.\nWe have attempted to minimise bias by selecting only patients medically suitable for dialysis, and by using two methods of survival analysis. We have also shown that the clinical phenotypes of the two groups were broadly comparable at both time points selected. We have also show that the rate of change of eGFR in the initial CKD stage 5 period was the same between groups. The limitation remains that patients who chose conservative care were older, more likely to live alone and, of the co-morbidities recorded, had a higher prevalence of PVD. The possibility remains that these factors reflect hidden bias and the extent to which such factors contributed to the difference in outcome remains uncertain. Conversely, although this analysis was performed based on retrospective patient selection, all phenotype data on all patients were collected as part of a detailed prospective observational cohort study. This provides a higher level of phenotype detail than one would typically see in a retrospective study.\nThe exclusion of patients with pre-existing significantly life limiting illnesses produced an analysis where modality choice was based on patient choice and multi-disciplinary team discussion. This may have also acted to reduce the likelihood of co-morbidities creating bias favouring better outcomes for patients who chose dialysis over conservative care.\nOf the 253 patients in our study, 31% (n = 81) chose conservative care, 48% (n = 128) chose dialysis, and 21% (n = 54) did not make a decision regarding RRT during the follow up period when their eGFR was \u226415ml/min/. In other studies, fewer patients tended to choose conservative care. In a European survey of nephrologist from 2009, conservative care was offered to 10% of patients and an additional 5% chose conservative care when they were offered RRT. This survey included patients of all age groups and was not directed specifically at old people [3]. In a single centre observational study from the United Kingdom evaluating outcomes in old people (\u2265 70 years) with ESRD choosing between conservative care and RRT, 14% of patients chose conservative care [4]. The higher percentage of patients choosing conservative care in our study is likely to be due to early multi-disciplinary team review, patient education, and shared decision-making.\nIt was noted when comparing baseline characteristics of dialysis and CC patients that a statistically greater proportion of CC patients lived alone (40% versus 21%, p = ). A numerically but not statistically greater proportion were widowed (37% versus 24%). This may indicate that social as well as medical factors are key drivers to patient decision making in ESKD.\nLate referrals to nephrology services in this age group are associated with much higher mortality. This was 42% in the first year after commencing RTT in one study of 254 patients aged <75 years (%) and \u226575 years (%) [5]. A similar effect has also been described in other age groups. In a national cohort of 2264 dialysis new starters of all ages from the Unites States in the years 1996 and 1997, the first year mortality risk among late referrals was as high as 68% [6] and in another large study of 3014 incident dialysis (peritoneal and haemodialysis) patients from the United States showed that patients who presented late had 36% higher mortality during the first 3 months after starting dialysis compared to patients who presented early [7].\nIn a retrospective analysis evaluating the outcome of RRT in very old people, Munshi et al showed that the median survival on dialysis for patients \u226575 years was 16 months (95% CI 8\u201324 months) [8]. We did not specifically evaluate survival from initiation of RRT as the intention was to compare survival with conservative care patients and there is no direct comparator with RRT commencement in conservative care patients.\nIn a similarly aged patient group (>70 years), a study form the Netherlands showed a survival advantage in the RRT over conservative care group. The median survival was  (IQR, \u2013) years versus  (IQR, \u20133) years respectively [9]. This survival advantage was lost in patients age > 80 years and in patients with a Davies comorbidity score of \u22653. However, the survival in that study was calculated form a point when eGFR <20ml/min/, which is much higher that the eGFR cut off used in our study.\nThat study did exclude patients who presented as emergency cases but was retrospective and does not appear to have excluded conservative care patients for whom dialysis may have been medically inappropriate. Indeed, we believe our study to be the first significant prospective study in this topic, and the first to exclude conservative care patient for whom dialysis is unlikely to have ever been considered. We believe this to be an important consideration when attempting to undertake as close an approximation to a like-for-like comparison in terms of patient selection. This will better reflect the potential outcome in dialysis versus conservative care for patients in a pre-dialysis setting when undertaking a face to face discussion with them about whether they want dialysis.\nMost studies described above have shown a survival advantage with dialysis compared to conservative care. However, there is conflicting information from recent meta-analysis which showed that there is not much difference in survival between dialysis and CC groups. Here, the 1 year survival for undifferentiated dialysis versus conservative care in old people was 73% (95%CI, \u2013%) and 71% (95%CI, \u201378%) respectively [10].\nWe have reported report significantly greater frequency of outpatient and inpatient follow up visits in the "dialysis group" patients compared to those on conservative care. Whilst the majority refer to preparation for dialysis, dialysis itself, and complications of dialysis, it is also likely that dialysis patients received more aggressive care in general. Timely treatment of even apparently minor ailments can prevent severe complications in patients with such advanced CKD.\nConclusion\nOur prospective observational study favours the standpoint that dialysis does confer a survival advantage in older people aged \u226575 years with end stage kidney disease. The survival in our study was assessed from two crucial points in a patient\u2019s journey towards end stage kidney disease. The survival advantage seen in our study provides valuable information for decision making in the age group. Our study had a high uptake into conservative care compared to other studies.\nLimitations\nThe limitations to our study are that we did not undertake measurements of quality of life to compare this aspect of outcome between groups. Also, as with all studies that are not randomised, the possibility of bias remains.\nAcknowledgments\nNone of the authors have any relationships with companies that may have a financial interest in the information contained in the manuscript.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:15Z', 'description': u'by Seung-Hwa Lee, Myungsoo Park, Kyoung-min Park, Hye-bin Gwag, Jungchan Park, Jeayoun Kim, Gyu-Seong Choi, Suk-Koo Lee, Gaab Soo Kim\nBackground Prolongation of corrected QT interval (QTc) on the electrocardiogram is associated with cardiac arrhythmia and sudden death. Changes in the QTc (corrected QT) interval before and after liver transplantation (LT) for the treatment of liver cirrhosis (LC) and its association with clinical outcomes have not been fully evaluated. Methods From January 2011 to May 2016, consecutive 516 consecutive recipients were enrolled into LT registry and the median follow-up was 31 months (IQR 12\u201352). Patients with an available electrocardiogram before LT and 1 month after from LT were analyzed. Patients were divided into 2 groups according to prolonged QTc interval. The patient groups were analyzed separately according whether the electrocardiogram was preoperative or postoperative. The primary outcome was all-cause death during the follow-up period. Results A total of 283 patients were enrolled in the study. In the preoperative QTc prolongation group, there was not a significant rate difference in all-cause mortality in multivariate analysis (hazard ratio [HR], ; 95% confidence interval [CI], \u2013; P = ). However, in the postoperative QTc prolongation group, mortality was significantly increased (HR, ; 95%CI, \u2013; P = ) in patients who underwent LT. Conclusion In patients who underwent LT for LC, postoperative QTc prolongation on ECG, rather than preoperative, is associated with mortality. Larger clinical trials are needed to support this finding.', 'title': u'Corrected QT interval on the electrocardiogram after liver transplantation: Surrogate marker of poor clinical outcomes?', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206463', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Corrected QT interval on the electrocardiogram after liver transplantation: Surrogate marker of poor clinical outcomes?\n\nFigures\nAbstract\nBackground\nProlongation of corrected QT interval (QTc) on the electrocardiogram is associated with cardiac arrhythmia and sudden death. Changes in the QTc (corrected QT) interval before and after liver transplantation (LT) for the treatment of liver cirrhosis (LC) and its association with clinical outcomes have not been fully evaluated.\nMethods\nFrom January 2011 to May 2016, consecutive 516 consecutive recipients were enrolled into LT registry and the median follow-up was 31 months (IQR 12\u201352). Patients with an available electrocardiogram before LT and 1 month after from LT were analyzed. Patients were divided into 2 groups according to prolonged QTc interval. The patient groups were analyzed separately according whether the electrocardiogram was preoperative or postoperative. The primary outcome was all-cause death during the follow-up period.\nResults\nA total of 283 patients were enrolled in the study. In the preoperative QTc prolongation group, there was not a significant rate difference in all-cause mortality in multivariate analysis (hazard ratio [HR], ; 95% confidence interval [CI], \u2013; P = ). However, in the postoperative QTc prolongation group, mortality was significantly increased (HR, ; 95%CI, \u2013; P = ) in patients who underwent LT.\nConclusion\nIn patients who underwent LT for LC, postoperative QTc prolongation on ECG, rather than preoperative, is associated with mortality. Larger clinical trials are needed to support this finding.\nIntroduction\nElectrocardiogram (ECG) is a record of electrical activity of the heart and routinely performed to detect any cardiac problems. The QT interval in the ECG encompasses ventricular depolarization and repolarization, and shows the processes of myocyte excitation, represented by the action potential.[1\u20133] Meanwhile, QT interval length varies with heart rate, and the correct interpretation of the QT interval requires correction by heart rate and called corrected QT interval (QTc).[3] QTc prolongation is one marker of cirrhotic cardiomyopathy and is frequently seen in patients with liver cirrhosis (LC) [1\u20133]. QTc prolongation is also associated with functional re-entry, torsade de pointes, and sudden death in the general population [4,5]. Moreover, LC patients with QTc prolongation show increased mortality [6].\nThe ultimate treatment for LC is liver transplantation (LT) [7]. Cirrhotic cardiomyopathy could theoretically be reversed by LT, but in some patients, QT prolongation did not change or even worsened [8,9]. LC patients with QT prolongation had increased mortality rates, but QT prolongation itself had no independent effect on mortality after LT, and more than half of patients showed normalized QT intervals after LT [10]. To date, changes in the QT interval after LT and its influence on clinical outcomes have not been fully evaluated. The aim of this study was to investigate the effects of preoperative and postoperative QT prolongation and their association with clinical outcomes in LC patients who underwent LT.\nMethods\nStudy population and data collection\nThe present study was a single-center retrospective study. The study population was enrolled from the LT database of Samsung Medical Center. From January 2011 to May 2016, 516 consecutive LT recipients were selected into the registry. The inclusion criteria were: 1) patients who underwent preoperative ECG and 2D echocardiography, 2) patients with follow-up ECG after 1months of window period, and 3) older than 19 years. The exclusion criteria were: 1) patients who did not undergo preoperative 2D echocardiography and preoperative and postoperative ECG, 2) patients undergoing multiple organ transplantations, and 3) patients without LC. Clinical, laboratory, and outcome data were collected by a trained study coordinator using a standardized case report form and protocol. All participants were analyzed anonymously, and consents were approved by the Institutional Review Board of Samsung Medical Center.\nDefinition and outcomes\nDiabetes mellitus was defined as a history of type 1 or type 2 diabetes mellitus that was, treated either pharmacologically or through dietary changes. Hypertension was either defined as self-reported use of antihypertensive medications or as systolic blood pressure >140 mm Hg. Resting blood pressure was measured when patients were admitted. Smoking history was defined as an at least 10 pack-year history of tobacco use. Ascites was detected immediately after surgical incision. A preoperative laboratory test, ECG, and 2D echocardiography were conducted as part of the routine preoperative evaluation. The formula for the model for end-stage liver disease (MELD) score was *loge(bilirubin [mg/dL]) + *loge(INR) + *loge(creatinine [mg/dL]) + *(etiology: 0 if cholestatic or alcoholic, 1 otherwise) [11]. Diastolic dysfunction was defined as in Mitter, et al [12] Left ventricular enlargement was defined as left ventricular end-diastolic diameter over 59mm by M-mode. A postoperative laboratory test was conducted with the follow-up ECG. The primary outcome was all-cause death during follow-up.\nQT prolongation measurement\nThe ECGs were reviewed, and the QTc (QT corrected for heart rate) interval was calculated by one trained staff member blinded to the patient status. The QT interval was measured from the beginning of the QRS complex to the termination of the T- wave (defined as the return to the isoelectric line) in leads where it was identifiable. The QTc interval was calculated by dividing the QT interval in seconds by the square root of the R-R interval in seconds (Bazett formula) [13]. Prolonged QTc was defined as QTc > 440ms [14]. Patients were divided into 4 groups according to the presence of prolonged QTc preoperatively [QTc prolongation (+), group A; QTc prolongation (-), group B] or postoperatively [QTc prolongation (+), group C; QTc prolongation (-), group D]. Clinical outcomes between the two groups were independently analyzed to evaluate the associations between clinical outcomes and QTc prolongation.\nAnesthetic, surgical and postoperative management\nStandardized anesthesia was performed in accordance with our institutional LT protocol. Standard monitoring devices (peripheral capillary oxygen saturation, 5-lead ECG, non-invasive arterial blood pressure) were applied, and anesthesia was induced with thiopental sodium (5 mg/kg) and maintained with isoflurane titrated to a bispectral index of 40\u201360. Remifentanil was also infused up to  mcg/kg/min according to hemodynamic responses. Mechanical ventilation was set at a tidal volume of 8\u201310 ml/kg using a mixture of medical air and oxygen at a fresh gas flow rate of 2 L/min with the respiratory rate adjusted to maintain normocapnia. The radial artery, femoral artery, femoral vein, and internal jugular vein were cannulated for direct hemodynamic monitoring. Infusions of fluids and vasopressor, such as dopamine, norepinephrine, and vasopressin, were administered to maintain mean arterial pressure \u2265 70 mmHg. A warm blanket and a fluid warmer were used to maintain normothermia with room temperature set at 24\xb0C. Packed red blood cells were transfused when blood hemoglobin concentration was <  mg/dL. All surgical procedures were in accordance to standardized institutional protocol. Immunosuppression was based on a quadruple regimen: induction with methylprednisolone plus basiliximab and maintenance with tacrolimus starting on postoperative day 3 plus mycophenolate mofetil. The plasma concentration of tacrolimus was titered at 10\u201315 ng/ml.\nStatistical analysis\nComparisons for continuous variables were made using the t-test or the Wilcoxon rank-sum test, and results were presented as the mean \xb1 standard deviation (SD) or median with interquartile range (IQR). A Chi-square or Fisher\u2019s exact test was used for categorical data. Survival curves were constructed using Kaplan-Meier estimates and compared with the log-rank test. The adjusted hazard ratio (HR) was compared using Cox regression based on the following covariates; male, hypertension, atrial fibrillation, living donor LT, and MELD score which showed P-value <  in the postoperative analysis. Statistical analyses were performed with IBM SPSS  (IBM, Somers, NY) and R version  (R Foundation) software. All tests were two-tailed and P <  was considered statistically significant.\nResults\nAmong 516 consecutive patients, a total of 283 patients were enrolled in the study and the median follow-up was 31 months (IQR 12\u201352). Fig 1 shows a flow chart of study. We analyzed the times of ECG separately. Among the 283 patients, 180 patients showed a prolonged QTc interval (%, group A), and 103 patients showed a normal QTc interval (%, group B) on preoperative ECG. The mean QTc interval was  (\xb1) in the group A and  (\xb1) in the group B (P < ). On follow-up ECG after 1 month, 121 patients showed a prolonged QTc interval (%, group C), and 162 patients showed a normal QTc interval (%, group D). At follow-up, the mean QTc interval was  (\xb1) in the group C and  (\xb1) in the group D (P < ). In addition, we divided patients into 4 groups according to change in QTc: no change in normal QTc (n = 90, %), prolonged QTc to normal QTc (n = 90, %), normal QTc to prolonged QTc (n = 31, %), and persistent prolonged QTc (n = 72, %). In these subgroups, we analyzed baseline differences and outcomes.\nAnalysis of preoperative ECG: Group A vs. group B\nThe baseline characteristics are described in Table 1. Patients in the group A showed lower incidences of smoking history, diastolic dysfunction, hepatocellular carcinoma and living donor LT; low levels of hemoglobin, sodium, and albumin; higher rate of diabetes, and, ascites; higher left atrial volume index and MELD score; and were more likely to be female. In the multivariate analysis, there was no significant difference in all-cause mortality (hazard ratio [HR], ; 95% confidence interval [CI], \u2013; P = ) between the group A and group B (Table 2, Fig 2A).\nAnalysis of follow-up ECGs after LT: Group C vs. group D\nTable 3 shows the baseline characteristics between the two groups. Patients in the group C showed lower incidences of atrial fibrillation and living donor LT; lower levels of hemoglobin, sodium, and albumin; higher rates of hypertension; higher MELD scores; and were more likely to be female. In the multivariate analysis, all-cause mortality during the follow-up period was higher in the group C than in the group D (HR, ; 95%CI, \u2013; P = ) (Table 4, Fig 2B).\nAnalysis of changes in QTc interval\nAmong the patient group that had a prolonged QTc preoperatively, a comparison between patients with normal and prolonged QTc intervals on follow-up ECG are shown in S1 Table. The prolonged QTc group was more likely female and showed lower incidences of atrial fibrillation and of low preoperative hemoglobin levels. A calcium channel blocker was more frequently used in the prolonged QTc group than in the normal QTc group. Among the patient group with normal preoperative QTc intervals, a comparison between patients with normal and prolonged QTc intervals on follow-up ECG is shown in S2 Table. Lower serum potassium levels were seen in the prolonged QTc group. Fig 3 shows the Kaplan-Meier curves between the four groups. Patients who had a prolonged QTc interval on follow-up ECG showed increased mortality regardless of whether preoperative QTc prolongation was observed. Table 5 shows causes of death between the four groups. Among the patients who had a prolonged QTc interval after LT (either the normal to prolonged QTc group or the persistent, prolonged QTc group), over 40% died due to sepsis. Cardiac deaths occurred only in patients with a prolonged QTc interval on follow-up ECG.\nDiscussion\nThe main findings of this study were as follows: 1) preoperative QTc prolongation was not associated with mortality in LC patients who underwent LT; 2) patients who had QTc prolongation on the LT postoperative follow-up ECG showed an increased incidence of all-cause death; and 3) regardless of preoperative QTc prolongation, QTc prolongation after LT was independently associated with all-cause mortality in patients with LC.\nIn a healthy population, prolonged QTc is associated with all-cause and cardiovascular mortality [4,15]. In addition, prolonged QTc interval may be an important marker of cerebral damage [16]. In LC patients, prolonged QTc interval is more frequently seen as a result of several features of LC, such as portal hypertension, sympathetic nervous system activation, or autonomic neuropathy attributed to ventricular repolarization [6,17,18]. Several clinical trials have shown that there is an association of prolonged QTc interval and all-cause or cardiovascular mortality in patients with LC [3,6]. However, the association between QTc prolongation and mortality was not consistent in patients receiving LT [10,19,20]. Moreover, there is limited data on the significance of QTc prolongation in follow-up ECG after LT. A previous study had shown that an improvement in QTc interval post-transplant did not translate into a mortality benefit. However, the study was a case-control study with a small patient population of 73 [20].\nAs mentioned above, a prolonged QTc interval on preoperative ECG was not associated all-cause mortality in LC patients who underwent LT [10,19,20]. We showed a similar result here. QTc prolongation is a supportive criterion of cirrhotic cardiomyopathy, and Child-Pugh score and plasma norepinephrine concentration, a marker of sympathetic nervous system activity, were independently associated with the abnormality [3]. LT has been shown to eventually reverse cardiac dysfunction and normalize the QT interval in some patients [1]. Hence, it is reasonable that preoperative QTc prolongation showed no correlation with mortality after LT. However, there is uncertainty about which patients showed a normalized QTc interval after LT and whether a prolonged QTc interval after LT is associated with a poor clinical outcome.\nIn some LC patients, prolonged QTc interval could be normalized after successful LT [1,10]. In the present study, 50% of patients showed normalization of QTc interval after LT. We showed that prolonged QTc interval on follow-up ECG was associated with a poor clinical outcome in patients who underwent LT. There are several possible explanations for this result. First, individuals with prolonged ventricular repolarization on surface ECG by prolongation of the QT interval are predisposed to ventricular fibrillation and sudden death [4]. Second, a prolonged QT interval is associated not only with sudden death but also with all-cause mortality, which was shown recently in a retrospective study [21]. The main causes of mortality were cerebral stroke/head trauma and heart failure in addition to an aborted cardiac arrest in patients with QT prolongation. Hence, we expect that QT prolongation is associated with mortality in patients with severe illness, although we do not know exact mechanism. Electrolyte imbalance or fatal arrhythmia in conjuntion with severe illness may contribute to increased mortality, but further investigation is needed. Furthermore, prolonged QTc interval is associated with a poor clinical outcome in patients with sepsis [22]. In the present study, over 40% of patients who had prolonged QTc interval on follow-up ECG died from sepsis. Several antibiotics that are used in septic patients could aggravate prolonged QT interval and contribute to death [3,23]. Finally, QT prolongation showed association with severity of LC. [24] Even in the early stage of LC, QT prolongation may be present. Therefore, prolonged QT interval may reflect liver damage itself and lead to poor clinical outcome in the patients with LC even in LT patients. In consideration of our results, clinicians need to be aware of the effect of QTc prolongation and proceed cautiously with LT patients. The definition of QTc interval prolongation varies [16,22,23].\nThe following limitations apply to this study. First, this study was not randomized; therefore, potential confounding factors or selection bias might have significantly affected the results. However, it is hard to match all the clinical variables, especially for patients under critical conditions like severe LC, hepatic failure, or post-operative status. Furthermore, our study population might be homogenous in some way considering that all surgical procedures and post-surgical management were in accordance to standardized institutional protocol. Second, a QTc interval calculated by the Bazett formula is highly dependent on heart rate. Hence, critical situations that affect heart rate may have confounded the results. Third, we cannot exclude that potential pre-transplant underdiagnosis and/or undertreatment of ischemic heart disease or cardiac arrhythmia may have led to an increased post-transplant incidence of mortality. Fourth, the differences in the incidence of cardiac death were not analyzed since only a few cardiac deaths were observed. Fifth, inherent limitations are associated with 12-lead ECG measurements of QT intervals, and rate-correction of QT intervals are often performed incorrectly [25]. Sixth, not only a follow-up ECG after LT was not available in all patients but also not all follow-up ECGs were evaluated at same timepoint after LT. Lastly, the present study did not determine whether the management of QTc prolongation could benefit mortality rates. Despite these limitations, the present study suggests that postoperative QTc prolongation is a useful surrogate marker of mortality, and that it can inform the current prognostic evaluation of LC patients undergoing LT.\nConclusion\nIn patients who underwent LT for LC, postoperative QTc prolongation on ECG, rather than preoperative, is associated with mortality. Larger registry datasets are needed to support this finding.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:19Z', 'description': u'by Myriam Richaud, Simon Galas\n\nThe design of experimental protocols that use animal models to assess the impact of a stress on a population or to determine the life span expectancy impact can be time-consuming due to the need for direct observations of dead and living animals. These experiments are usually based on the detectable activity of animals such as food intake or mobility and can sometimes produce either under- or overestimated results. The tardigrade Hypsibius exemplaris is an emerging model for the evolutionary biology of the tardigrade phylum because of its convenient laboratory breeding and the recent introduction of new molecular tools. In this report, we describe the use of a new fluorescent dye that can specifically stain dead tardigrades. Furthermore, we also monitored the absence of a toxic side effect of the death-linked fluorescent dye on tardigrade populations. Finally, we conclude that tardigrade experiments that require survival counting of the Hypsibius exemplaris species can be greatly improved by using this technique in order to limit underestimation of alive animals.', 'title': u'Defining the viability of tardigrades with a molecular sensor related to death', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206444', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Defining the viability of tardigrades with a molecular sensor related to death\n\nDefining the viability of tardigrades with a molecular sensor related to death\nFigures\nAbstract\nThe design of experimental protocols that use animal models to assess the impact of a stress on a population or to determine the life span expectancy impact can be time-consuming due to the need for direct observations of dead and living animals. These experiments are usually based on the detectable activity of animals such as food intake or mobility and can sometimes produce either under- or overestimated results. The tardigrade Hypsibius exemplaris is an emerging model for the evolutionary biology of the tardigrade phylum because of its convenient laboratory breeding and the recent introduction of new molecular tools. In this report, we describe the use of a new fluorescent dye that can specifically stain dead tardigrades. Furthermore, we also monitored the absence of a toxic side effect of the death-linked fluorescent dye on tardigrade populations. Finally, we conclude that tardigrade experiments that require survival counting of the Hypsibius exemplaris species can be greatly improved by using this technique in order to limit underestimation of alive animals.\nFunding: This work was supported by CNRS D\xe9fi Origins 2018 funding program - Grant number : 265880 - Giga18 (?article1345). The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nWith a length of \u2013 mm, tardigrades can inhabit seas, fresh water or the water films of terrestrial moss and lichens [1]. However, the main reason for the interest in tardigrades lies in their capacity to cope with the harshest treatments or to withstand deleterious environmental conditions. For example, they can survive a 10 kJ/m2 UV exposure [2], a ten-day space flight exposure to solar radiation at low earth orbit in the space vacuum [3], and an exposure of up to  GPa [4], a pressure equal to that prevailing at a depth of up to 180 km from the earth surface. Moreover, tardigrades can resist harsh treatments with organic solvents [5], extreme temperatures (ranging from -272 to 151\xb0C) or high radiation dose (kGy) intensities [6]. The tardigrade can enter an anhydrobiotic latent life state called "tun" that forms by dehydration. Some marine or terrestrial tardigrade species share the capacity to turn on anhydrobiosis. However the anhydrobiosis can be principally encountered in the terrestrial tardigrade group. This is mainly under this inactive and ametabolic anhydrobiotic state [7] that tardigrade can cope with the harshest environmental conditions [8\u201311].\nUp to 1000 species of tardigrade have been reported [12,13,14], but few species can be routinely maintained in the laboratory for experimental investigations. The Hypsibius exemplaris (previously known as H. dujardini) species is a limnetic tardigrade species that can enter anhydrobiosis when its surrounding water film progressively vanishes. H. exemplaris is considered an emerging model for studies on the evolutionary developmental biology of tardigrades. The genome of H. exemplaris has recently been sequenced [15\u201319], and the laboratory culture protocols [20] as well as new genetic knockdown techniques by RNA interference (RNAi) have been described [21]. The H. exemplaris species does not show the higher tardigrade resistance to the harshest stress treatments. However, because of the growing number of techniques now available for H. exemplaris, we found it interesting to develop new tools to facilitate the viability assay protocols with this emerging laboratory model species of tardigrade.\nIt is known that H. exemplaris specimens can be marked as living when a corresponding motility or feeding behavior can be reported by a direct observation of the culture. However, this species sometimes fails to show any motility, for example, when a molt occurs or if individuals prepare egg laying. In such cases, the scoring of dead animals can be more time-consuming than necessary. To avoid such experimental problems and to improve the tools offered by this emerging model, we assessed whether an indirect observation that specifically marks dead animals can be developed.\nWe then assessed whether the SYTOX Green Nucleic Acid stain, a new fluorescent dye, may highlight dead animals in cultures of the H. exemplaris tardigrade. We show that SYTOX green does not have detectable toxicity and can mark dead tardigrades from 1 h to 6 days after labelling, without affecting the normal tardigrade survival. Moreover, we also observed that the living tardigrade scoring by the SYTOX green technique can limit survival underestimation when compared to a classical examination by direct counting.\nWe conclude that experimental assays such as lifespan measurement, stress treatments, effect assessments, or rehydration of anhydrobiotic animals can be greatly improved by the use of SYTOX green labelling with the H. exemplaris tardigrade.\nResults\nSodium azide impacts the viability of Hypsibius exemplaris\nGroups of active tardigrades were incubated with either 5 or 10 mM sodium azide, and their viability was monitored by direct counting of living animals. As shown in Fig 1, a treatment with 5 mM sodium azide induced a highly significant fraction (Z-test, \u03b1 = , p-value = ) of dead animals in comparison with the controls, when the observation was made immediately after drug addition (Fig 1A), while the treatment of tardigrade groups with 10 mM sodium azide resulted in their immediate death. Furthermore, the fraction of dead tardigrades remained roughly the same when the observation of the 5 mM sodium azide-treated group was made at 24 h (Fig 1B), and the corresponding statistical analysis revealed a highly significant difference in comparison with the control group (Z-test, \u03b1 = , p-value = ). The direct counting of living tardigrades performed at either 48 h or 6 days did not reveal any living tardigrades in both the 5 and 10 mM sodium azide-treated groups (Fig 1C and 1D).\nThe average fraction of living tardigrades (y-axis) treated with either 0, 5 or 10 mM sodium azide concentration (x-axis) and scored by direct observation at 1 h (A), 24 h (B), 48 h (C) or 6 days (D) after the experiment began. Error bars indicate the standard deviation from at least three experiments, and a double asterisk represents the respective significant difference at \u03b1 =  (Z-test) degree. A complete description of statistical results is indicated in the text.\nIt is interesting to observe that up to 80% of the H. exemplaris tardigrade groups submitted to 5 mM sodium azide could cope with the treatment for up to 24 h after the beginning of the treatment (Fig 1B).\nThe SYTOX green dye does not impair tardigrade viability\nIn the previous section, we used a sodium azide treatment that allowed us to trigger reproducible tardigrade deaths in a controlled manner. With the goal of substituting the direct scoring technique of tardigrade survival by a death-linked and specific dye, we then assessed whether a treatment with the fluorescent SYTOX green dye may not impair, by itself, the tardigrade groups\u2019 viability.\nTo do so, tardigrade groups were incubated with either , 1 or 10 \u03bcM SYTOX green, and living animals were scored by direct counting. As shown in Fig 2, tardigrade survival was not affected by treatment with the SYTOX green dye at either 1 h (Fig 2A) or 24 h (Fig 2B) of incubation. We then assessed whether the SYTOX green dye could possibly exert a delayed toxic effect on the tardigrade groups. Fig 2C shows the viability of the tardigrade groups at 48 h after the SYTOX green dye addition to the culture media. We were not able to detect a decrease in the tardigrade viability. Furthermore, the tardigrade viability was not significantly impaired (Z-test, \u03b1 = , p-value = ) for all of the experimental groups in up to 6 days of incubation with the three SYTOX green concentrations assessed (Fig 2D).\nThe average fraction of living tardigrades (y-axis) treated with increasing SYTOX green dye concentrations (0, , 1 or 10 \u03bcM; x-axis) and scored by direct observation of viability at either 1 h (A), 24 h (B), 48 h (C) or 6 days (D) after the beginning of the experiment. Error bars indicate the standard deviation from at least three experiments and the "NS" indicates a non-significant difference at \u03b1 =  degree (Z-test). A complete description of statistical results is indicated in the text.\nThus, in light of the results described in this section, we can conclude that the SYTOX green does not impair the viability of the H. exemplaris tardigrade. In addition, we also demonstrated the possibility of adding the SYTOX green dye directly at the beginning of a viability assay without any subsequent alteration of the tardigrade survival.\nWe next wondered about the most suitable SYTOX green dye concentration that may be associated with the optimal scoring of dead tardigrades with the least interference. Because we did not detect any interference with tardigrade survival by the SYTOX green dye at all of the concentrations that we assessed (Fig 2A\u20132D), we then decided to confirm the use of the fluorescent dye at the three concentrations that we assessed by a death-linked fluorescence scoring.\nThe SYTOX green dye improves the tardigrade viability determination\nAs we showed in the previous section, the SYTOX green incubation did not have a negative impact on the tardigrade viability. We then assessed whether the SYTOX green dye association with the sodium azide treatment may allow the detection of the survival fraction of tardigrades by means of the death-linked fluorescent signal.\nFig 3A shows representative pictures of tardigrade groups after 1 h of incubation with either  (Fig 3A-1), 1 (Fig 3A-2) or 10 \u03bcM (Fig 3A-3) SYTOX green. We could observe the tardigrades under brightfield illumination, but as expected, we did not detect an associated SYTOX green fluorescence because of the absence of sodium azide in the media. We next assessed if a 5 mM sodium azide concentration added to the tardigrade media may induce detectable death-linked fluorescence by the SYTOX green dye. As shown in Fig 3B, we were able to detect a death-linked fluorescence from the dose of 1 \u03bcM (Fig 3B\u20131) of the fluorescent dye. Moreover, the incubation with either 1 \u03bcM (Fig 3B-2) or 10 \u03bcM (Fig 3B-3) SYTOX green resulted in an improved result because of increased fluorescent staining of the detectable deaths. This last observation was therefore confirmed with a 10 mM sodium azide treatment (Fig 3C) that resulted in a faint SYTOX green dye staining when the tardigrades were incubated with  \u03bcM (Fig 3C-1) SYTOX green. However, the tardigrade groups treated with 10 \u03bcM sodium azide showed an increase in the observable death-linked fluorescence when either 1 \u03bcM (Fig 3C-2) or 10 \u03bcM (Fig 3C-3) SYTOX green was added to the tardigrade media. A brief comparison of the fluorescent staining between the tardigrade groups shown in Fig 3B-1 and both Fig 3B-2 and 3B-3, as well as between Fig 3C-1 and both Fig 3C-2 and 3C-3, allowed us to conclude that  \u03bcM SYTOX green may underestimate the death fraction in tardigrade groups.\nBecause we observed a comparable death-linked SYTOX green fluorescent staining with both 1 \u03bcM (Fig 3B) and 10 \u03bcM (Fig 3C) media concentration, we then decided to perform the next experiment with 1 \u03bcM SYTOX green to optimize the fluorescent dye volume needed for the experiments.\nWe next decided to evaluate the relevance of a scored death tardigrade fraction by the SYTOX green fluorescence in comparison with a classical examination by direct counting. Fig 4 represents the viability of the tardigrade groups exposed to either 0, 5 or 10 mM sodium azide and stained with 1 \u03bcM SYTOX green fluorescent dye. Fig 4A shows the living tardigrade counts 1 h after the beginning of the experiment. As expected, we observed a non-significant statistical difference (Z-test, \u03b1 = , p-value = ) between control tardigrade groups scored by either direct observation or the death-linked fluorescence. However, we noted a highly significant statistical difference (Z-test, \u03b1 = , p-value = ) between both tardigrade groups when 5 mM sodium azide was added to the media. Furthermore, we were not able to detect tardigrade survival by using either one of the two scoring techniques when 10 mM sodium azide concentration was added to the tardigrade media. It is interesting to note that this result matches with the previous observation of Fig 1A in the previous section. This result is of great significance because it challenges the relevance of the classical counting technique by direct observation and uncovers its underestimation bias. More precisely, it is possible that direct scoring of death tardigrade, which is based only on the apparent motility of animals only, must overestimate the total score of death animals when they do not move at all but are always alive.\nThe average fraction of living tardigrades treated with either 0, 5 or 10 mM sodium azide and scored by direct observation on brightfield illumination (colored bars, left) or SYTOX green dye linked fluorescence at 1 \u03bcM on an epifluorescence microscope (white bars, right), at either 1 h (A), 24 h (B), 48 h (C) or 6 days (D) after the beginning of the experiment. Error bars indicate the standard deviation from at least three experiment repetitions and a double asterisk represents the respective significant difference at \u03b1 =  (Z-test) degree, while "NS" indicate a non-significant difference at \u03b1 =  degree (Z-test). A complete description of statistical results is indicated in the text.\nFig 4B shows an experiment identical to the previous one but scored at 24 h for tardigrade survival instead of 1 h. We did not observe a significant difference (Z-test, \u03b1 = , p-value = ) in the tardigrade viability estimation by the two scoring techniques that we used when 0 mM azide was added to the media. Moreover, the 5 mM sodium azide-treated groups also revealed a non-significant difference between both scoring techniques (Z-test, \u03b1 = , p-value = ). This result may indicate a stabilization of the tardigrade population\u2019s ability to cope with the sodium azide toxicity at this duration of experimental incubation. Interestingly, in the previous section, we noticed a comparable tardigrade viability upon identical sodium azide treatment as shown in Fig 1B.\nFig 4C shows the tardigrade viability at 48 h of incubation. Unexpectedly, we noted a highly significant difference (Z-test, \u03b1 = , p-value = ) in the observed viability between the tardigrade groups scored by either direct counting or the death-linked fluorescence techniques when 5 mM sodium azide was added to the media. This observation argues for the possibility of a tardigrade death overestimation by the direct counting technique as we previously noticed in Fig 4A because a scoring of the living animals on the basis of their motility can also include living animals that do not move and can be scored as dead.\nFig 4D shows the tardigrade groups\u2019 viability at 6 days of incubation. As expected and in accordance with the results shown in Fig 1D, we were not able to detect any tardigrade survival for either 5 or 10 mM sodium azide incubation of tardigrade groups.\nDiscussion\nExperimental setups dedicated to tardigrade viability assessments can be time-consuming because of the need for direct scoring of living and dead animals. Such direct scoring of living tardigrades is critical for anhydrobiotic exit survival [22,23] or stress resistance assessments [2,24\u201326].\nIn this report, we assessed if an indirect measurement of tardigrade viability may help to discriminate between living and dead tardigrades. To do so, we used SYTOX green, a fluorescent dye that is believed to mark only dead cells [27,28] or death processes of few organisms [29\u201333] and is used for high content screening of molecules acting on animal survival [34]. The SYTOX green dye can bind DNA and become detectable by fluorescence only when the cell membrane of a cell or within an organism is corrupted. Because of this property, the SYTOX green dye can specifically mark the dead animals in a population.\nHere, we showed that the SYTOX green dye can be used as an alternative means of tardigrade viability quantification. Moreover, we monitored the toxicity induced by the SYTOX green and showed that this dye can be used up to 6 days for viability assessment without impairing tardigrade survival.\nEffective SYTOX green dye concentrations that have been previously reported vary between 1 and 5 \u03bcM for bacteria [29,30] and are up to 1 \u03bcM for phytoplankton [31], budding yeast [32] and Caenorhabditis elegans as well [34].\nIn this report, we assessed three different SYTOX green dye concentrations and found that 1 \u03bcM can be used without affecting the sensitivity of detection of dead animals in a tardigrade culture. This information is encouraging in consideration of experimental costs. We conclude that the direct observation of tardigrade survival may suffer from underestimation bias and may be greatly improved by the use of the SYTOX green fluorescent dye.\nWe hope that this new technique for tardigrade viability monitoring may help in the design of future experiments.\nMaterials and methods\nTardigrade handling and culture\nH. exemplaris tardigrades [35] were fed with the unicellular algae Chlorococcum sp.; both were purchased from Sciento Company (Manchester, UK) and maintained in culture at 15\xb0C on Chalkley\u2019s medium as previously described [20].\nSodium azide assay\nWe used sodium azide (NaN3), which is believed to inhibit the activity of mitochondrial cytochrome c oxidase (mitochondria complex IV) by binding metals containing oxygen at the reduction site of the enzyme [36,37]. Sodium azide also inhibits the ATP hydrolase activity of the F-ATPases but not their synthetic activity [38,39]. Groups of 20 adult tardigrade were randomly selected from cultures and disposed in Chalkley\u2019s medium for the control group or in NaN3 diluted in Chalkley\u2019s medium to a final concentration of either 5 or 10 mM. Tardigrade without apparent motility for at least 3 minutes after a stimulation by gentle plate soaking were scored as dead by a direct observation under brightfield illumination with a stereomicroscope. Dead animals were scored at either 1 hour, 24 hours, 48 hours or 6 days after sodium azide addition, and plates were stored at 15\xb0C during the experiment duration. Three independent experiments with groups of 20 animals were conducted for each condition. The animals\' death scoring was immediately followed by another check by another laboratory experimenter to verify the detection of dead tardigrades.\nSYTOX green assay\nWe used SYTOX green nucleic acid stain purchased from Molecular Probes (Oregon, USA) [40]. The SYTOX green dye is not fluorescent in aqueous solution and cannot cross either intact cell membranes or egg/embryo shells. When the cell membrane integrity is altered by cell or animal death, SYTOX green can then bind dsDNA, thereby increasing its fluorescence by a great order of magnitude (X1000) and allowing the detection of dead tardigrades by direct fluorescence at a wavelength of 523 nm. Groups of 20 tardigrades were transferred to 12-well plates. The wells were filled with  ml Chalkley\u2019s medium. SYTOX green was added to each well on the Chalkley\u2019s medium at a final concentration of either 0, , 1 or 10 \u03bcM, and the plates were then incubated at 15\xb0C. Scoring of the dead tardigrades was conducted under a fluorescence microscope at either 1 h, 24 h, 48 h or 6 days as previously described for sodium azide treatments (see previous section). Each experiment was repeated three times. The animals\' death scoring was immediately followed by another check by another laboratory experimenter to verify the detection of dead tardigrades.\nSodium azide assay using SYTOX green fluorescent dye\nAdults animals were selected randomly from tardigrade cultures. Groups of 20 animals were incubated in Chalkley\u2019s buffer as control media and in sodium azide-treated media by diluting sodium azide in Chalkley\u2019s buffer to a final concentration of 5 and 10 mM. Tardigrade were deposited on 12-well plates, and wells were supplemented with SYTOX Green at a final concentration of 0, , 1 or 10 \u03bcM in a final volume of  ml. Counting of living or dead animals was performed after two hours of incubation by a direct observation of their mobility, and photographs were taken at the same time. This operation was repeated 24 hours, 48 hours and one week later. Each sodium azide concentration assay was repeated at least three times.\nFluorescent microscopy\nMicroscopic observations were performed using a Leica stereomicroscope M205FCA with a TL3000 Ergo transmitted light base and a Leica DFC3000G camera. Observations and images were made with brightfield illumination, while we used a Leica GFP3 filter (Excitation: 470/440 nm, Emission: 525/550 nm) for the SYTOX green dye fluorescence observations and images. To count the living tardigrades, direct observations were made by verification of motile and non-motile animals under brightfield illumination. The detection of tardigrades associated with a death-linked fluorescence was performed under epifluorescence illumination. Images of both brightfield and SYTOX green fluorescence were taken with a Leica DFC3000G camera.\nStatistical analysis\nThe pairwise comparisons of the tardigrade death frequency were made using the Z-test with XLSTAT software (Addinsoft, New York, NY, USA).\nAcknowledgments\nWe thank the referees for their advice in evaluating the manuscript and their help in its improvement.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:21Z', 'description': u'by Max Eike Timm, Omid Majdani, Tobias Weller, Mayra Windeler, Thomas Lenarz, Andreas B\xfcchner, Rolf Benedikt Salcher\nObjectives The aim of this study was to identify anatomical indication ranges for different lateral wall cochlear implant electrodes to support surgeons in the preoperative preparation. Methods 272 patients who were implanted with a FLEX20, FLEX24, FLEX28, or a custom-made device (CMD) were included in this study. The cochlear duct length (CDL) and basal cochlear diameter (length A) were measured within preoperative imaging data. The parameter A was then employed to additionally compute CDL estimates using literature approaches. Moreover, the inserted electrode length (IEL) and insertion angle (IA) were measured in postoperative CT data. By combining the preoperative measurements with the IA data, the covered cochlea length (CCL) and relative cochlear coverage (CC) were determined for each cochlea. Results The measurements of the CDL show comparable results to previous studies. While CDL measurements and estimations cover similar ranges overall, severe deviations occur in individual cases. The electrode specific IEL and CCL are fairly consistent and increase with longer electrodes, but relatively wide ranges of electrode specific CC values were found due to the additional dependence on the respective CDL. Using the correlation of IEL and CCL across electrode arrays, CDL ranges for selected arrays were developed (FLEX24: \u2013, FLEX28: \u2013, FLEXSoft: \u2013). Conclusions Our analysis shows that electrode specific CC varies due to the CDL variation. Preoperative measurement of the CDL allows for an individualized implant length selection yielding optimized stimulation and a reduced risk of intraoperative trauma. The CDL, as derived from preoperative CT imaging studies, can help the implant surgeon select the appropriate electrode array to maximize the patient\u2019s outcomes.', 'title': u'Patient specific selection of lateral wall cochlear implant electrodes based on anatomical indication ranges', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206435', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Patient specific selection of lateral wall cochlear implant electrodes based on anatomical indication ranges\n\nFigures\nAbstract\nObjectives\nThe aim of this study was to identify anatomical indication ranges for different lateral wall cochlear implant electrodes to support surgeons in the preoperative preparation.\nMethods\n272 patients who were implanted with a FLEX20, FLEX24, FLEX28, or a custom-made device (CMD) were included in this study. The cochlear duct length (CDL) and basal cochlear diameter (length A) were measured within preoperative imaging data. The parameter A was then employed to additionally compute CDL estimates using literature approaches. Moreover, the inserted electrode length (IEL) and insertion angle (IA) were measured in postoperative CT data. By combining the preoperative measurements with the IA data, the covered cochlea length (CCL) and relative cochlear coverage (CC) were determined for each cochlea.\nResults\nThe measurements of the CDL show comparable results to previous studies. While CDL measurements and estimations cover similar ranges overall, severe deviations occur in individual cases. The electrode specific IEL and CCL are fairly consistent and increase with longer electrodes, but relatively wide ranges of electrode specific CC values were found due to the additional dependence on the respective CDL. Using the correlation of IEL and CCL across electrode arrays, CDL ranges for selected arrays were developed (FLEX24: \u2013, FLEX28: \u2013, FLEXSoft: \u2013).\nConclusions\nOur analysis shows that electrode specific CC varies due to the CDL variation. Preoperative measurement of the CDL allows for an individualized implant length selection yielding optimized stimulation and a reduced risk of intraoperative trauma. The CDL, as derived from preoperative CT imaging studies, can help the implant surgeon select the appropriate electrode array to maximize the patient\u2019s outcomes.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: This study was supported by the German ministry for research and education (BMBF) under FKZ 13GW0160B "my-CI" and MED-EL Deutschland GmbH. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. MedEl Deutschland GmbH paid for scientific congress charge, traveling and hotel costs for Max Eike Timm and Thomas Lenarz. No other author received specific funding for this work.\nCompeting interests: Company MedEl paid for one scientific congress charge, traveling and hotel costs for Max Eike Timm and Thomas Lenarz in the past (2017,2018). This does not alter our adherence to PLOS ONE policies on sharing data and materials.\nIntroduction\nCochlear implantation is a technology for patients with total, severe or frequency specific hearing loss which can restore the patient\u2019s ability to understand speech [1,2]. The cochlear implant (CI) works by directly stimulating the auditory nerve. This is accomplished by inserting a cochlear implant electrode array into the patient\u2019s cochlea. An electric field stimulus is then applied by a number of contacts distributed along the electrode array, targeting the spiral ganglion cells and auditory nerve fibers.\nFor cochlear implantation, various types of electrode arrays from different manufacturers are available. These electrode arrays differ in size, length, number of electrode contacts and material characteristics [3]. Prior to surgery, a decision must be made by the patient and physician on which electrode to implant. To do so, multiple factors must be taken into account including the residual hearing and medical history of the patient, which may include otosclerosis, patient preference as well as the length and shape of the cochlea. The cochlear length is known to have large variations [4\u201322]. Previous studies have shown that for patients who only hear with their CI, improved outcomes after CI surgery can be expected with longer electrode arrays and accordingly deeper insertion angles [23\u201325]. Other studies have shown that the insertion angle not only depends on the electrode array type but also on the length of the cochlea [26,27]. Furthermore, dysplasia and other syndromes exist which have an effect on cochlear geometry, especially regarding the length, shape and number of turns (. Mondini dysplasia) [28].\nDifferent methods are available for the evaluation of the cochlea duct length (CDL) and the depth of insertion within clinical imaging data of cochlea without malformation: one option is to manually trace the contour of the cochlea or electrode array and subsequently use spline interpolation to determine the corresponding length [15,29]. Other methods, which are based on mathematical correlations, use the basal diameter A (within a logarithmic equation) to estimate the cochlea or array length [30\u201332]. The benefit of the latter is that these types of estimates do not require special software tools but can be employed using common DICOM viewers. However, if these estimations are used for patient specific considerations on which CI array to use, the corresponding CDL values must be accurate and reliable. In order to address both the impact of cochlear length variations onto cochlear implant surgery as well as the reliability of popular literature approaches to assess this variability, the proposed study was conducted.\nBased on a large dataset of imaging data of CI patients, evaluations were performed on the distribution of CDL values, the correlation of electrode array length and the length of the cochlea covered by the respective array and suitability of specific CI arrays for certain ranges of CDL values. Following up on the study of Rivas et al. [33] who addressed the impact of A-value assessment deviations onto the electrode choice, it was further evaluated to which extent inaccuracies of the A-value method itself [30] would have led to a different choice of CI array than the respective contour tracings.\nMaterials and methods\nEthics statement\nThe ethics committee of the Hannover Medical School, Germany, approved this retrospective study. Due to the retrospective design, no written information was given to the patients of the study group. All patient data were anonymized and de-identified prior the retrospective analysis.\nSubjects\nAt the Hannover Medical School, pre- and postoperative imaging of all CI patients is obtained by either Cone Beam CT (CBCT) or standard CT scans. We performed a retrospective study of 272 preoperative imaging datasets of patients who were implanted with a MED-EL FLEX20, FLEX24 or FLEX28 electrode between 2006 and 2017. Postoperative scans were available in 259 of these cases. Furthermore, patients who received custom-made devices (CMD) of 16mm length as well as 16 mm partial insertions of FLEX24 and 20 mm insertions with the FLEX28 were evaluated. Partial insertions were performed in an attempt to preserve residual hearing which were all considered CMD for the purpose of data analysis. Within the overall study group, most patients were implanted with a MED-EL FLEX28 (165 patients), 46 patients with a FLEX24, 52 patients with a FLEX20 and 12 patients with a MED-EL Flex CMD (see Fig 1). In our practice, pre- and postoperative imaging are a routine part of clinical care analyses.\nImaging data analysis\nAll datasets were evaluated using the DICOM-Viewer OsiriX MD (version  64bit, Pixmeo SARL, Switzerland). The corresponding analysis included the following steps:\nTracings of the cochlear lateral wall from the center of the round window to the apex yield the corresponding CDL (see Figs 2 and 3)[15]. This is an automated feature within OsiriX MD. Performing one of these measurements takes approximately 2 minutes. An example is given in the supplementary material of this manuscript (see S1 Video).\nMeasurements of the basal turn diameter A as well as the cochlear angle (CA) (see Fig 4).\nMeasurement of the insertion angle (IA), defined as the angle from the center of the round window to the most apical contact (see Fig 5).\nTracings of the cochlear lateral wall in the preoperative scan (in order to avoid inaccuracies due to artifacts of the implanted array, see Fig 5) from the center of the round window to the insertion angle, yielding the covered cochlea length (CCL).\nMeasurement of the inserted electrode length (IEL) by placing marker points in the centers of all 12 electrode contacts as well as the entrance point of the electrode array in the round window (see Fig 5).\nComputation of the individual cochlear coverage (CC) in percent by dividing the corresponding CCL by the respective CDL.\n(A) Postoperatively, marker points were placed in the center of the round window and along the inserted electrode array in the middle of the respective contact artefacts, and the corresponding insertion angle was measured. (B) The latter value was then used within the corresponding preoperative imaging data to determine the length along the lateral wall up to the insertion angle.\nMeasurement data analysis\nAfter measurement data was acquired according to the methodology stated above, data analysis regarding the CDL and its estimation was performed in the following manner:\nEstimation of the cochlea length using the estimation method of Escud\xe9 et al. [30] by using A and the average CA value of 900 deg (or  turns):\nComparison of the measured CDL values derived by the lateral wall tracings and the ones estimated using the above equation.\nResults regarding the coverage of the cochlea with specific electrode arrays, corresponding anatomical indication ranges for each electrode array and clinically relevant evaluation errors were derived as follows:\nCorrelation of IEL and CCL in order to derive the relation between the length of the inserted electrode and the covered length of the cochlea.\nDetermining the CDL indication ranges for the different electrode arrays was based on (a) the previous correlation and (b) the manufacturer\u2019s recommendation of 80% cochlear coverage (CC) [34].\nEvaluating the accuracy of Escude\u2019s method in terms of estimated CDL values suggesting the same CI array indication as the corresponding lateral wall measurements.\nStatistical analysis\nThe data was statistically analyzed using IBM SPSS Statistics (Version ). To test whether a normal distribution exists we used the Kolmogorov-Smirnov test.\nResults\nAll measurement data can be found in S1 Table. Fig 6A and 6B show histograms of both measured and estimated CDLs of the 272 cochleae: In both cases a normal distribution was found with a mean length of  and standard deviations of  and  respectively. The actual deviations of measurements and estimations are shown in Fig 6C: while the general trend of estimations and measurements is in agreement (R2 = ), the mean absolute deviation was found to be at  +/- with a maximal deviation of .\nIn order to evaluate the clinical relevance of these deviations, the postoperative measurement data was included into the analysis. Note that no tip fold over could be observed in any of the reviewed cases. Fig 7A shows the derived IEL and CCL values in a boxplot, grouped by the respective electrode array type. Means and the standard deviations of the IEL for the different arrays are  +/- for the CMD group,  +/-  mm for the FLEX20,  +/-  mm for the FLEX24 and  +/-  for the FLEX28. Mean values and standard deviations of the CCL are slightly larger (about 2 mm on average) than the respective IEL values with  +/-  for the FLEX20,  +/-  for the FLEX24 and  +/- for the FLEX28. The mean CCL of the CMD group was found to be 17mm +/- . Taking the preoperatively measured CDL into account, the individual cochlear coverage (CC) of the lateral wall can be calculated as the ratio of CCL and CDL, which is shown in Fig 7B. The achieved mean CC is 56% +/-% for the FLEX20, % +/-% for the FLEX24 and % +/-% for the FLEX28. For the CMD devices a coverage of 46% +/- % was achieved. The CC variation for the longest electrode (FLEX28) ranged between % and % while it ranged from 58\u2013% for the FLEX24 and from \u2013% for the FLEX20.\nIn order to correlate IEL and CCL, a scatter plot of the two is given in Fig 8A. Linear regression of these data points yielded the following correlation function:\nThe red area within the graph indicates (based on the example of a FLEX28 electrode array) the CCL range which can be expected for a successfully implanted array, if successful insertion is assumed to lie within +/- 5% of the array length that is supposed to be implanted (. 28mm for a FLEX28 electrode array), the correlation function above can be employed to derive the corresponding CCL range. Table 1 shows the corresponding IEL and CCL ranges for different MED-EL electrode arrays suitable for patients without residual hearing. As mentioned before, the manufacturer recommends 80% CC (Mistr\xedk & Jolly, 2016). Thus, translating the CCL to a clinical indicated range can be accomplished by dividing the derived CCL ranges by . The corresponding indicated ranges for the different arrays are listed in Table 1 and depicted in Fig 8B. Note that the indicated range for the FLEX28 array matches the peak of the derived CDL distribution.\nSeveral publications refer to the CDL as the length of the organ of Corti (OC) and not the lateral wall. That is why the data of Hardy and Lee [5,31,35] was used to project the lateral wall indication ranges onto the organ of Corti (see Fig 9A). Linearly relating the CDL mean values +/- one standard deviation for lateral wall ( mm +/-  mm) and organ of Corti ( mm +/- mm) yielded the following equation:\nThis equation was used to translate the lateral wall indication ranges into the ones for organ of Corti, which are displayed in Fig 9B and stated within the last two rows of Table 1.\nFinally, we evaluated if CDL estimations using the A value and CA [30] could be used instead of actual measurements to derive an accurate anatomical indication for a specific array. Note that only the length of the cochlea and not the length of the implanted array were taken into account for this analysis. Using the FLEX28 implanted group we then analyzed to what extent the CDL estimation method would predict cochlear anatomies as too short, applicable or too long for this array. Within Fig 10A, the x-axis represents the measured CDL whereas the y-axis shows the corresponding estimations. The shaded areas within this graph represent the FLEX28 indication ranges for measured and estimated CDL values respectively (3rd column of Table 1). Correct identification, . a match of measured and estimated indication (highlighted in the table), of short cochleae could be achieved in %, of long cochleae in % and of matching cochleae in % of the cases (see Table 2 and Fig 10B).\nDiscussion\nIn our study, we analyzed the anatomy of the cochlea in 272 clinical imaging datasets. The postoperative location of different lateral wall electrode arrays could be assessed in 259 of these 272 cases. The derived variability of the cochlea length is in agreement with previous studies [4,5,15\u201317] and highlights again the importance of considering the patient specific anatomy in the field of cochlear implantation (see Fig 6A).\nThe projection of the wide portfolio of available electrode arrays [3] onto this range of cochlear length values then allows for optimal coverage of the intracochlear neural structures: achieving 80% CC with lateral wall electrodes in case of an average or long cochlea, for instance, would currently only be achievable with MED-EL devices who also offer electrode array lengths of more than 26mm. However, it was not yet clearly proven if electrode arrays stimulate the neural fiber endings at the organ of Corti or the spiral ganglion cells directly, . what cochlear coverage achieves the best possible speech perception. Nevertheless, recent publications show superior speech understanding for the FLEX28 array (which typically achieves insertion angles of 540\u2013720 degrees) in comparison to shorter electrode arrays [24]. The derived indication ranges yield a possible explanation for this finding, . the sufficient coverage of neural structures for most cochleae with the FLEX28 array.\nThe comparison of measured and estimated [30] CDLs showed normal distributions in either case with no significant differences, but quite severe deviations were found for individual cases (see Fig 6C) with deviations of up to . Hence, the CDL estimation method described by Escud\xe9 et al. [30] may be applicable for retrospective analysis but is not suitable for clinical use where accuracy matters for each and every individual case. This was further highlighted in Fig 10B where the estimation deviations were evaluated in terms of anatomical indications for specific CI electrode array lengths: the results show that in total, correct indications could only be derived in 66% of the analyzed cochleae. Especially concerning are the 11% of the cochleae whose CDL values were overestimated: in a clinical setting, overestimations could result in implantations of electrode arrays too long for a specific cochlea such that the array cannot be fully inserted and/or possibly cause intracochlear damage. Underestimations, on the other hand, were found to occur in 22% of the cases and could entail insufficient coverage of the cochlear neurons and hence result in poor speech understanding, since studies show that longer electrodes result in a better speech understanding for electric stimulation only [23,24].\nThe IEL and corresponding CCL values for the analyzed electrode arrays are shown in Fig 7A. CCL values are larger than the according IEL values for each electrode array due to the latter being located in closer proximity to the modiolus than the lateral wall and thus representing a shorter distance. The projection of the array from the modiolus out onto the lateral wall hence creates a larger spiral profile and an accordingly larger CCL value. The group of CMDs shows the highest deviation regarding the IEL to CCL correlation. This fact is owed to the CMD group containing FLEX24 and FLEX28 arrays which were only partially inserted (covering only the individual frequency region with severe to profound hearing loss) as well as custom made devices of 16mm length.\nWhile CC increases for longer electrodes overall (see Fig 7B), it can be seen that the CC distributions overlap especially regarding the FLEX24 and FLEX28 arrays. This can be explained by the fact that the CC is not only dependent on the length of the electrode array but also on the length of the cochlea [27]. In some cases, a FLEX24 in a short cochlea may therefore cover a larger fraction of the cochlea than a FLEX28 in a large cochlea. It should further be noted that the smallest CC values can be found within the FLEX20 group because this electrode was developed to not cover the full frequency range of the cochlea in order for patients to benefit from acoustic stimulation in the low frequencies using an EAS system.\nVariations in CC values generated with the same array can also be seen in Fig 8A. Although the overall cochlea length does not directly influence CCL values, it can be assumed that the same kind of array will be situated differently in a small cochlea than in a large one. Variations in cochlear anatomy are therefore likely to also influence the length of the cochlea covered by an electrode array.\nRegarding the anatomical indication ranges it was found based on the measured CDL that most cochleae are covered by the FLEX28 with a target CDL range of  to  (11+132+28 of the 271 cases corresponding to 63% of the analyzed cases). Without knowing the anatomy, a FLEX28 electrode also seems to be the best choice since it could be implanted in % (see Fig 11) of the cases with a reduced risk of harming any intracochlear structures.\nConclusion\nFollowing previous investigations, we showed that due to the variation of cochlear size, preoperative cochlea length assessment should be included into the routine preoperative care. Furthermore, individual implant selection based on the patient specific cochlea length is feasible and likely to improve implantation outcomes. However, length estimations exclusively based on mathematical correlations may result in false recommendations and could potentially injure the cochlea and lead to poorer outcomes. Furthermore, the presented results demonstrate that most cochleae are sufficiently covered by a FLEX28 electrode array while the FLEX24 and FLEXSoft should be employed for short and long cochleae respectively.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:24Z', 'description': u'by Kitae Kim, Young Ki Son, Su Mi Lee, Seong Eun Kim, Won Suk An\nBackground Guidelines recommend a break-in period of 2 weeks before starting peritoneal dialysis (PD), but PD within 14 days is also an acceptable and safe alternative to hemodialysis (HD) in patients with an urgent need. However, the effect of the break-in period within 48 hours or later had not been evaluated for early technical complications, long-term maintenance, and survival in patients starting urgent PD. Methods Of 360 patients with a surgically inserted PD catheter, we evaluated 190 patients who needed urgent PD and 29 patients who received conventional PD at a single center between January 2007 and December 2014 in this retrospective observational study. Enrolled patients were divided according to break-in period of <48 hours (P1) or 2\u201313 days (P2) before starting urgent PD. The primary endpoint was incidence of early technical complications and secondary endpoints included long-term PD maintenance, and patient survival. Results PD was started in 103 patients (%) within 48 hours and in 87 patients (%) within 2 to 13 days. The incidence of early technical complication was significantly higher in P1 group (%) than in P2 group (%) (P = ). The need for a repositioning procedure was significantly greater in P1 group (%) than in P2 group (%) (P = ). However, we observed no significant differences between the two groups with respect to the prevalence of catheter dysfunction requiring change to HD within 6 months or incidence of peritonitis or exit-site infection. There was no significant difference in PD maintenance and patient survival according to the break-in period between P1 and P2 as well as against the control group. Conclusion Urgent PD was associated with a low incidence of early technical complications if start was avoided within 48 hours after catheter insertion, and long-term PD maintenance was independent of the break-in period.', 'title': u'Early technical complications and long-term survival of urgent peritoneal dialysis according to break-in periods', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206426', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Early technical complications and long-term survival of urgent peritoneal dialysis according to break-in periods\n\nFigures\nAbstract\nBackground\nGuidelines recommend a break-in period of 2 weeks before starting peritoneal dialysis (PD), but PD within 14 days is also an acceptable and safe alternative to hemodialysis (HD) in patients with an urgent need. However, the effect of the break-in period within 48 hours or later had not been evaluated for early technical complications, long-term maintenance, and survival in patients starting urgent PD.\nMethods\nOf 360 patients with a surgically inserted PD catheter, we evaluated 190 patients who needed urgent PD and 29 patients who received conventional PD at a single center between January 2007 and December 2014 in this retrospective observational study. Enrolled patients were divided according to break-in period of <48 hours (P1) or 2\u201313 days (P2) before starting urgent PD. The primary endpoint was incidence of early technical complications and secondary endpoints included long-term PD maintenance, and patient survival.\nResults\nPD was started in 103 patients (%) within 48 hours and in 87 patients (%) within 2 to 13 days. The incidence of early technical complication was significantly higher in P1 group (%) than in P2 group (%) (P = ). The need for a repositioning procedure was significantly greater in P1 group (%) than in P2 group (%) (P = ). However, we observed no significant differences between the two groups with respect to the prevalence of catheter dysfunction requiring change to HD within 6 months or incidence of peritonitis or exit-site infection. There was no significant difference in PD maintenance and patient survival according to the break-in period between P1 and P2 as well as against the control group.\nConclusion\nUrgent PD was associated with a low incidence of early technical complications if start was avoided within 48 hours after catheter insertion, and long-term PD maintenance was independent of the break-in period.\nData Availability: All relevant data are within the manuscript and its Supporting Information files.\nFunding: This study was supported by research funds from Dong-A University.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nIt remains unclear whether peritoneal dialysis (PD) or hemodialysis (HD) is a better modality.[1, 2] HD has been preferred for its efficacy, rapid correction of metabolic and uremic abnormalities, and convenient vascular access. However, a higher mortality rate has been reported with HD through a central venous catheter compared with PD in patients aged 65 and over who required dialysis.[3] Recently, urgent PD has been introduced as a first-line renal replacement modality if vascular access for HD is not available.[4]\nUrgent PD was introduced as a feasible and safe therapeutic option. However, it is difficult to determine the safety margin of the break-in period as well as the ability of a patient to tolerate a period without dialysis. To determine the break-in period for those in need of urgent PD requires comparison of the risks and benefits of early initiation of PD. In addition, PD maintenance associated with a shorter break-in period should be considered before selecting the dialysis modality. However, there are few reports on break-in periods shorter than 7 days, and there is a lack of data on associated long-term PD survival or transition to HD.[4\u20139]\nAccordingly, we investigated the effect of break-in periods of \u226448 hours, with an emphasis on early technical complications, long-term maintenance, and survival in patients starting PD.\nMaterials and methods\nStudy design and patients\nThis retrospective study evaluated 360 patients at a single center, Dong-A University Hospital in Korea, between January 2007 and December 2014. All patients had PD catheters implanted by experienced general surgeons using a midline or vertical incision under local anesthesia. PD catheter implantations were exclusively performed by two general surgeons and conducted by surgical method. The two surgeons had similar surgical experiences and shared the techniques. Among 360 patients, 67 patients who underwent emergent HD via femoral or jugular venous catheter placement before PD catheter insertion were excluded. These 67 patients should be treated with emergent HD and could not wait for 48 hours till PD catheter insertion.\nWe analyzed the data on those who started PD as a first-line dialysis modality and divided the patients into 3 groups based on the break-in period. PD was started in 129 patients within 48 hours after catheter insertion, 135 initiated PD in 2 to 13 days, and 29 started PD after 14 days or more (Fig 1). Among these, patients (n = 72) in whom urgent PD was not indicated (unmet criteria for urgent PD described below, n = 70) and experienced surgical complication related with PD catheter insertion (patients experienced bleeding, leakage and malposition without PD start, n = 2) were excluded. All of them started PD within 13 days after catheter insertion. Finally, 190 PD patients who needed urgent dialysis were included and divided into 2 groups: those who started PD within 48 hours after catheter insertion (P1 group, n = 103) and those who started within 2\u201313 days (P2 group, n = 87). Conventional PD was defined as the initiation of dialysis after 14 days of catheter insertion[10]. A total of 29 conventional PD patients were enrolled as controls.\nThis study was approved by the Dong-A University Institutional Review Board. Informed consent was waived because the study is of a retrospective design. The data including patient records and information was anonymized and de-identified prior to analysis. All clinical investigations were performed in accordance with the Declaration of Helsinki.\nIf patients require urgent PD, the protocols of Dong-A University Hospital are as follows. Irrigation is performed 2\u20133 times immediately after catheter placement, using 500 mL dialysis solution. PD is started with 500 mL every 2\u20133 hours, 2\u20136 times over the following 2 days. PD volume is gradually increased to 750\u20131,000 mL over the next 5 days, according to the required dialysis dose. We increase the volume to 1,000\u20132,000 mL within 14 days, at the discretion of the physician. All patients remain supine, with minimal ambulation during the first 3 days. Initially, all patients used a lactate buffered PD solution containing % glucose concentrations (Baxter Healthcare Corporation, Deerfield, IL, USA, or Frensenius Medical Care, Bad Homburg, Germany).\nTechnical complications and survival\nThe primary endpoint was defined as the incidence of catheter-related technical complications, such as malposition, peri-catheter leakage, omental wrapping, catheter obstruction, and the need for surgical intervention within 6 months after initiating PD. For cases who were failed conservative management to PD related complication such as sudden malposition and catheter obstruction sign, we performed laparoscopic surgical intervention and omental wrapping was diagnosed. The secondary end-point was the incidence of peritonitis, transfer to HD due to PD-related complications, late (after 6 months) catheter complications, PD survival, and overall survival.\nStatistical analysis\nThe data were expressed as a mean \xb1 SD, median value, or frequency. Subject characteristics were analyzed using Student\u2019s t-test for continuous variables. A Chi-squared test was used to compare categorical data between the two groups. To identify peritonitis-free survival, technical survival, and patient survival in the two groups, Kaplan-Meier analysis and log-rank tests were performed. A P value < was considered statistically significant, and statistical calculations were performed with SPSS software (SPSS version , Chicago, IL, USA).\nResults\nPatient characteristics\nBaseline characteristics and demographic data of urgent PD groups are shown in Table 1. Mean age, sex, and prevalence of diabetes mellitus (DM) were not significantly different between the P1 group and P2 group. In addition, there were no significant differences in age, sex, and prevalence of DM between urgent and conventional PD groups. There were no significant differences in baseline laboratory data between P1 and P2 groups. However, BUN and creatinine levels were significantly higher and serum albumin level was significantly lower in the urgent PD group compared with the conventional PD group. There were no significant differences in baseline potassium, calcium, phosphorus, hemoglobin, and glycated hemoglobin levels between P1, P2, and conventional PD groups.\nEarly technical complications\nIn both P1 and P2 groups, 38 patients had catheter-related technical complications within 6 months. A higher incidence of early technical complication was noted in the P1 group compared to the P2 group (P = ). However P2 group had an incidence similar to that of the conventional PD group (Table 2). In particular, malposition (% vs. %) and omental wrapping (% vs. %, P = ), which required surgical repositioning of the of PD catheter, were noted more frequently in the P1 group compared to the P2 group. In addition, significantly more cases required surgical intervention during the overall PD period in the P1 group compared to the P2 group. However, catheter obstruction, peri-catheter leakage, and the number of transfers to HD were not significantly different. The incidence of PD peritonitis within 6 months was not different according to the break-in period.\nLong-term complications and PD survival\nThe incidence of technical complication over the entire duration of PD in the P1 group was also greater than in the P2 group. However, there were no differences in drop-out rate due to transfer to HD, kidney transplantation, or death among the three groups. Overall cumulative PD survival showed similar Kaplan-Meier curves between P1 and P2 groups (log-rank, P = ) (Fig 2). There were no differences in cumulative PD survival between the urgent PD groups and the conventional PD group (log-rank, P = ).\nDiscussions\nThis retrospective study found that urgent PD initiated within 2 to 13 days, ., with an average 6-day break-in period, was safe without serious complications. In addition, early technical complications and long-term PD survival, including PD maintenance and patient survival, were not different between urgent PD groups and the conventional PD group with a 2-week break-in period. However, the urgent PD group with \u2264 48 hours break-in period had a higher risk of early technical complications such as malposition and omental wrapping compared to the group with a 2 to 13 days break-in period. Acutely started PD within 24 hours showed a higher rate of mechanical complications compared to that in planned start PD with break-in periods >12 days in a previous retrospective study.[11] Therefore, we suggest that urgent PD can be relatively safe, with reduced incidence of early technical complications, when initiated 48 hours after PD catheter insertion. Our data suggested that a minimum 48-hour break-in period might be a milestone in the prevention of early technical complications. However, physicians should monitor patients to determine the ability to tolerate 48 hours without PD after catheter insertion. It is much safer to wait 6 days after catheter insertion to start low-volume (500 ml) PD solution and to allow enough time to achieve full volumes based on our study. Our methods were similar to those using automated PD or continuous ambulatory PD (CAPD) following acute renal failure, and cannot only reduce the occurrence of technical complications by using small volumes of dialysate, but also effectively remove overhydrated fluid and small solutes and electrolytes, especially potassium, through a short dwell time and rapid cycling within the first 24 hours.[11, 12]\nEmergent PD defined as dialysis therapy could not be delayed for 48 hours. Therefore, PD catheter was inserted and PD was started within 48 hours in emergent cases. Urgent PD defined as requiring dialysis in less than 2 weeks but able to delay PD catheter insertion for more than 48 hours, with medical treatment alone. [4] Several guidelines recommend waiting at least 14 days after implantation of a PD catheter, if possible, to prevent bleeding or catheter leakage.[10, 13] However, it is difficult to wait 14 days, because treatment with medical therapy alone may be harmful to patients. In these situations, we recommend starting urgent PD without waiting 14 days, and deferring consideration of HD catheter insertion. Urgent PD is now an accepted modality, especially in patients who are appropriate candidates for PD as renal replacement therapy.[4, 14] However, physicians should select central venous catheter insertion for emergent HD in patients who cannot wait 48 hours till PD catheter insertion. If patients can wait at least 4 days (2 days waiting for PD catheter insertion plus 2 days break-in periods for urgent PD start, to reduce early technical complications), urgent PD is safe, and can achieve long-term PD and patient survival, based on our study. From these encouraging results, PD can be useful in cases needing urgent dialysis therapy.\nAmong early complications, malposition of the PD catheter, with the catheter tip located outside of the true pelvis on a simple abdominal X-ray, can worsen with immobilization due to surgical site pain or decreased bowel motility and constipation. When patients start urgent PD within 48 hours after catheter insertion, using a laxative to initiate bowel motility may be one option for prevention of malposition. Use of a laxative and ambulation may be helpful for repositioning of the catheter if malposition has occurred.[15] If conservative measures fail, laparoscopic repositioning or omentectomy should be performed.[12, 15\u201317] In spite of an increase in early technical complications, the P1 group also showed a longer duration of PD maintenance compared to the P2 group. This result might be influenced by proper timing of surgical intervention. A previous study suggested that laparoscopic internal fixation was associated with reduced catheter migration as well as maintenance of PD.[16] We performed laparoscopic internal fixation and omentectomy for correction of malposition caused by omental wrapping in this study. Although a previous study reported that the risks of malposition or omental wrapping after PD catheter insertion were associated with DM, younger age, serum albumin and use of a straight catheter, our data showed no significant differences.[18, 19] However, PD start within 5 days after PD catheter insertion and a previous history of abdominal surgery were associated with technical complications such as malposition or omental wrapping. These reports were in keeping with our findings showing an association between shorter break-in time and malposition. Simultaneous preventive laparoscopic PD catheter insertion and internal fixation may be considered if patients have a high likelihood of needing PD within 48 hours after catheter insertion.\nLeakage is a major concern when starting PD urgently without a 2-4-week healing period.[20, 21] Ghaffari et al. reported higher frequency of leakage in urgent-start PD group than in non-urgent-start PD group.[4] However, most leaks were minor and managed with less effort except for 2 cases (%).[4] Early dialysate leakage is defined as occurring within 30 days after insertion, and is usually associated with catheter implantation at the exit or incision site. Higher risk for dialysate leakage was reported with a midline incision compared with a paramedian incision, as well as with dialysate volume >500 ml and PD initiation within 10 to 14 days after implantation.[20] To minimize the occurrence of peritoneal leaks, Jo et al. reported use of a modified percutaneous catheter implantation technique, as in CAPD, and started dialysis immediately after catheter insertion with 500 ml of low-volume dialysate every 3 hours for the first 3 days.[9] They reported peritoneal leakage in only one case. Yang et al. also reported use of low-volume dialysate as described above, in an early-start PD group, with initiation of dialysis within 14 days after catheter insertion, with dwell volume of 750 ml and more than 4 cycles in a day, depending on uremic symptoms.[7] The dwell volume was gradually increased to 1,500 ml at 12 days after break-in, if no complications were noted during the incremental process. They compared the results in a late group that initiated dialysis 12 days after catheter insertion, and found no association between shorter break-in time and peritoneal leaks. Our study showed a similar incidence of leakage according to the break-in period in urgent PD groups using low initial dwell volume. Therefore, leakage may not be a major concern in urgent PD if patients can be managed using low initial dwell volume.\nThis study had some limitations. First, the design of this study was retrospective. Second, the number of control group with break-in period as guideline recommended is too small.\nConclusions\nIn conclusion, initiating urgent PD within 2 to 13 days after catheter insertion may prevent early technical complications such as obstruction and malpositioning requiring surgical intervention, compared to the outcomes with a \u226448-hour break-in period. In addition, compared to conventional PD, urgent PD showed similar long-term maintenance, regardless of the break-in period.\n4.\nGhaffari A. Urgent-start peritoneal dialysis: a quality improvement report. American journal of kidney diseases: the official journal of the National Kidney Foundation. 2012;59(3):400\u20138. pmid:22019332', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:26Z', 'description': u'by Marta Rodr\xedguez-Arias, Sandra Montagud-Romero, Ana Mar\xeda Guardia Carri\xf3n, Carmen Ferrer-P\xe9rez, Ana P\xe9rez-Villalba, Eva Marco, Meritxell L\xf3pez Gallardo, Mar\xeda-Paz Viveros, Jos\xe9 Mi\xf1arro\n\nThe experience of social stress during adolescence is associated with higher vulnerability to drug use. Increases in the acquisition of cocaine self-administration, in the escalation of cocaine-seeking behavior, and in the conditioned rewarding effects of cocaine have been observed in rodents exposed to repeated social defeat (RSD). In addition, prolonged or severe stress induces a proinflammatory state with microglial activation and increased cytokine production. The aim of the present work was to describe the long-term effects induced by RSD during adolescence on the neuroinflammatory response and synaptic structure by evaluating different glial and neuronal markers. In addition to an increase in the conditioned rewarding effects of cocaine, our results showed that RSD in adolescence produced inflammatory reactivity in microglia that is prolonged into adulthood, affecting astrocytes and neurons of two reward-processing areas of the brain (the prelimbic cortex, and the nucleus accumbens core). Considered as a whole these results suggest that social stress experience modulates vulnerability to suffer a loss of glia-supporting functions and neuronal functional synaptic density due to drug consumption in later life.', 'title': u'Social stress during adolescence activates long-term microglia inflammation insult in reward processing nuclei', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206421', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Social stress during adolescence activates long-term microglia inflammation insult in reward processing nuclei\n\nFigures\nAbstract\nThe experience of social stress during adolescence is associated with higher vulnerability to drug use. Increases in the acquisition of cocaine self-administration, in the escalation of cocaine-seeking behavior, and in the conditioned rewarding effects of cocaine have been observed in rodents exposed to repeated social defeat (RSD). In addition, prolonged or severe stress induces a proinflammatory state with microglial activation and increased cytokine production. The aim of the present work was to describe the long-term effects induced by RSD during adolescence on the neuroinflammatory response and synaptic structure by evaluating different glial and neuronal markers. In addition to an increase in the conditioned rewarding effects of cocaine, our results showed that RSD in adolescence produced inflammatory reactivity in microglia that is prolonged into adulthood, affecting astrocytes and neurons of two reward-processing areas of the brain (the prelimbic cortex, and the nucleus accumbens core). Considered as a whole these results suggest that social stress experience modulates vulnerability to suffer a loss of glia-supporting functions and neuronal functional synaptic density due to drug consumption in later life.\nData Availability: All relevant data are within the manuscript and its Supporting Information files.\nFunding: This work was supported by Ministerio de Econom\xeda y Competitividad (MINECO), Direcci\xf3n General de Investigaci\xf3n, PSI2014-51847-R to JM and PSI 2017-83023-R to MR; Instituto de Salud Carlos III, Red de Trastornos Adictivos (RTA) (RETICS RD2012/0028/0021 to MPV; RD16/0017/0007 to JM) and Uni\xf3n Europea, Fondos FEDER "A way to build Europe"; GRUPOS UCM-BSCH 951579 to MPV. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nSubstance abuse and addiction are complex processes in which stress plays a critical role [1, 2, 3, 4, 5]. Addiction and stress responses share a common neurobiological pathway which can be modified by environmental stressors [6, 7]. Vulnerability to relapse into drug-seeking following a stress-producing experience, even after long periods of abstinence, highlight the power of stress-induced neurobiological modifications [8]. The plasticity of the adolescent brain may be one of the main factors involved in the elevated percentage of drug use initiation and rapid development of addiction disorders in this period of life [9]. During adolescence, the prefrontal cortex and limbic regions undergo a maturation process characterized by myelination and competitive synaptic elimination [10, 11]. The immaturity of the frontal cortex circuitry revealed by neuroimaging studies partially explains why teens are more responsive to rewarding experiences and experience them positively over any negative attribution [12, 13]. The adolescent brain is characterized by a pro-motivational state; this is the result of a limited inhibitory capacity, high dopamine release in the nucleus accumbens (NAc) when processing positive stimuli, and an overactive amygdala [14].\nThe risk of developing psychological disorders such as depression and anxiety and increased vulnerability to drug use can be attributed to the experience of social stress during adolescence [15,16]. Exploring the mechanisms by which social stress affects health requires appropriate animal models. The rodent social defeat model has been widely employed in this sense, and numerous studies using this model have provided knowledge of the neurobiology and behavioral changes related to this type of stress [17, 18]. The procedure for inducing social defeat is based on the resident/intruder paradigm in which the intruder animal is placed in the cage of a resident/aggressive rodent that attacks and threatens it. These agonistic interactions promote the development of dominance-based social hierarchies [19]. The repeated social defeat (RSD) model is a putative model of bullying with face validity [20, 21] that induces strong physiological, behavioral and endocrine responses [22, 23, 24, 25].\nResearch has repeatedly shown that social defeat induces an increase in the rewarding effects of cocaine. Defeated animals show higher acquisition and maintenance of cocaine self-administration [26, 27, 28] and quicker escalation of cocaine-seeking behavior [29, 30, 31, 32]. In addition, social defeat increases conditioned place preference (CPP) induced by cocaine [33, 34, 35, 36, 37, 38]. We have previously reported that experienced social defeat during adolescence also augments the conditioned rewarding effects of cocaine in adult animals and modifies cocaine self-administration [22, 23].\nThere is an effective communication between the peripheral immune system and the central nervous system (CNS), and, in this context, chronic or intense stress experiences can induce a proinflammatory state [39]. In fact, stress-related psychiatric disorders are hypothesized to be due to this proinflammatory state in the CNS [40]. Human and animal studies show that immune mediators are able to influence the way the brain processes information and responds to it [41]. One example is the relationship of neuroinflammation with the pathophysiology of depression, which has been deeply studied (review on [42]). Peripheral inflammatory responses can access the brain, contributing to the increase in neurotoxic kynurenine pathway metabolites and the decrease in neuroprotective metabolites. Activated microglia released glutamate join to the kynurenine metabolites that stimulates the N-methyl- D -aspartate (NMDA) receptors. In addition, inflammatory mediators can also downregulate dopaminergic neurotransmission via oxidative stress and mitochondrial dysfunction. Activation of NMDA receptors and deficient dopaminergic neurotransmission both result in depression symptoms. Proinflammatory cytokines can also exert direct neurotoxic effects on specific brain regions [43]. Previous imaging studies have reported associations between proinflammatory states and alterations in brain regions involved in emotional regulation, including the hippocampus, the amygdala and the anterior cingulate cortex [44]. In addition to these effects, cytokines are expressed in the CNS constitutionality and serve as important plasticity factors in the formation and stabilization of neuronal circuits during development [43]. Numerous studies have shown that RSD induces microglial activation and increased cytokine production [45, 46].\nResearch into stress induced-neuroinflammation needs to address how long these changes endure in the brain. For example, anxiety-like behavior induced by RSD can be observed immediately after the last defeat and persists for a week, but seems to vanish 3 weeks later, temporally correlating with the neuroinflammatory response [47]. Conversely to these results, we and other authors have repeatedly shown that sensitivity to the rewarding effects of cocaine continues to be increased one month after the last social defeat [22, 23, 37, 48, 49], regardless of the age at which social defeat is experienced. Changes in the blood brain barrier (BBB) structure after an experience of RSD during adolescence are also observed one month after the last encounter. The NAc and hippocampus of defeated adult mice display reductions in the expression of claudin-5 (a tight junction protein) and a higher degradation of basal laminin (decrease in laminin and collagen-IV expression) [22]. Other studies have linked disruption of the integrity of the BBB [50, 51] to increased levels of proinflammatory cytokines [52] or free radical formation [53].\nNeuronal-supporting glia like astrocytes and microglia play a critical role in maintaining the BBB. Microglia are immune cells resident in the CNS and are sensitive and reactive to disruption of homeostasis [54, 55, 56]. The resting phenotype, observed in basal/healthy conditions, is characterized by a ramified morphology with a small round soma. However, in response to harmful stimuli, microglia change their shape towards an amoeboid structure with a reduction of processes length, and short-term proliferation reactivity [57, 58, 59]. The ionized calcium binding adaptor molecule 1 (Iba1), expressed in reactive and quiescent cells, has been widely used as a protein marker of microglia [60]. Both classic inflammatory stimuli and psychological stress have been shown to induce changes in microglia [61, 62, 63, 64]. However, stress-related studies have taken measurements a short time after stress exposure, and so little is known about how microglia reactivity might be maintained in the long-term.\nThe correct functionality of the BBB requires astrocytes, which secrete factors that promote a tight association between the cells [65]. As both astrocytes and microglia are highly sensitive to inflammatory signals produced by stress, a strong impact could have long-lasting consequences that persist with age and consistently affect neuronal survival [66, 67, 68]. Synaptophysin is considered the most important glycolipid protein in the structure of vesicle membranes in the axon terminal [69], and it is a molecular indicator of synaptic density. Decreased levels of synaptophysin is related to loss of synaptic contacts and are associated with functional deficit, while increased levels are related to synaptic plasticity and structural changes [70].\nThe aim of the present work was to describe the long-term effects induced by RSD during adolescence on the neuroinflammatory response and synaptic structure by evaluating different glial and neuronal markers. We hypothesized that social stress experience during adolescence will induced a neuroinflammatory response that can account for the increased observed in the rewarding effects of cocaine. Our results confirm that, when experienced in adolescence, RSD produces inflammatory reactivity in microglia that is prolonged into adulthood, seriously affecting the astrocytes and neurons of two reward-processing areas of the brain: the PrL and the NAc.\nMaterial and methods\nAnimals\nA total number of 104 OF1 male mice (Charles River, Barcelona, Spain) were used in this study. The experimental mice (n = 84) arrived at the laboratory at 21 days of age and were housed under standard conditions in groups of four in plastic cages (27\xd727\xd714 cm) during the entire experimental procedure. Mice employed as aggressive opponents (N = 20) were housed individually in plastic cages (21 \xd7 32 \xd7 20 cm) for a month before the start of the experiments with the purpose of heightening their aggression [71]. The housing conditions were as follows: constant temperature; a reversed light schedule (white light on 8:00 to 20:00); and food and water accessible ad libitum, except during behavioral tests. The experimental protocol has been approved by an Institutional Review Committee for the use of animal subjects (Comit\xe9 d\'\xc8tica d\'Experimentaci\xf3 i Benestar Animal). Procedures involving mice and their care were conducted according to national, regional and local laws and regulations, which are in compliance with the Directive 2010/63/EU. All the efforts were made to minimize animal suffering and to reduce the number of animals used.\nDrugs\nFor cocaine treatment 1 or 25 mg/kg of cocaine hydrochloride (Alcaliber laboratory, Madrid) were used. The low dose of cocaine was selected on the basis of previous CPP studies showing that 1 mg/kg is a threshold dose [72, 73, 74] that has rewarding effects depending on the state of the mouse\u2019s brain reward system. The dose of 25 mg/kg is an effective rewarding dose which shows reinstatement of the extinguished preference with a priming dose of  mg/kg of cocaine [75]. All treatments were adjusted in a volume of /g of weight. Control groups were injected with physiological saline (NaCl %), which was also used to dissolve the drugs.\nExperimental design\nTwo different sets of mice were employed in this study: 54 mice underwent the CPP procedure and 30 mice received the same pharmacological treatment and were employed to obtain brain samples. The total sample of 84 experimental mice was divided into six experimental groups according to the stress condition (exploration vs social defeat) and the cocaine dose used during cocaine treatment (saline, 1 mg/kg and 25 mg/kg). Social defeat or exploration began on PND 26 to 35 and the CPP procedure (PND 53\u201364) or cocaine treatment (PND 60\u201363) was initiated three weeks after the last social defeat. Brain samples were obtained one day after the last cocaine or saline injection on PND 63. A detailed outline of the experimental procedure is provided in Table 1.\nApparatus and procedures\nRepeated social defeat encounters.\nWe exposed animals in the RSD groups to 4 episodes of social defeat lasting 25 min each. The episodes consisted of 3 phases that began by placing the animal or intruder in the aggressive opponent\u2019s or resident\u2019s home cage for 10 min. During this initial phase, the intruder was kept safe from attack by a see-through wire mesh wall that allowed for social interactions and species-typical threats from the male aggressive resident [76]. In the second phase, the wire mesh was removed and a 5-min period of confrontation followed. In the third phase, the wire mesh was put back in place for a further 10 minutes to allow the resident to make social threats. Adolescent mice were exposed to social defeat on postnatal day (PND) 27, 30, 33 and 36, and adult mice on PND 47, 50, 53 and 56. The same protocol was used for the exploration groups but without a "resident" mouse in the cage. Following this last phase, the mice remained in the animal facility for three weeks, after which time the behavioral tests began. The second phase of each social defeat protocol was video-recorded and ethologically analyzed. Behaviors relating to threat and attack were scored in resident mice and behaviors relating to avoidance/flee and defensive/submissive were evaluated in intruder mice.\nConditioned place preference (CPP).\nFor place conditioning, eight identical Plexiglas boxes were employed with two equally-sized compartments ( cm long \xd7  cm wide \xd7  cm high), which were divided by a gray central area ( cm long \xd7  cm wide \xd7  cm high). The compartments had contrasting colored walls (black vs white) and different floor textures (fine grid for the black compartment and wide grid for the white one). The animals\u2019 positions and their crossings from compartment to compartment were recorded by means of four infrared light beams in each compartment of the box and six in the central area. The equipment was controlled by three IBM PC computers using MONPRE 2Z software (CIBERTEC, ., Spain).\nPlace conditioning, which consisted of three phases, was carried out during the dark on 3 consecutive days. On day 3, the time spent in each compartment was recorded. This procedure was carried out during the dark cycle following a procedure that was unbiased in terms of initial spontaneous preference [77]. During the first phase\u2014or preconditioning (Pre-C)\u2014mice had access to both compartments of the apparatus for a period of 900 s per day. The animals that showed a strong unconditioned aversion (less than 33% of the session time; . 250 s) or preference (over 67% of the session time; . 650s) for any compartment were excluded for the remainder of the study. In each group, half of the animals received the drug or vehicle in one compartment and the other half in the other compartment. An ANOVA showed there was no significant difference between the time spent in the drug-associated and the vehicle-associated compartments during the Pre-C phase. In the second phase (conditioning, 4 days), animals were conditioned with either cocaine or saline. The mice were then administered an injection of physiological saline before being confined to the vehicle-associated compartment for 30 min. After 4 hours, the animals received cocaine immediately before an extra 30 minutes of confinement in the drug-associated compartment. The central area was rendered inaccessible by guillotine doors during conditioning. In the third phase\u2014or postconditioning (Post-C)\u2014which took place on day 8, the guillotine doors dividing the two compartments were lifted, and the time that the untreated mice spent in each compartment was recorded during a 900 s observation period. The difference in seconds between the time spent in the drug-associated compartment during the Post-C and Pre-C tests is a measure of the degree of conditioning induced by the drug. If this difference is positive, the drug has prompted a preference for the drug-associated compartment, while the opposite indicates an aversion.\nTissue sampling.\nOn PND 63, mice were anesthetized with a mixture of medetomidine (Domtor, Esteve Veterinaria) and ketamine hydrochloride (Ketolar, Pfizer). They were then transcardially perfused with physiological saline % at 4\xb0C followed by 4% paraformaldehyde (PFA, Merck) in phosphate buffer (PB,  M, ). The brains were removed and post-fixed in PFA 4% for 48h at 4\xb0C and were then washed in PB (, pH ). They were washed a further three times, for 30 min each time, in PB ( M, pH ), and cryoprotected in 11% sucrose in phosphate buffer saline (PBS,  M, pH ) at 4\xb0C for 48 h, after which they were transferred to PBS containing 33% sucrose and conserved at 4\xb0C for 48 h. Finally, samples were frozen and kept at -30\xb0C until further use.\nFor immunostaining techniques brains were frozen sectioned into coronal sections of 25 \u03bcm using a cryostat microtome (CM-3050, Leica, Germany). Tissue sections were collected in gelatin-coated slides (4 slices per slide), air dried and stored at -30\xb0C.\nSlides immunostained for GFAP, Iba1, NeuN, and Sinaptophysin were observed in a Zeiss Axio-Imager 2. Images where captured with the same adjustments of contrast and brightness with a Zeiss Axiocam Camera and processed using Axiovision 40 V  software (Carl Zeiss vision GMBH).\nQuantitative analysis\nAll quantification analyses of NeuN, GFAP, synaptophysin and Iba1+ cells were performed in the prelimbic cortex (PrL) and nucleus accumbens core (NAc), with high resolution digital micrographs captured under the 20x or 10x magnification objective. Neuroanatomical sites were identified with the Paxinos and Franklin mouse brain atlas [78], the anterior-posterior localization from Bregma of the analyzed areas was: PrL, 1,98\u20131,54 mm; NAc core, 1,42\u20130,74 mm. Slices count areas were calculated in mMC (426 x  mm for 20 magnification and  x  mm for 10x) and immunopositive cell count was expressed as number of cells/mMC for the quantification of the number of GFAP+ cells and each of the morphological types of Iba1+ cells. The densitometric studies were performed for the quantification of total Iba1+, NeuN and synaptophysin + cells, by measuring the optical density (OD) of the selected area with the software Image J (NIH, USA). We measured the total OD and subtracted the OD of the unmarked tissue, results were express as optical density (arbitrary units).\nQuantification GFAP+.\nTo investigate whether RSD affects astrocytes in mice, we analyzed the expression of glial fibrillary acidic protein (GFAP). This cytoskeletal protein is a general marker of mature astrocytes in the brain, except in neurogenic niches, where it is expressed by neural stem cells that are differentiated from mature astrocytes by the negative expression of S100\u03b2 [79, 80]. Presence was determined by counting the number of immunoreactive GFAP cells in a whole area of the sections pictured at 20X magnification. Results are expressed as number of positive GFAP+/mm2.\nDensitometry and morphology of Iba1+.\nMicroglial response was evaluated by quantification of Iba1+ cells, a calcium-binding protein specifically expressed in microglia [81]. We also evaluated changes in microglial morphology, since the resting phenotype is characterized by a ramified morphology with a small round soma, but microglia changes to an amoeboid structure in response to harmful stimuli [55, 58]. Immunoreactive cells were densitometered in a selected area of the sections pictured at 20X magnification. Microglia morphology analysis was performed according to established morphological criteria. Cells were classified in five morphological types [82]: type I, cells with few cellular processes (two or less); type II, cells showing three to five processes; type III, cells with more than 5 processes and a small cell body; type IV, cells with large somas and retracted and thicker processes; and type V, cells with amoeboid cell body, numerous short processes and intense Iba1+ immunostaining. Iba1+-immunoreactive cells types III, IV and type V were counted together.\nDensitometry of NeuN and synaptophysin.\nWe identified neurons with the nuclear antigen NeuN and the synaptic protein synaptophysin. NeuN immunoreactivity is considered a neuronal marker, and weak NeuN immunostaining is associated with vulnerability and neuronal loss [83, 84]. Immunoreactive NeuN+ densitometry was recorded with micrographs taken with a 20X magnification objective, while anti-CB1 and anti- synaptophysin was performed with a 10X magnification objective.\nStatistical analyses\nStatistical significance for immunoreactivity expression, for the morphotype Iba1+ and for the CPP data (difference of time spent in the drug-paired compartment in Post-C vs. Pre-C tests) was determined by a mixed two-way ANOVA with two between-subjects variables\u2014Stress, with two levels (RSD and EXP), and cocaine treatment, with three levels (Saline, C1, C25). Prior to this, the Shapiro-Wilk normality test and Levene homoscedasticity test were performed to analyze the data obtained for immunoreactivity expression and the morphotype Iba1+, which were transformed to satisfy the normality assumption for the ANOVA. Post hoc comparisons were performed with Bonferroni tests. The value of the effect size was evaluated by the partial square ETA. The results are reported as mean \xb1 . All Statistical analyses were performed using the SPSS  software package (SPSS Inc., Chicago, IL, USA).\nNext, we quantified the number of microglia and their degree of reactivity in two key structures (NAc and PrL cortex) that process the rewarding effects of cocaine: PrL and NAc. ANOVA of Iba1+ quantification in the PrL showed a significant effect of the variable Stress (F 2,24 = ; p< ), where Iba1+ expression was decreased in all socially defeated groups (Fig 1B, 1C and 1D).\nMicroglia phenotype was characterized in an inflammatory gradient scale from M1 (less inflammatory response) to M5 (more inflammatory response). M3-M5 were considered reactive microglia (Fig 2A). When this parameter was analyzed with ANOVA, a significant interaction was detected between Stress X Cocaine (F2,24 = ; p<) in PrL. RSD mice treated with saline displayed a larger number of Iba1+ cells of M3, M4 and M5 morphotypes than animals also treated with saline but which did not experience stress during adolescence (p< ) (Fig 2B). In addition to this, the highest dose of cocaine produced an activation of microglia in all mice, even the non-stressed ones (decreased M1 morphotype p< in all cases).\nANOVA displayed a significant effect of the interaction between the variables Stress X Cocaine in the NAc (F2,24 = ; p<). Post-hoc analysis revealed a higher number of Iba1+ in M2 phase and a decrease of those in M1, in non-stressed animals treated with 25 mg/kg cocaine, showing once again the deleterious effect of this concentration of drug on microglia. Curiously, socially defeated animals treated with saline (p< in both cases) also showed a rise of M2 Iba1+ cells and a decrease in those in M1 (Fig 2C), with no changes in those in M3-5.\nConsidered together, these results show that social stress induced during adolescence has a long-term effect of a decrease in numbers and increased reactivity of microglia during adulthood. This is compatible with an inflammatory environment and heightened cellular vulnerability.\nRepeated social defeat in adolescence decreases the number of astrocytes in adult NAc and leaves neurons more vulnerable to eventual drug insults\nQuantification of GFAP+ astrocytes did not reveal any difference in the PrL cortex, but they were significantly reduced in the NAc (F1,24 = ; p< ). Repeated exposure to social stress reduced the number of GFAP+ cells in this structure in all treated groups compared with non-socially stressed animals (Fig 3A and 3B). Given that astrocytes are the main supporting glia for neurons, we sought to evaluate how neurons were affected by this observed undermining benefits of the glia.\nConsequently, when we measured the number of neurons (NeuN+ cells) remaining in the PrL and NAc, we observed a significant downregulation with the highest cocaine dose in the stress conditions (Fig 3C and 3D). ANOVA revealed a significant effect of the interaction between the variables Stress X Cocaine in the PrL (F2,24 = ; p<) and NAc (F2,24 = ; p<). Post-hoc comparisons showed that animals experiencing RSD and treated with the highest dose of cocaine had lost more neurons than those receiving the same dose but not undergoing stress (p<  in PrL and p<  in NAc), suggesting a combined effect in which a high dose of cocaine produces an insult whose consequences are more pronounced when social stress conditions have previously been experienced.\nFinally, we analyzed the functional reliability of the remaining neurons with the synaptic protein synaptophysin. Two-way ANOVA showed a significant effect of the interaction between the variables Stress X Cocaine in the PrL (F2,24 = ; p<) and NAc (F2,24 = ; p<). Synaptophysin expression in the PrL cortex was higher in defeated animals treated with saline (Fig 3E), indicating a stress-dependent effect on this synaptic protein (p< ). Interestingly, socially defeated animals treated with cocaine exhibited lower synaptophysin levels in the NAc than RSD animals treated with saline (Fig 3F) suggesting a different sensitivity to experimental variables in this nucleus (p< ).\nThese results indicate that supporting glia cells are highly affected by stress experienced in early periods of life, with their numbers being reduced and their capacity to support neurons undermined. The combination of raised inflammatory signals and microglia reactivity, in addition to a decrease in astrocyte protection, results in high neuronal vulnerability in stress- and drug-sensitive areas.\nDiscussion\nRepeated Social Defeat is recognized as a multisystem-impacting stressor. Most research in the field has been performed in animals socially defeated during adulthood and have evaluated effects during a short time after the last defeat. However, the long-lasting effects of RSD experienced during adolescence have not been well studied. Our study confirms that RSD during adolescence induces increases in the conditioned rewarding effects of cocaine in adulthood. Stressed mice developed CPP with a non-effective dose of cocaine (1 mg/kg) and showed significantly higher preference for an effective dose than their non-stressed counterparts.\nAs we have observed in previous experiments [22, 23], mice exposed repeatedly to social defeat during adolescence developed CPP with a dose of cocaine (1mg/kg) that was non-effective in control animals. On the other hand, 25mg/kg of cocaine induced CPP in all groups, though defeated mice showed a greater preference than control animals. When the conditioned rewarding effects of amphetamine were studied in adolescent-defeated animals by Burke and co-workers, similar results were obtained [85]. Social defeat during adolescence has also been demonstrated to induce an increase in the acquisition of intravenous cocaine and oral ethanol self-administration in adulthood [22, 29], and shows particularities when compared to that experienced in adult animals. We have previously shown that the effects of social defeat aggression are less intense in adolescent mice, which show a significant increase in corticosterone levels only after the fourth encounter, in contrast with the sharp rise observed in adult mice after the first encounter [23]. Our results indicate that RSD increases the sensitivity of mice to the conditioned rewarding effects of cocaine. Although mice defeated in adolescence showed attenuated amphetamine-induced increases of DA in the medial prefrontal cortex, there was an increased response to amphetamine in the NAc, thus supporting our hypothesis [85].\nIn the present study we show that the increase in the conditioned rewarding effects of cocaine is accompanied by alterations in glial and neuronal markers. We have evaluated two brain areas implicated in the rewarding effects of cocaine: the PrL cortex and the NAc. Under non-stress conditions, neither 1 nor 25 mg/kg of cocaine induced any effect per se on any of the parameters studied (glia and neuronal profiles); however, social defeat induced profound changes when combined with a dose of cocaine, and in the absence of it.\nDefeated mice showed changes in microglia activation in both structures 3 weeks after the last social defeat; a decrease of Iba1+ cells in the PrL cortex was complemented by a decrease in morphotypes 1 and 2 and increases in morphotypes 3, 4 and 5 in both structures. Few studies have explored the effect of social stress on Iba1+ expression, and all have been performed in adult animals and immediately after the last social defeat. Said studies have revealed an increased expression of microglial marker Iba1+ in different brain areas, [86] and a heightened response after a secondary immune challenge [87]. The conclusions of prior research are not consistent regarding the effect of stress on microglial activation. Most studies have reported changes in microglial activation in response to stress, but there is not a consensus regarding the characteristics of said changes. For instance, stress has been reported to both de-ramify and hyper-ramify microglia, to increase and decrease cell size, and to increase and decrease Iba1+ levels [86, 87, 88, 89, 90].\nUnder our experimental conditions (long-lasting effects of adolescent stress), we found only a slight decrease of Iba1+ immunoreactive cells in the PrL, and no changes in the NAc. On the other hand, we observed an increase of the most active morphotypes of microglia in response to stress and cocaine treatment. Defeated animals exhibited a more pronounced activation of microglia, with a decrease of the morphotypes M1 and M2 and an increase of M3-5, all three being the most active forms. These results are in line with other evidence associating morphological changes in microglia with an inflammatory profile after social defeat [91]. To sum up, in our experimental conditions, the total number of Iba1+ microglial cells is reduced by RSD, and there is a decrease in resting phenotypes in both the PrL and NAc.\nWe also found astrocytes to be affected, since all defeated mice showed a decrease in GFAP+ cells in the NAc. Astrocytes express glucocorticoid receptors [92] and are responsive to stress [67], with corticosterone inducing a decrease in GFAP levels in the rat brain [93, 94]. Therefore, we believe that the decreased number of astrocytes after RSD is a sign of long-term cell damage. In agreement with our results, a previous report by Araya-Call\xeds and co-workers [95] showed that, after daily social defeat experienced over a 5-week period, there was a decrease in GFAP expression in the hippocampus 24h after the last defeat. However, other types of stress, like activity stress, chronic variable stress or thermal stress, have been shown to increase GFAP immunoreactivity in several brain regions, which may indicate stimulation of reactive astrocytes [96, 97, 98]. Hence, social stress seems to exert a different effect on astrocyte function. In line with this, a decrease in GFAP+ astrocytes is observed in the medial prefrontal cortex after juvenile separation [99], in the hippocampus after chronic social defeat [100], and in the neocortex after chronic mild stress [101].\nFinally, we observed that neuronal synaptic function was also modified by RSD. The neuronal marker NeuN was diminished in defeated mice after administration of the highest cocaine dose. Previous research has described how chronic social stress promotes a decrease in neuronal populations\u2014assessed by the NeuN marker\u2014in several brain structures, including the hippocampus [102, 103]. Once again, the aforementioned results were obtained immediately after social defeat in adult animals. In the present study, we demonstrate that this effect is also present in adolescent animals, is prolonged in time, and is potentiated by concomitant cocaine administration.\nIn our experiments, the changes in synaptophysin depended on the structure studied. While an increase was observed in the PrL of defeated mice, a decrease was detected in the NAc of those treated with cocaine. Sometimes synaptophysin signal in the cortex is not easily associated with a specific nucleus, and several variables can affect its quantification. Neurons in both areas may show different degrees of vulnerability to damage, in which case the synaptophysin signal would be diminished by a strong neuronal insult, while the projection of neurons from other structures to the cortex could be more resilient to experimental variables, in which case quantification would reveal a mix of resident and projecting neurons. In addition to this, social defeat induces abnormal structural plasticity of dendrites and spines in different brain structures [104]. For example, adult animals exposed for 5 weeks to chronic unpredictable stress exhibit a short-term decrease in synaptophysin density in the hippocampus and prefrontal cortex [105]. Conversely, in our stress protocol, there was a trend for synaptophysin density to increase, though it was significant only in the PrL cortex. In line with our results, the hippocampal expression of synaptophysin was found not to differ in adult rats exposed to social instability stress during adolescence [106]. However, isolation during adolescence was reported to induce a reduction in synaptophysin in the infralimbic cortex and cingulate gyrus in adulthood [107]. We also found that cocaine treatment had no significant effect on synaptophysin expression in the NAc of control animals, but did induce a significant decrease in socially stressed animals. In accordance with these results, other authors failed to observe changes in synaptophysin expression in the NAc after five-day treatment with a dose of 10mg/kg [108].\nFinally, we have to consider the limitations of the model employed. Although men are more deeply affected by social stress at a physiological level [109], women show higher rates of anxiety and fear. Since most female rodents do not express spontaneous aggression, one of the major disadvantages of the social defeat paradigm is that it is principally designed for male rodents. Furthermore, we have to take into consideration that the SD model emphasizes the social aspect of stress, but it produces both physical and social stress. The physical stress suffered by the animal also has a bearing, and it is difficult to separate the two types of stress within this model [110].\nConsidered as a whole these results suggest that social stress experience modulates vulnerability to suffer a loss of glia-supporting cells and functional neuronal synaptic density due to drug consumption in later life.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:29Z', 'description': u'by Hideki Tani, Takashi Komeno, Aiko Fukuma, Shuetsu Fukushi, Satoshi Taniguchi, Masayuki Shimojima, Akihiko Uda, Shigeru Morikawa, Nozomi Nakajima, Yousuke Furuta, Masayuki Saijo\n\nSevere fever with thrombocytopenia syndrome (SFTS), caused by SFTS virus (SFTSV), is a viral hemorrhagic fever with a high case fatality rate. Favipiravir was reported to be effective in the treatment of SFTSV infection in vivo in type I interferon receptor knockout (IFNAR\u2212/\u2212) mice at treatment dosages of both 60 mg/kg/day and 300 mg/kg/day for a duration of 5 days. In this study, the efficacy of favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day against SFTSV infection in an IFNAR\u2212/\u2212 mouse infection model was investigated. IFNAR\u2212/\u2212 mice were subcutaneously infected with SFTSV at a  \xd7 106 50% tissue culture infectious dose followed by twice daily administration of favipiravir, comprising a total dose of either 120 mg/kg/day or 200 mg/kg/day. The treatment was initiated either immediately post infection or at predesignated time points post infection. Neutralizing antibodies in the convalescent-phase mouse sera was examined by the pseudotyped VSV system. All mice treated with favipiravir at dosages of 120 mg/kg/day or 200 mg/kg/day survived when the treatment was initiated at no later than 4 days post infection. A decrease in body weight of mice was observed when the treatment was initiated at 3\u20134 days post infection. Furthermore, all control mice died. The body weight of mice did not decrease when treatment with favipiravir was initiated immediately post infection at dosages of 120 mg/kg/day and 200 mg/kg/day. Neutralizing antibodies were detected in the convalescent-phase mouse sera. Similar to the literature-reported peritoneal administration of favipiravir at 300 mg/kg/day, the oral administration of favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day to IFNAR\u2212/\u2212 mice infected with SFTSV was effective.', 'title': u'Therapeutic effects of favipiravir against severe fever with thrombocytopenia syndrome virus infection in a lethal mouse model: Dose-efficacy studies upon oral administration', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206416', 'keywords': '', 'ID_RSS': u'606', 'contents': u"Therapeutic effects of favipiravir against severe fever with thrombocytopenia syndrome virus infection in a lethal mouse model: Dose-efficacy studies upon oral administration\n\nAffiliations\nDepartment of Virology I, National Institute of Infectious Diseases, Tokyo, Japan,\nDepartment of Virology, Graduate School of Medicine and Pharmaceutical Sciences, University of Toyama, Toyama, Japan\nFigures\nAbstract\nSevere fever with thrombocytopenia syndrome (SFTS), caused by SFTS virus (SFTSV), is a viral hemorrhagic fever with a high case fatality rate. Favipiravir was reported to be effective in the treatment of SFTSV infection in vivo in type I interferon receptor knockout (IFNAR\u2212/\u2212) mice at treatment dosages of both 60 mg/kg/day and 300 mg/kg/day for a duration of 5 days. In this study, the efficacy of favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day against SFTSV infection in an IFNAR\u2212/\u2212 mouse infection model was investigated. IFNAR\u2212/\u2212 mice were subcutaneously infected with SFTSV at a  \xd7 106 50% tissue culture infectious dose followed by twice daily administration of favipiravir, comprising a total dose of either 120 mg/kg/day or 200 mg/kg/day. The treatment was initiated either immediately post infection or at predesignated time points post infection. Neutralizing antibodies in the convalescent-phase mouse sera was examined by the pseudotyped VSV system. All mice treated with favipiravir at dosages of 120 mg/kg/day or 200 mg/kg/day survived when the treatment was initiated at no later than 4 days post infection. A decrease in body weight of mice was observed when the treatment was initiated at 3\u20134 days post infection. Furthermore, all control mice died. The body weight of mice did not decrease when treatment with favipiravir was initiated immediately post infection at dosages of 120 mg/kg/day and 200 mg/kg/day. Neutralizing antibodies were detected in the convalescent-phase mouse sera. Similar to the literature-reported peritoneal administration of favipiravir at 300 mg/kg/day, the oral administration of favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day to IFNAR\u2212/\u2212 mice infected with SFTSV was effective.\nFunding: This research was partially supported by Grants-in-Aid from the Ministry of Health, Labour, and Welfare of Japan (H25-Shinko-Shitei-009) (.), AMED under Grant Number JP18fk0108002 (.) and JP18fk0108072 (.), and JSPS KAKENHI Grant Number JP15K08510 (.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors declare no conflicts of interest in association with the present study.\nIntroduction\nSevere fever with thrombocytopenia syndrome (SFTS) is caused by SFTS virus (SFTSV), belonging to the family Phenuiviridae (genus Phlebovirus). SFTS is a viral hemorrhagic fever with a high case fatality rate; it was first reported as a novel infectious disease in China [1, 2], followed by discovery in South Korea and Japan [3, 4]. It is characterized by marked reduction in platelet, white blood cell, and total blood cell counts in patients. Hemorrhagic symptoms, such as gingival oozing, bloody diarrhea, and hematuria, are commonly observed in patients with severe and fatal SFTS [3, 5, 6]. Because of the associated high mortality rate, it is critical to develop specific and effective therapy for SFTS. Unfortunately, no such treatment has been developed yet. The inhibitory effect of ribavirin on the replication of SFTSV has been elucidated in vitro as well as in vivo [7, 8]. Although ribavirin inhibited the replication of SFTSV in vitro in a dose-dependent manner, therapeutic effect in vivo was limited in comparison with that of favipiravir. Thus, an anti-SFTSV effect of ribavirin is limited or absent in the clinical setting [9, 10]. Favipiravir is an RNA-dependent RNA polymerase inhibitor and a potent broad-spectrum antiviral drug. It inhibits the replication of multiple families of RNA viruses in vitro and in vivo [11, 12]. Favipiravir is a therapeutic antiviral drug against influenza virus approved in Japan with strict regulations for its production and clinical use. However, during the 2014\u20132015 Ebola outbreak in West Africa, it was also considered as a candidate agent against Ebola virus infection [13, 14]. In addition, favipiravir was demonstrated to have antiviral effects against the newly discovered emerging viruses SFTSV and Heartland virus (HRTV) [15]. HRTV is an emerging tick-borne virus, which, similar to SFTSV, belongs to the genus Phlebovirus in the family Phenuiviridae. Patients infected with HRTV show similar symptoms as SFTS patients. The efficacy of favipiravir against HRTV infections was demonstrated in animal infection models using STAT2 knockout hamsters [15].\nReportedly, favipiravir is effective when administered even after symptoms appeared. The antiviral effects of favipiravir against SFTSV were confirmed in a mouse model as well as STAT2 knockout hamster model [16]. We have previously demonstrated the antiviral effects of favipiravir against SFTSV in a lethal mouse model using IFNAR\u2212/\u2212 mice. In the study, the highest dose of favipiravir used in mice experiments, at which side effects did not appear, was 300 mg/kg/day via intraperitoneal (.) route. All mice treated with favipiravir at 300 mg/kg/day survived without showing any symptoms upon SFTSV infection. In the mouse model, all mice also survived when treated . with favipiravir at 60 mg/kg/day. However, their body weight decreased by approximately 10% [8]. In the present study, the efficacy of favipiravir in the mouse lethal model was evaluated at dosages of 120 mg/kg/day via oral administration (.) and 200 mg/kg/day . The two doses of favipiravir were selected in clinical trials to evaluate the efficacy of favipiravir against influenza virus infections in humans. Favipiravir dosages of 120 mg/kg/day . and 200 mg/kg/day . have been applied for the restricted approval in Japan. The aim of this study was to assess the efficacy of favipiravir at dosages of 120 mg/kg/day . and 200 mg/kg/day . in the treatment of SFTSV infection in the lethal mouse model using IFNAR\u2212/\u2212 mice.\nMaterials and methods\nEthics statement\nAll animal experiments were performed in biological safety level 3 (BSL-3) containment laboratories at the National Institute of Infectious Diseases (NIID) in Japan and adhered to NIID regulations and guidelines on animal experimentation. Protocols were approved by the Institutional Animal Care and Use Committee of the NIID (No. 215024).\nCells, viruses, and antiviral compounds\nVero cells obtained from American Type Culture Collection (Summit Pharmaceuticals International, Japan) were maintained in Dulbecco\u2019s modified Eagle\u2019s medium (DMEM) supplemented with 10% heat-inactivated fetal bovine serum and antibiotics (DMEM-10FBS). The SFTSV Japanese strain SPL010 was used in this study [8]. Pseudotyped vesicular stomatitis viruses (VSV) possessing SFTSV-GP or VSV-G, designated SFTSVpv or VSVpv, respectively, were used [17]. SPL010 virus stocks were stored at \u221280\xb0C until use. All work with SFTSV was performed in BSL-3 containment laboratories in the NIID in accordance with the institutional biosafety operating procedures. Favipiravir (Toyama Chemical Co., Ltd., Toyama, Japan) was suspended in % (w/v) methylcellulose solution.\nAnimal experiments\nIFNAR\u2212/\u2212 C57BL/6 mice were produced as described previously [8]. IFNAR\u2212/\u2212 C57BL/6 mice were bred and maintained in an environmentally controlled specific pathogen-free animal facility of the NIID. Eight- to 10-week-old male mice were used. Favipiravir was administered in mice using a stomach probe after subcutaneous inoculation (.) with  \xd7 106 50% tissue culture infectious dose (TCID50) of SFTSV in 100 \u03bcl DMEM. Treatments were commenced at 1 h post infection or at 1, 2, 3, 4, or 5 days post infection with interval for 7 hours twice a day and continued for 5 days.\nTo determine the efficacy of favipiravir in the treatment of SFTSV infection, the mice were treated with favipiravir at dosages of either 120 mg/kg/day . or 200 mg/kg/day . [60 or 100 mg/kg/bis in die (BID), .] in 100\u03bcl per shot for 5 days starting at various time points as described above (Fig 1). Blood samples (20 \u03bcl/animal) were obtained via tail vein puncture at intervals of 2\u20134 days over a period of 14 days (<4 blood drawings in total) for the measurement of viral RNA levels. Body weight was recorded daily for 2 weeks, and each mouse was monitored daily for the development of clinical symptoms such as hunched posture, ruffled fur, activity, response to stimuli, and neurological signs. When mice showed serious clinical symptoms or weight loss of more than 30%, they were considered to be reached the humane endpoint so that they were humanely euthanized.\nSix mice in each group were administered favipiravir at either 120 mg/kg/day or 200 mg/kg/day starting at 1 h or 1, 2, 3, 4, or 5 days post infection and continued for 5 consecutive days. Placebo control mice were treated with an equal volume of % (w/v) methylcellulose solution administered at 1 h post infection and continued for 5 consecutive days.\nNeutralization assay\nThe day of SFTSV infection was considered as Day 0 and days post infection were subsequently counted. Sera from the mice at a convalescent phase were obtained at Day 14. To examine the neutralization antibody responses against SFTSV of the mice at a convalescent-phase, pseudotyped VSV system was employed. SFTSVpv and VSVpv were pre-incubated with serially diluted sera of the mice at a convalescent-phase for 1 h at 37\xb0C. Then, Vero cells were inoculated with each of the virus\u2013serum mixtures. After 2 h of adsorption at 37\xb0C, cells were washed with DMEM-10FBS and infectivity was determined by measuring luciferase activity after 24 h of incubation.\nResults\nTherapeutic efficacy of favipiravir against SFTSV infection in IFNAR\u2212/\u2212 mice\nConsistent with the results of a previous study, the optimal lethal infectious dose of SFTSV strain SPL010 in mice was determined to be  \xd7 106 TCID50 [8]. All control mice, infected with SFTSV died within 8 days post infection [8] (Fig 2A). All mice treated with favipiravir at dosages of 120 mg/kg/day or 200 mg/kg/day survived from a lethal SFTSV infection when treatment was initiated within 3 days and 4 days post infection, respectively (Fig 2B and 2C). When treatment was initiated on Day 4, the mice treated with favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day exhibited 67% and 100% survival, respectively. However, under these conditions, the health of mice was highly deteriorated, with more than 15% weight loss. A few mice treated with favipiravir at a dosage of 200 mg/kg/day dose initiated on Day 5 survived even with 30% weight loss (Fig 2C).\nFig 2. Effects of treatment with favipiravir against SFTSV infection in IFNAR\u2212/\u2212 mice.\n(A) Ten mice in the placebo control group were inoculated . with  \xd7 106 TCID50 of SFTSV strain SPL010. Control mice received % (w/v) methylcellulose solution via the . route. (B, C) Six mice in each group were inoculated . with  \xd7 106 TCID50 of SFTSV strain SPL010. Mice were treated with favipiravir at a dose of 120 mg/kg/day (B, 60 mg/kg/BID, .) or 200 mg/kg/day (C, 100 mg/kg/BID, .). Treatment was commenced at 1 h or 1, 2, 3, 4, or 5 days post infection. Favipiravir was administered twice daily . using a stomach probe until death or for 5 days as indicated in the upper columns (shaded in gray with survival curves). Survival was determined using Kaplan\u2013Meier analysis and GraphPad Prism6 (GraphPad Software) and shown in the upper columns. Relative weights are shown as means with standard deviations (middle columns). SFTSV RNA levels in blood samples collected at 2, 4, 7, 11, or 14 days post infection were determined by quantitative RT-PCR assays (lower columns). One way ANOVA with Bonferroni\u2019s multiple comparison test was used to determine statistical significance. Dashed lines indicate the detection limits of the assay in blood samples. Significance was determined in comparison to the results of the placebo group (for survivals) or Day 2 blood samples (for RNA copies): ****, P < ; ***, P < ; **, P < ; * P < ; ., not tested.\nThe RNA levels in the blood of mice gradually decreased upon administration of favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day, respectively (Fig 2B and 2C). There was no significant difference in the RNA levels between the two treatment groups. The viral RNA in blood was undetectable by Day 14 in most mice treated with favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day (Fig 2B and 2C).\nNeutralizing antibody responses against SFTSV in the mouse sera at a convalescent-phase\nTo examine whether neutralizing antibodies were induced in the mice at a convalescent-phase, serum samples collected on Day 14 were tested for neutralizing activity with an assay using a pseudotyped VSV system. Sera of convalescent-phase mice neutralized SFTSVpv infection at a dilution of 1 in 800 (Fig 3) and in a dilution-dependent manner (S1 Fig), whereas no significant neutralization of VSVpv infection was observed (Fig 3). The induction of neutralizing antibody responses in mice wherein treatment was initiated on Days 0 or 5 seemed lower than the induction of neutralizing antibody responses in mice wherein treatment was initiated on Day 1 at a dosage of 200 mg/kg/day (Fig 3B).\nDiscussion\nWe have previously demonstrated the protective efficacy of favipiravir in the treatment of SFTSV infection at dosages of 300 mg/kg/day . in the lethal mouse model [8]. Since favipiravir is approved for anti-influenza drug as a formula of . drug in Japan, we have tested the efficacy of favipiravir at dosages of 120 mg/kg/day and 200 mg/kg/day . against SFTSV in the lethal mouse model. The results demonstrated favipiravir at both dosages were effective via oral administration. The dosages were the standard dose applicable in humans. For utilizing favipiravir as an anti-influenza drug in humans, a dosage of 120 mg/kg/day . has been set for clinical use in Japan. With regard to the Ebola virus disease (EVD) outbreak that occurred in West Africa in 2013\u20132015, favipiravir was required to be administered at a higher dose for the treatment of EVD than that required for the treatment of influenza. This was based on the higher IC50 values of favipiravir for Ebola virus in vitro and in vivo [14, 19, 20].\nThe effective concentration of favipiravir in blood is considered to be similar when administered . and when administered . since several hours post administration [21]. Here the therapeutic effect of favipiravir in the treatment of SFTSV infection was observed both when administered . as well as when administered . In contrast to the previous reports, where favipiravir was administered once a day, favipiravir was administered twice a day (BID) in the present study. The antiviral effects of favipiravir when administered orally at the tested doses might be higher than those when administered via the intraperitoneal route quaque die [8]. This difference may be attributed to the maintenance of effective favipiravir concentration in blood. Furthermore, it is speculated that the observed therapeutic effect might be obtained not only due to a direct inhibition of viral replication by favipiravir but also due to the production of neutralizing antibodies against SFTSV in the later phase of the disease (Fig 3). The neutralizing antibody responses were higher in mice wherein treatment was initiated on Days 1 and 2 than in those wherein treatment was initiated on Day 0. This may be attributed to the amount of replicated virus as an antigen. Conversely, the production of neutralizing antibodies was weak in mice wherein treatment was initiated on Day 5, suggesting that neutralizing antibody producing cells were more heavily damaged in mice wherein the treatment was initiated in the later stages of the disease.\nThe therapeutic effect of favipiravir is remarkably higher against SFTS in animal models than other reported viral infectious diseases [19, 22, 23]. Administration of favipiravir after the onset of the disease did not show any efficacy in the treatment of EVD or Crimean-Congo hemorrhagic fever viral infection in animal models [19, 22, 23]. Conversely, the administration of favipiravir in the mice infected with SFTSV within 4 days post infection showed efficacy even at a dosage of 120 mg/kg/day, which is the dosage approved to be prescribed to humans (Fig 2). Therefore, favipiravir was effective not only for prophylactic use but also for treating SFTS in the mouse model. However, it was too late to initiate the administration of favipiravir at Day 5 in the mice model (Fig 2). The results obtained in the present study indicate that favipiravir should be administered as early as possible post infection. This also indicates that favipiravir should be administered as early as possible from disease onset for the treatment of patients with SFTS.\nCurrently, there is no antiviral therapy available for the treatment of SFTSV infection. Here, we studied the efficacy of favipiravir at dosages of 120 mg/kg/day . and 200 mg/kg/day . in the treatment of mice infected with SFTSV. These dosages can also be applied to humans. Currently, clinical trials are underway for evaluating the efficacy of favipiravir in the treatment of patients with SFTS in Japan [24]. We hope that favipiravir will not only be used as a prophylactic drug against SFTS in the near future but also as a therapeutic drug in clinical practice.\nSupporting information\nSFTSVpv were preincubated with 200-, 400-, and 800-fold diluted mouse sera collected on Day 14 (120 mg/kg/day treatment group [(A) left columns] and 200 mg/kg/day treatment group [(B) right columns]). Subsequently, Vero cells were infected with SFTSVpv. Infectivity of SFTSVpv was determined by measuring luciferase activities at 24 h post infection. Results from three independent assays are shown, with error bars representing standard deviations. Significance was determined in comparison to the results from non-serum treatment or infectivity of VSVpv.\n14.\nSissoko D, Laouenan C, Folkesson E, M'Lebing AB, Beavogui AH, Baize S, et al. Experimental Treatment with Favipiravir for Ebola Virus Disease (the JIKI Trial): A Historically Controlled, Single-Arm Proof-of-Concept Trial in Guinea. PLoS Med. 2016;13(3):e1001967. pmid:26930627; PubMed Central PMCID: PMCPMC4773183 following competing interests: SB, XdL, HR, and SG received a grant from St Luke International University (Tokyo, Japan) to perform research on favipiravir in non-human primates. YY declared board membership for AbbVie, BMS, Gilead, MSD, Roche, Johnson&Johnson, ViiV Healthcare, Pfizer, and consultancy for AbbVie, BMS, Gilead, MSD, Roche, Johnson&Johnson, ViiV Healthcare, and Pfizer. OP worked for Fab'entech biotechnology from 1st April to 13th November 2015. Between January 2014 and now, SC received a grant from the CHU de Quebec research center, which had no relationship with the trial described in the paper. All other authors declared no conflict of interest.", 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:30Z', 'description': u"by Matthias Braeunig, Ruth Pfeifer, Uwe Schaarschmidt, Claas Lahmann, Joachim Bauer\nObjective To identify changes in work-related psychological attitudes that influence mental health improvement in school teachers after participation in a psychological group program. Methods In an exploratory study with N = 544 matched cases we combined a screening instrument for general mental health (GHQ) with measures of work-related behavioral and experiential patterns (AVEM). We compared four GHQ change types pre and post intervention with regard to their performance on eleven sub-scales that figure as professional resources. Factors that showed significant relative changes and thus (likely) contributed to improved health status were identified by means of pairwise t-tests and corresponding effect sizes. Results Decreases in willingness to work to exhaustion (VB), in striving for perfection (PS), and in the tendency for resignation in the face of failure (RT), as well as an increase of distancing ability (DF) and of inner calm and balance (IR) appear to be the main factors influencing health improvement in the intervention. Simultaneously, an increase of satisfaction with life (LZ) is observed. Conclusions The balanced use of professional resources is a critical ingredient in maintaining teachers' health. Adjusting the balance between commitment and resistance through factors found in this analysis help teachers in maintaining and strengthening resilience. The coaching program addresses these factors by focusing on personal attitudes and good interpersonal relationships in the school environment.", 'title': u'Factors influencing mental health improvements in school teachers', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206412', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Factors influencing mental health improvements in school teachers\n\nFigures\nAbstract\nObjective\nTo identify changes in work-related psychological attitudes that influence mental health improvement in school teachers after participation in a psychological group program.\nMethods\nIn an exploratory study with N = 544 matched cases we combined a screening instrument for general mental health (GHQ) with measures of work-related behavioral and experiential patterns (AVEM). We compared four GHQ change types pre and post intervention with regard to their performance on eleven sub-scales that figure as professional resources. Factors that showed significant relative changes and thus (likely) contributed to improved health status were identified by means of pairwise t-tests and corresponding effect sizes.\nResults\nDecreases in willingness to work to exhaustion (VB), in striving for perfection (PS), and in the tendency for resignation in the face of failure (RT), as well as an increase of distancing ability (DF) and of inner calm and balance (IR) appear to be the main factors influencing health improvement in the intervention. Simultaneously, an increase of satisfaction with life (LZ) is observed.\nConclusions\nThe balanced use of professional resources is a critical ingredient in maintaining teachers\' health. Adjusting the balance between commitment and resistance through factors found in this analysis help teachers in maintaining and strengthening resilience. The coaching program addresses these factors by focusing on personal attitudes and good interpersonal relationships in the school environment.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nThe extent to which teachers in Germany and other countries are affected by stress-related health disorders [1], such as depression, anxiety, and somatoform disorders, has not diminished since we first published our results on the effectiveness of our Manual-Based Psychological Group Program for teachers [2,3]. As these results were based on an RCT study, we were appointed by the Baden-W\xfcrttemberg Ministry of Culture (Kultusministerium) to offer our intervention as part of a state-wide prevention program. The program aims at strengthening health and resilience by fostering competency in relationship-building which includes reflections on stress physiology and work-related attitudes. In the process, we have continually evaluated the outcome of the intervention with different inventories including the General Health Questionnaire (GHQ-12), a screening instrument for mental health we had already applied in our initial study. In this paper we address the important research question that had remained open: Can the observed health benefits of the intervention be correlated with changes in attitudes and coping strategies, and how exactly do they contribute? In order to tackle this question, we applied the AVEM inventory (German for "Arbeitsbezogene Verhaltens- und Erlebensmuster"), an instrument that measures work-related attitudes as professional resources on eleven sub-scales [4]. While other studies that applied AVEM usually focus on the related four risk patterns, . Zimmermann et al. [5] and Voltmer et al. [6], we based our investigation directly on the sub-scales: subjective importance of work (BA), professional ambition (BE), willingness to work to exhaustion (VB), striving for perfection (PS), distancing ability (DF), tendency for resignation in the face of failure (RT), proactive problem-solving (OP), inner calm and balance (IR), experience of success at work (EE), satisfaction with life (LZ), and experience of social support (SU). We investigated whether those who benefited from the intervention, as measured by the GHQ, showed significant higher differences with respect to changes in the AVEM features, compared to those who did not benefit.\nMaterials and methods\nThe research data referred to here are the by-product of the prevention measure that was offered to all school teachers of the region Baden-W\xfcrttemberg by the state Ministry of Culture (Kultusministerium). The state ministry requested that the intervention should be evaluated by the questionnaires described above. Teachers who decided to respond generated an anonymous code that was later used to match pre and post questionnaires. The data is therefore anonymous and the identity of the respondent is never revealed. As teachers did not undergo physical examination and no biological material was taken, the study did not require approval by the institutional review board (ethics committee). However, with the response of a filled questionnaire written informed consent was given to the use of data for the purpose of evaluation. Since the recorded response was anonymous, the data cannot be traced back to the respondent.\nThe study included 544 out of 1532 teachers assigned to the program in two consecutive school years (2013/14 and 2014/15). The main reason for this reduction consists in our high standards: Criteria for inclusion were participation in at least five out of six sessions of our intervention or, alternatively, the full-day seminar. Additionally, we only used data from participants who submitted both pre and post questionnaires. Nevertheless the subgroup of the 544 teachers did not differ significantly from the rest in their sociodemographic or GHQ parameters.\nThe intervention is conceptualized as a Balint-type group work based on a published manual [7]. It includes five modules dealing with the following issues: (1) basic knowledge of stress physiology and the effects on health parameters; (2) mental attitudes with a particular focus on authenticity and identification; (3) competence in handling relationships with students; (4) competence in handling relationships with parents; (5) strengthening collegiality and social support among the staff. Since we have shown that participation in at least five sessions was sufficient for achieving the health benefit [2], the actual program has been shortened from originally ten to currently six sessions. Alternatively, a full- and half-day seminar was offered.\nOur analysis was based on data derived from the inventories GHQ-12 [8] and AVEM-44 [9]. Participants were dichotomized with regard to a GHQ cut-off greater than or equal to 4, which indicates an impaired health status [10]. To investigate changes in AVEM parameters in those who improved on the GHQ scale, we divided our sample into four subgroups: (i) "stable healthy" group below the cut-off before and after the intervention; (ii) "improvers" who changed from above to below the cut-off upon intervention; (iii) members of the "worsener" group who changed from below to above the cut-off with the intervention; (iv) "stable at risk" group above the cut-off before and after the intervention. For each group we separately analyzed changes in the means of the eleven AVEM parameters before and after the intervention. Group differences were assessed by paired t-tests, and the corresponding effect sizes calculated, taking into account the correlated design [11]. P-values have been adjusted for multiple testing using Holm-correction [12].\nResults and discussion\nWith respect to the GHQ, the sample as a whole improved: As shown in Fig 1, the proportion of those above the cut-off diminished from 49% (266/544) before to 22% (118/544) after the intervention (medium effect size, Cohen\u2019s h = ). However, the focus of this study was not to replicate the effects of the intervention on the GHQ, but to explain them in terms of changed attitudes and coping behaviors as gauged by AVEM features (Fig 2). The following small (d>.2) and medium (d>.5) effect sizes were observed: In the "stable healthy" group PS decreased. For the "improvers" group VB, PS and RT were reduced, while DF, IR, and LZ increased. In the "worsener" group VB and LZ were reduced. In the "stable at risk" groupVB, as well as OP decreased, while DF increased. With respect to the changes with small and medium effects only those in the improvers and "stable healthy" group reached significance (after Holm-adjustment).\nRefer to S1 File for a visualization of these results. The relevant factors are shown in Table 1.\nFig 2. Profiles of AVEM features for each of the four GHQ change types with standard error bars.\nAcronyms denote subjective importance of work (BA), professional ambition (BE), willingness to work to exhaustion (VB), striving for perfection (PS), distancing ability (DF), tendency for resignation in the face of failure (RT), proactive problem-solving (OP), inner calm and balance (IR), experience of success at work (EE), satisfaction with life (LZ), and experience of social support (SU).\nOur main finding is that mental health improvements effected by the intervention appear to be influenced by a decrease in willingness to work to exhaustion (VB), in striving for perfection (PS) and in the tendency for resignation (RT), and an increase in distancing ability (DF) and in inner calm and balance (IR). Simultaneously\u2013and probably as a result of these changes\u2013satisfaction with life in general (LZ) increased. Similar albeit smaller AVEM changes could also be observed in the other three GHQ change types. In the "stable at risk" group these changes were obviously not strong enough to result in a positive shift of health status. The "stable healthy" group may have profited from weak but still significant changes in the same direction as in the improvers group, by helping to maintain their already positive health status. The smallest group, the "worseners", were either not reached by the intervention or had other reasons for their decline.\nLimitations\nWe are aware that the changes in attitude and experience on health improvement are to be seen as correlates of the four GHQ change types. A deeper understanding of their mediating influence must be gained through further investigation.\nThe forgoing analysis focuses on effect sizes rather than significance of changes. The effect sizes found are based on the t-test statistic and consider the correlation between pre and post measures of the AVEM features. The p-values are merely used as indicators. However, they have been adjusted by an appropriate adjustment method (Holm-correction) and underline the reliability of the result. The significance level is an aid to support our claim that the effects in the improvers group are to be considered as relevant. Correlation between AVEM features is assumed and the relevant factors may contribute in an orchestrated manner. Nevertheless, an analysis of correlation between AVEM features remains to be done and should be performed in a sequel to this paper.\nThe missing replacement by median values in T1 and copy in T2 is simple and conservative, and a more sophisticated method could be sought, such as replacement on the item level of the questionnaire. Since missing pertains mainly to the feature `SU`(experience of social support), which is a resource that does not change much under the intervention, we consider our choice of replacement as safe.\nConclusions\nAn important lesson to be learned from these results is that teachers\u2019 health can be improved or maintained by intervention programs that promote self-regulation by adjusting commitment and strengthening resistance, . tuning the use of professional resources like the ones that we have outlined above. Our findings are in good agreement with those reported by Roloff Henoch et al [13]. Our intervention explicitly addresses these resources by introducing teachers to specific modules dealing with personal attitudes, focusing on good interpersonal relationships in their school environment and integrating a relaxation technique. Future research should take into account the factors found in this study and model the mental health benefit of intervention strategies accordingly.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:32Z', 'description': u"by Edc\xe1ssio Dias Ara\xfajo, Alisson Carraro Borges, Neriamara Martins Dias, Dimas Mendes Ribeiro\n\nThis study aimed to evaluate 1) the influence of gibberellic acid (GA3) in the development of Tifton 85 bermudagrass grown in constructed wetland systems (CWs) and 2) the plant's capacity to remove nutrients and sodium from synthetic municipal wastewater (SMW). The experiment was carried out in Vi\xe7osa, Minas Gerais, Brazil, and consisted of foliar applications of GA3 set in randomized blocks design, with four replicates and 6 treatments as following: NC (control with plants); 0 \u03bcM GA3; N1: 5 \u03bcM GA3; N2: 25 \u03bcM GA3; N3: 50 and N4: 100 \u03bcM GA3 per CWs, NC* (control with no plants): 0 \u03bcM GA3. The study was conducted over two crop cycles in the spring 2016. The parameters used to evaluate the performance of the Tifton 85 bermudagrass were its plant height, productivity, chlorophyll measurement, number of internodes, nutrients and Na removals. Chemical analyses of the effluents were conducted. In response to the application of GA3, the increase in height of Tifton 85 bermudagrass in the first crop cycle was higher than the increase in height in the second crop cycle. The decrease in plant growth in response to GA3 in the second crop cycle may be linked to the age of the plant tissue and climatic conditions. The greater growth of the plants cultivated in the CWs allows a more efficient removal of pollutants, using simple management and low cost. The results suggest that applying 50 \u03bcM of GA3 to the development of Tifton 85 bermudagrass provides higher dry matter yield and removal of nitrogen, phosphorus, and sodium for the first crop cycle in CWs. However, in the second crop cycle, the application of GA3 had no effect on dry matter production and nutrient removal by Tifton 85 bermudagrass in CWs.", 'title': u'Effects of gibberellic acid on Tifton 85 bermudagrass (Cynodon spp.) in constructed wetland systems', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206378', 'keywords': '', 'ID_RSS': u'606', 'contents': u"Effects of gibberellic acid on Tifton 85 bermudagrass (Cynodon spp.) in constructed wetland systems\n\nAffiliations\nDepartment of Agricultural Engineering, Federal University of Vi\xe7osa, Vi\xe7osa, Minas Gerais, Brazil,\nDepartment of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America\nFigures\nAbstract\nThis study aimed to evaluate 1) the influence of gibberellic acid (GA3) in the development of Tifton 85 bermudagrass grown in constructed wetland systems (CWs) and 2) the plant's capacity to remove nutrients and sodium from synthetic municipal wastewater (SMW). The experiment was carried out in Vi\xe7osa, Minas Gerais, Brazil, and consisted of foliar applications of GA3 set in randomized blocks design, with four replicates and 6 treatments as following: NC (control with plants); 0 \u03bcM GA3; N1: 5 \u03bcM GA3; N2: 25 \u03bcM GA3; N3: 50 and N4: 100 \u03bcM GA3 per CWs, NC* (control with no plants): 0 \u03bcM GA3. The study was conducted over two crop cycles in the spring 2016. The parameters used to evaluate the performance of the Tifton 85 bermudagrass were its plant height, productivity, chlorophyll measurement, number of internodes, nutrients and Na removals. Chemical analyses of the effluents were conducted. In response to the application of GA3, the increase in height of Tifton 85 bermudagrass in the first crop cycle was higher than the increase in height in the second crop cycle. The decrease in plant growth in response to GA3 in the second crop cycle may be linked to the age of the plant tissue and climatic conditions. The greater growth of the plants cultivated in the CWs allows a more efficient removal of pollutants, using simple management and low cost. The results suggest that applying 50 \u03bcM of GA3 to the development of Tifton 85 bermudagrass provides higher dry matter yield and removal of nitrogen, phosphorus, and sodium for the first crop cycle in CWs. However, in the second crop cycle, the application of GA3 had no effect on dry matter production and nutrient removal by Tifton 85 bermudagrass in CWs.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: Minas Gerais State Agency for Research and Development - FAPEMIG - Grant PPM-00561-17 (ACB). \nCompeting interests: The authors have declared that no competing interests exist\nIntroduction\nThe disposal of wastewater into rivers, lakes and other water bodies leads to a reduction in quality of water resources, which are of prime importance to human and aquatic life. The discharge of wastewater contains high levels of organic nitrogen and phosphorus compounds that enable growth of algae and aquatic plants, which are responsible for eutrophication of water bodies.\nConstructed wetland systems (CWs) are treatment systems planned and designed to use natural processes involving wetland vegetation, soils, and their associated microbial assemblages to improve water quality [1]. In CWs\u2014under appropriate environmental conditions\u2014physical, chemical and biochemical processes occur to treat sanitary sewage, industrial effluents and many types of wastewater [2]. Many countries have adopted these systems [3] because they require low-cost investments combined with their efficiency and feasibility [4].\nThe efficiency of sewage treatment using CWs is obtained through the hydraulic interaction of the substrate, plants, microorganisms and solar radiation. Pollutant removal takes place in a support media, which is responsible for the filtration and the formation of the biofilm next to the roots of the plants. The microorganisms adhere to the biofilm, degrade carbonaceous and nitrogenous matter, and the plants absorb the nutrients and heavy metals, thus promoting phytoremediation [5].\nThe selection of wetland plants is crucial to the success of the wastewater treatment because the plants uptake macro and micronutrients from the CWs for their development. The macronutrients N and P are essential for plant growth and development. Nitrogen, besides constituting proteins, is required to produce the molecule chlorophyll. P is important for the energy reserve and structural integrity of tissues.\nReed (Phragmites australis), cattail (Typha spp.), lakeshore bulrush (Schoenoplectus lacustris) and Canna indica are some of the most common wetland species studied in treatment wetlands [6]. Ornamental species [7] or species of zootechnical interest such as elephant grass (Pennisetum purpureum) and Tifton 85 bermudagrass (Cynodon spp.) [8] have been used in previous studies for economic return. Tifton 85 bermudagrass is a cross between bermudagrass (Cynodon dactylon) and a close tropical relative called stargrass (Cynodon nlemfuensis) with high zootechnical and economic potential due to its good palatability, digestibility, and expressive crude protein concentrations. In addition, it presents an attractive commercial value for the hay production, reaching higher values in regions with little forage availability.\nTifton 85 bermudagrass has interesting characteristics for wastewater treatment in CWs, as it is a perennial crop that presents a high growth rate, which in turn allows frequent cuts making it possible to extract large amounts of nutrients from the system [9].\nOne of the main mechanisms responsible for the removal of N in CWs is the uptake by plants when frequent cuts are performed [10]. Therefore, it is important to create favorable conditions for plants, such as adequate climatic conditions, plant density, cutting height, and the use of cultural practices that stimulate growth and development of plants to potentiate the extraction of nutrients in the CWs, thus generating a better-quality effluent.\nIn this context, since the nutrient removal is due to the fast plant growth and dry matter production, it is necessary to look for alternatives that potentiate the growth rate of the plants.\nThe growth rate of plants can be increased with the use of growth-regulating substances [11]. Gibberellic acid (GA3) is one of the classes of growth phytohormones that influence plant growth, increase elongation and cell division, which is evidenced by increased length and number of cells [12]. However, the effect of GA3 is influenced by several factors, such as environmental conditions, GA3 concentration, number of applications, and the season of application and species or cultivar [11].\nOne of the roles played by plants in CWs is nutrient removal. Nutrient uptake affects plant growth rate. However, there are no references in the scientific literature regarding the effect of GA3 on plants grown in CWs. Therefore, it is necessary to investigate the effects GA3 has on productive characteristics of Tifton 85 bermudagrass, and pollutant removal efficiency in CWs.\nThis study aimed to evaluate 1) the influence of GA3 in the development of Tifton 85 bermudagrass grown in CWs; and 2) the plant's capacity to remove nutrients and sodium (Na) from synthetic municipal wastewater (SMW).\nMaterials and methods\nCharacterization of the experimental area\nThe experiment was carried out in a greenhouse located at the experimental area of the water resources reference center belonging to the Department of Agricultural Engineering at the Federal University of Vi\xe7osa, (altitude: 650 m; latitude 20\xb045'14'' S, longitude 42\xb052'53'' W) Vi\xe7osa, Minas Gerais state, Brazil. The climate, according to the K\xf6ppen climate classification, is Cwa (humid subtropical climate with dry winter and hot summer).\nThe experimental system consisted of a set of 10 L polyethylene containers (reactors) with  cm height,  cm diameter, with a surface area of  m2, cultivated with Tifton 85 bermudagrass (Cynodon dactylon Pers. x Cynodon nlemfuensis Vanderyst, Vi\xe7osa, Brazil), which were then submitted to SMW applications (Fig 1).\nThe CWs were filled up to  cm height with gneissic gravel 0 (D60 = 7 mm, coefficient of uniformity D60/D10 = , and initial void volume of %) and a free edge of  cm. Prior to filling the CWs, the rocks were immersed in a bleach solution and rinsed with running water.\nExperimental design and treatments\nThe different treatments and their respective doses of GA3 are listed in Table 1.\nA randomized complete block design was used, with four replications and five treatments with Tifton 85 bermudagrass exposed to different doses of GA3, and one treatment control with no plants to assess the effluent, totaling 24 experimental plots.\nThe SMW was used in the experiment to guarantee greater control of chemical and organic compounds, and for sanitary purposes, since the operation of CWs and handling of SMW was done manually.\nThe SMW used in this study was modified from Nopens [13]; the concentrations of COD, N and P were consistent with the ranges recommended by Von Sperling for municipal wastewater [14], and the concentration of potassium (K) was around the values described by Santos [15]. The ingredients were diluted in drinking water. The compounds used to prepare SMW are shown in Table 2.\nMunicipal wastewater is characterized by a high concentration of salts, especially K and Na. The concentrations of K and Na in the influent of the present study are similar to those found at the municipal wastewater treatment plant of Jana\xfaba, Minas Gerais [15]. The concentration of Na in raw sewage ranges between 30 to 50 mg L-1 [16].\nThe CWs worked as a batch system, being fed from the top. Influent SMW was applied until the reactors were filled up to the point where the upper layer of gravel was reached. Then the volume of input of each CWs was recorded. SMW remained in reactors during a cycle time, then the SMW was collected from the bottom to characterize a vertical flow.\nSMW was changed every 7 days (cycle time) during the acclimatization period of the experiment, and every  days after that. The cycle time in batch systems is analogous to the hydraulic residence time (HRT) in continuous systems.\nThe salts and the other ingredients were diluted into drinking water to prepare SMW; weekly evaluations of the parameters of the influent were conducted, totaling 11 analyses. The averages and standard deviations of the actual SMW composition in the present study are shown in Table 3.\nExperiment development and application of gibberellic acid (GA3)\nTifton 85 bermudagrass sprigs, formed by a segment of stolon with two buds with leaves and roots removed, were collected and standardized at  m. Then four sprigs were planted in each reactor.\nThe stabilization period lasted 48 days. At the end of this period, the plants were cut at a standard height of  m above the level of the support media. % (v/v) A spreader was added to the different doses of GA3 (2 drops of spreader in 25 ml GA3 solution) to facilitate the contact and absorption of the phytohormone by plants. The solutions were applied on the day of the standardization cut and at the end of the first cycle.\nThe first and second cycles lasted 18 and 23 days respectively and were carried out in the spring 2016 (southern hemisphere). The end of each cycle was pinpointed by when the Tifton 85 bermudagrass started lodging. Both cycles received two applications of the different doses of GA3; the second application was seven days after the plants being cut. The experiment was carried out for 89 days.\nThe weather conditions (Fig 2) were measured with two thermohygrometers installed in the center of the greenhouse. Maximum and minimum and average temperatures were recorded to monitor the weather changes in all the stages of the experiment.\nThe weather conditions inside the greenhouse were not controlled, so in the first and second crop cycles, the average temperatures were  and \xb0 C, and the relative humidity was 58% and 56%, respectively.\nExperimental evaluations\nYield and vegetative analyses.\nThe parameters analyzed in Tifton 85 bermudagrass and their methodologies are shown in Table 5. The forage yield was evaluated in two cycles when were performed cuts to  m at the level of the support media. The aerial parts of the material were collected and taken into a drying oven with forced ventilation at 65\xb0C for 72 hours. At the end of the cycles, two grass stems per reactor were evaluated for each of the following parameters: plant height and number of internodes.\nAn estimate of chlorophyll content in leaves was determined at the end of each cycle using a chlorophyll meter. First, the chlorophyll meter was calibrated according to the specifications of the equipment, then SPAD readings were measured on one leaf per stem, on two distinct stems per reactor, on the middle third of the stem and the leaf blade.\nNutrients and sodium absorption by the Tifton 85 bermudagrass.\nThe analyses of TN in the aerial part of the plants were quantified by the Kjeldahl semi-micro method with the addition of salicylic acid, adapted from Kiehl [17]. Absortion of K, TP and Na by plants followed the methods suggested by Silva [18].\nBased on the analyses results, the nutrients/Na accumulation by Tifton 85 bermudagrass was calculated using Eq 1 [19].\n(1)\nwhere, ATN, K, TP or Na\u2014nutrient or Na accumulation (g), CNutri\u2014content of nutrients or Na in dry matter of the aerial part of Tifton 85 bermudagrass (g g-1); DMY\u2014dry matter of the aerial part of Tifton 85 bermudagrass.\nEffluent evaluations.\nIn the experiments, influents and effluents were evaluated weekly, ., every two cycle times (HRT of  d). Analyses of oxidation-reduction potential, pH, electrical conductivity, evapotranspiration, COD, total nitrogen, total phosphorus, K, Na and total dissolved solids were performed to understand the current reactions and the nutrients and Na removal efficiency in CWs. The parameters analyzed are presented in Table 6.\nThe Tifton 85 bermudagrass evapotranspiration (ETc) was determined in each plot and after each cut ( m). ETc was calculated as the difference between the volumetric inflow and outflow divided by the surface area of the plot for data collected during the exchange of SMW, Eq 4 [20].\n(4)\nwhere, ETc (mm d\u22121), Qin is the plot volumetric inflow (mm3 d\u22121), Qout, is the measured plot volumetric outflow (mm3 d\u22121), and SA is the measured plot surface (mm2).\nThe analyses of COD, TP, K, and Na were performed according to the Standard Methods for the Examination Water and Wastewater [21]. TN of effluents was quantified according to the Kjeldahl semi-micro process with the addition of salicylic acid.\nStatistical analysis\nAll numerical data were subjected to variance analysis [23]. When they were significant at the 5% level, it proceeded to regression analysis and it was adopted the model with the highest coefficient of determination (R2) and that expressed the behavior of the phenomenon. The regression coefficients were subjected to t-test at the 5% level of significance. When the regression model presented the level above 5%, the probability found for the model was used. When the regression model did not explain the phenomenon, the Dunnett\u2019s test was used to compare the GA3 treatments with the control.\nResults and discussion\nYield and vegetative development of Tifton 85 bermudagrass\nIn the first cycle, the parameters plant height, dry matter yield (DMY) and Tifton 85 bermudagrass SPAD index were significantly influenced by various doses of GA3 (Table 7). In the second cycle, plant height was the only significant effect for the levels tested. The productivity of Tifton 85 bermudagrass had no significant effect for the second cycle; the same was true for the SPAD index and number of internodes.\nFig 3 shows the values of Tifton 85 bermudagrass heights of two crop cycles, with a positive effect on growth according to the GA3 doses. A square root model regression was set for each cycle. For the 1st cycle, the model presented p =  by t-test.\nOne of the roles of GA3 is to promote elongation of the stem [12]. This effect was observed in this study for plant height of Tifton 85 bermudagrass (Figs 3 and 4). The increase in plant height is due to the lengthening of the stem internodes, as there was no difference in the number of internodes (Table 7). Comparing the best treatment for plant height (100 \u03bcM GA3) with the control, it is observed an increase of % and % in plant height for the first and second cycles, respectively.\nIn the two cycles observed, the control without the application of GA3 showed lower growth than the other treatments (Fig 3). The Tifton 85 bermudagrass is well suited for the conditions of CWs and may be able to develop aerenchyma in hypoxic conditions [24]. However, it is not considered an aquatic plant, and, in municipal wastewater treatment systems, this plant is grown in media with high concentrations of salts (K and Na). Thus, one can deduce that the grass is growing in abiotic stress conditions. When plants grow under abiotic stress conditions, they have their levels of phytohormones altered and, therefore respond with reduced growth [25].\nWhen studying the effect of exogenous application of GA3 on dwarf rice, a significant increase in plant height was observed compared to a treatment without the phytohormone [26].\nThe increase in height of Tifton 85 bermudagrass in the first cycle was approximately  , being x the doses of GA3, though the increase in the same parameter for the second cycle was  x05. The reduced response to GA3 may be linked to the age of plants because the GA3 response in older tissue was less prominent. Gibberellins are produced in young tissues of the shoot system and developing seeds [27]. The effect of GA3 on plants is influenced by weather conditions [28]; possibly high temperatures in the second cycle negatively affected the induction of Tifton 85 bermudagrass growth.\nThe DMY of aerial parts of Tifton 85 bermudagrass in the first cycle presented a square root behavior for the various doses of GA3 (Fig 5). The highest productivity found in the regression model was  kg ha-1 depending on the optimal dose of 53 \u03bcM GA3. It was observed in the control treatment (0 \u03bcM GA3)  kg ha-1 yield, ., % lower than the yield obtained with the treatment of 50 \u03bcM of GA3.\nThe increase of the DMY in aerial parts of Tifton 85 bermudagrass with the exogenous application of increasing doses of GA3 indicated that the phytohormone plays an important role in the absorption of water and nutrients and processing the accumulation of carbohydrates within plant tissues. The same was observed by Zang during foliar application of GA3 and evaluation of dry matter in blueberry leaves [29].\nThe GA3 stimulates cell division and cell elongation and the exogenous addition of this phytohormone leads to an increase in plant growth, improving the availability of endogenous GA3. This view is supported by Kaur [30] and Tuna [31], working with chickpea and corn, respectively. Arabidopsis thaliana plants treated with GA3 showed a higher shoot development compared to the control treatment [32].\nPlants have an important role in the removal of nutrients in CWs, however, the removal capacity can be improved if crop conditions that allow rapid growth and dry matter production are created [33]. In view of this, the application of GA3 is a viable practice to improve the development of plants, as well as to create conditions to increase the removal of nutrients (pollutants).\nAs for the SPAD index evaluated in the first cycle (Fig 6), an increasing and linear behavior among the different doses of GA3 was observed, indicating a lower chlorophyll content in the treatment without exogenous application of GA3.\nSince the plants were grown in adverse conditions (flooded media and the presence of salts), this lower amount of chlorophyll in the control could be attributed to the formation of proteolytic enzymes such as chlorophyllase, an enzyme responsible for the degradation of chlorophyll [31], which may damage the photosynthetic system. The application of GA3 improved chlorophyll levels in plants grown in CWs.\nThe absence of effect of GA3 for DMY and SPAD index in the second cycle may be related to the period of application of the phytohormone. Some studies reported that GA3 applied during the spring season promotes a high forage growth and that response to the hormone is reduced in summer due to the high temperatures [28]. As can be seen in Fig 2, the maximum and average temperatures in the second crop cycle (near the summer season) were higher than the temperatures in the first cycle. Other factors which may have influenced the absence of effect of GA3 in the second cycle are the age of the plant, space restriction for root growth, and a lower GA3 response in older tissues.\nAbsorption of nutrients and sodium by Tifton 85 bermudagrass\nThe parameters, total nitrogen and total phosphorus accumulation, and total nitrogen uptake rate by Tifton 85 bermudagrass had a significant effect under the different doses of GA3 compared to the treatment without the application of GA3 (Table 8). The same parameters were evaluated in the second cycle and were not significant at the 5% level. That absence of significance could be correlated with the absence of the GA3 effect for the productive parameters of the second cycle.\nThe absence of significant parameters evaluated in the second crop cycle may have occurred due to the room limitation within the reactors for root growth as a function of plant age. Also, the height of the support media was  cm, while Matos, cultivating Tifton 85 bermudagrass in CWs, reported that they reached a depth of 30 cm [34]. Another factor that may have influenced the absence of significant responses was GA3 lower response in older tissues since this hormone is produced in young tissues [27].\nIt is worth mentioning that the experiment aimed to verify the effect of the GA3 application in the same cutting stage of the control without application, but one of the suitable practices of forage cultivation is to establish the cut by height and not by the time of cultivation, so it would be possible to perform more cuts when applied GA3 which would result in greater removals of the pollutants from the CWs.\nIn Fig 7, the effects of the ATN and URTN parameters were adjusted to the square root regression model with p =  and p =  respectively, making it possible to understand the relationship between GA3 doses and TN removal by plants.\nFor the generated model (Fig 7) the highest accumulation and TN uptake rate was  g and  g m-3 d-1 respectively, for the 57 \u03bcM dose of GA3.\nIn the first cycle, GA3 promoted an increase in the DMY of the aerial part of the plants. Associated to this effect, the plants accumulated larger amounts of N resulting in higher rates of removal of this nutrient (Fig 7). Mustard plants accumulated higher amounts of N in the shoots and seeds in treatments with the exogenous application of GA3 [35].\nThe application of GA3 in environmental conditions with a high concentration of atmospheric CO2 promoted a lower concentration of N in Arabidopsis thaliana. However, for environments with different concentrations of CO2, the DMY was higher for the GA3 treatments compared to the control. As a result, plants treated with GA3 had a higher accumulation of nitrogen [32].\nThe accumulation of TP in the aerial part of Tifton 85 bermudagrass is presented in Table 9. Because it did not present a significant regression model to explain the effect of the doses of GA3, the treatments with the control were compared by the Dunnett\u2019s test, where only level 1 (5 \u03bcM GA3) differed from the control level without GA3 application.\nThe treatment with exogenous application of GA3 in a maize crop under salinity conditions increased foliar TP [31]. The higher growth and productivity of Tifton 85 bermudagrass treated with GA3 compared to the control promoted a greater accumulation of TP for the N1 treatment. From the environmental point of view, it is an advantage since it showed that the removal of TP in CWs can be improved with an application of GA3.\nThe efficiency of constructed wetland systems in the removal of pollutants from synthetic municipal wastewater\nThe influent had an average oxidation-reduction potential (ORP) of  mV. Only in three peaks (Fig 8), was it possible to observe ORP above the input value, indicating a small effect of the oxygenation promoted by the root system. This may be an indicator of the formation of aerenchyma by the roots of Tifton 85 bermudagrass. This formation in the plant tissue can be characterized as a mechanism of adaptation in flooded systems. Other studies have described and presented histological sections with the presence of aerenchyma in roots of Tifton 85 bermudagrass in flooded systems [24, 36].\nORP evaluated throughout the experimental period remained between 0\u2013 mV. A critical factor for nitrification would be an ORP above 500 mV [37].\nIn function of the ORP evaluated in the present study, it was possible to indicate that the conditions of the CWs were anoxic/facultative. A classification for the ORP of the medium, ORP above 400 mV has the predominance of O2 (oxidized medium); between 400\u2013200 mV, the presence of O2 and nitrate (NO3-); and below 200 mV indicates low oxygen presence tending to anoxic/facultative conditions [38].\nAfter collecting the effluents, the pH and EC were determined, and their values are presented in Fig 9. The pH of the inlet was on average  and the EC of  \u03bcS cm -1. Except for the NC*, the treatments presented a similar behavior for the parameter pH and EC. In both cycles the pH and EC were higher for the NC*, this allows to understand the importance of the removal of the pollutants (nutrients and Na) and other salts by the plants.\nThe increase in pH in the different treatments may be related to the use of carbon dioxide by plants and algae [5].\nThe pH values ranged from  to  for treatments and control plots, what indicated that SMW (influent and effluent) presented ideal conditions for the survival of microorganisms and for the degradation of organic matter [39]. The optimum range for nutrient absorption is between  and , pH above  causes a great restriction in the availability of micronutrients and P [40].\nThe daily average evaporation and ETc was calculated through the determination of the volume of the input (influent) and the output (effluent) (Fig 10). Subsequently, the mass differences were calculated to express the removal of nutrients and Na. The system without Tifton 85 bermudagrass showed an average evaporation of  mm d-1 and the system with Tifton 85 bermudagrass grass showed an average ETc of the treatments of  mm d-1.\nIt is possible to observe the importance of plant cultivation in CWs since they transform the SMW into water into the atmosphere through transpiration. Thus, in addition to removing the pollutants (nutrients), CWs with plants reduce the volume of sewage for the final disposal.\nThe behavior of TN and TP concentrations in the effluent is shown in Fig 11. Initially, the removal of TN and TP by plants compared to the control without plants was perceptible. The removal of these elements in CWs reduces the N and P disposal into rivers and lakes, these nutrients are essential for the growth and multiplication of algae that are responsible for the eutrophication of the water bodies. Therefore, plants play an important role in the uptake of N in the forms of NO3- and ammonium (NH4+); the ammonium ion can also be adsorbed by plants roots. The sum of these N forms is described as TN [41]. The presence of plants in CWs allows a greater removal of N [42, 43].\nIn the first cycle, the COD removal was higher for the CWs without plants (NC*), and the CWs with the treatment levels N3 and N4 were the ones with the lowest COD removals compared to the two controls (Table 10).\nThe treatments N3 and N4 were those that obtained higher plant height and DMY in comparison with NC (1st cycle) (Table 10). As a result, it was possible to deduce that these treatments presented a greater growth of the roots. The application of GA3 can stimulate root growth [12]. Together with the greater development of the aerial part, these treatments may have released more exudates through the root system, resulting in higher concentrations of COD in the effluents. Exudates are secretions that release ions, free oxygen, water, enzymes, mucilage and a diversity of primary and secondary metabolites with carbon in their composition [44].\nIn the second cycle, the NC* treatment presented a lower COD concentration when compared to N1 and N4. The treatments that received gibberellin (5, 50 and 100 \u03bcM GA3) did not differentiate from the NC control. This lower COD efficiency removal in treatments with the presence of Tifton 85 bermudagrass may be related to the release of root exudates and plant senescence.\nFor the nutrients, Na, and TDS all treatments were superior to NC*, demonstrating the importance of plant species in CWs.\nThe treatment with 50 \u03bcM of GA3 showed a greater removal of TP and Na from the SMW compared to NC and NC* controls by the Dunnet\u2019s test. This fact is interesting because P is one of the main nutrients responsible for eutrophication of rivers and lakes and this nutrient must be removed to comply with the legislation of disposal of effluents in water bodies. Although the efficiency of removal of TP is greater than 90% in N3, it does not comply with the legislation of Minas Gerais [45] that ranges from  to  mg L-1, being necessary to associate with another treatment system or recirculate therein system.\nThe total efficiency of CWs was obtained through the system-substrate-plant-micro-organism interaction and solar radiation. In this study, the reason for the high efficiency of nutrient removal by plants was due to the low load applied, even though this load was sufficiently great to verify the effect of GA3 on nutrient removal by plants, thus meeting the initial objective of the work.\nThe efficiency of municipal wastewater treatment of subsurface vertical flow constructed wetland cultivated with vetiver grass, observed a removal of TN of % and for TP of % for application rates of  and  g m-2 d-1, respectively [46]. These efficiencies and application rates were similar to the ones in the present study.\nThe TN uptake rate by the Tifton 85 bermudagrass treated with 50 \u03bcM of GA3 was  g m-2 d-1 of TN, as a function of an application rate of  g m-2 d-1 of TN through SMW (Table 11).\nThe TN removal in the present study was higher than the values observed by Matos (2008), Fia (2011) and Matos (2010) [9, 34, 47]. These authors found removals of ,  and  g m-2 d-1 TN from the aerial parts of Tifton 85 bermudagrass, respectively. Only Fia (2011) worked with a high rate of TN application, around  g m-2 d-1 TN, via swine wastewater [47].\nJesus (2016) observed removals of  g m-2 d-1 when treating municipal wastewater with TN application rates equal to  g m-2 d-1 in CWs with Tifton 85 bermudagrass. These values of application and removal rates were higher than the ones in the present study [48].\nAlthough the use of GA3 showed potential for nutrient removal via biomass of Tifton 85 bermudagrass cultivated in CWs in the treatment of SMW, it would be interesting to conduct further field testes with higher load applications.\nAn application of GA3 in spring and another in autumn resulted in the increased dry mass of azevem and white clover [49]. Thus, responses to GA3 strongly depend on the time of year in which the plants were treated. And for perennial crops such as Tifton 85 bermudagrass, GA3 may be interacting with a fixed strategy for seasonal plant growth [50].\n21.\nAmerican Public Health Association, American Water Works Association, Water Environmental Federation. Standard methods for examination of water and wastewater. Washington: United Book Press; 2012; 1496 p.", 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:35Z', 'description': u'by Marie Moitry, Kevin Zarca, Mich\xe8le Granier, Marie-St\xe9phanie Aubelle, Nathana\xebl Charrier, Brigitte Vacherot, Georges Caputo, Maroua Mimouni, Pierre-Henri Jarreau, Isabelle Durand-Zaleski\n\nIn France, secondary care hospitals encounter difficulties to adhere to retinopathy of prematurity (ROP) screening guidelines. Our objective was to assess the effectiveness and efficacy of a tele-expertise program for ROP screening in neonatal intensive care units without on-site ophthalmologists. We evaluated the impact of a tele-expertise program funded by the Paris Region Health Authority in a secondary care center general hospital of the Paris Region (CHSF), where there was previously no on-site ophthalmologist. We performed an observational, controlled before-after study, with a university tertiary care center with on-site ophthalmologists (Port-Royal) as the control group. Recruitment and data collection for both periods took place from 1 January 2012 to 31 December 31 2012, and from 1 January 2014 to 31 March 2015. The primary endpoint was the percentage of compliance with screening guidelines, secondary endpoints included pain scores and costs. Over the two periods, at total of 351 infants were recruited in the CHSF. Implementation of the tele-expertise resulted in an absolute +% increase in the proportion of examinations realized in accordance with guidelines (% during the "before" period and % during the "after" period, p<). As compared with the control group, the proportion of infants appropriately screened improved (% versus %, p = ); median pain score on the acute pain rating scale for neonates during examination was significantly higher (median score /10, range [\u2013] versus /10, range [\u2013], p = ). Screening rates in the control group remained unchanged. The average cost per examination increased from \u20ac337 in the "before" period to \u20ac353 in the "after period" in the tele-expertise group. The implementation of tele-expertise for ROP screening in the CHSF medical center resulted in a major improvement of access to care with a small cost increase. The issue of pain control during examination with tele-expertise should be further addressed.', 'title': u'Effectiveness and efficiency of tele-expertise for improving access to retinopathy screening among 351 neonates in a secondary care center: An observational, controlled before-after study', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206375', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Effectiveness and efficiency of tele-expertise for improving access to retinopathy screening among 351 neonates in a secondary care center: An observational, controlled before-after study\n\nFigures\nAbstract\nIn France, secondary care hospitals encounter difficulties to adhere to retinopathy of prematurity (ROP) screening guidelines. Our objective was to assess the effectiveness and efficacy of a tele-expertise program for ROP screening in neonatal intensive care units without on-site ophthalmologists. We evaluated the impact of a tele-expertise program funded by the Paris Region Health Authority in a secondary care center general hospital of the Paris Region (CHSF), where there was previously no on-site ophthalmologist. We performed an observational, controlled before-after study, with a university tertiary care center with on-site ophthalmologists (Port-Royal) as the control group. Recruitment and data collection for both periods took place from 1 January 2012 to 31 December 31 2012, and from 1 January 2014 to 31 March 2015. The primary endpoint was the percentage of compliance with screening guidelines, secondary endpoints included pain scores and costs. Over the two periods, at total of 351 infants were recruited in the CHSF. Implementation of the tele-expertise resulted in an absolute +% increase in the proportion of examinations realized in accordance with guidelines (% during the "before" period and % during the "after" period, p<). As compared with the control group, the proportion of infants appropriately screened improved (% versus %, p = ); median pain score on the acute pain rating scale for neonates during examination was significantly higher (median score /10, range [\u2013] versus /10, range [\u2013], p = ). Screening rates in the control group remained unchanged. The average cost per examination increased from \u20ac337 in the "before" period to \u20ac353 in the "after period" in the tele-expertise group. The implementation of tele-expertise for ROP screening in the CHSF medical center resulted in a major improvement of access to care with a small cost increase. The issue of pain control during examination with tele-expertise should be further addressed.\nData Availability: The data were entirely processed by the research unit DRCI-URC Eco and were not transferred anywhere. The procedures carried out with the French data privacy authority (Commission nationale de l\'informatique et des libert\xe9s, CNIL) do not provide for the transmission of the database. The French law named "Informatique et Libert\xe9" prevents the authors from sharing the data or making it publicly available, even if they have previously been unidentified. Therefore access to the data is currently restricted the DRCI-URC Eco, and, as things stand, it is not possible to transfer the data to another structure. Consultation by the editorial board or interested researchers may nevertheless be considered, subject to prior determination of the terms and conditions of such consultation and in respect for compliance with the applicable regulations. To transfer the data to another structure, a specific request for authorization must be made to the CNIL (-un-fichier). To be more precise, the path to follow is: 1- Interested researchers request the unit responsible for data processing: @ or secretariat@urc- 2- URC Eco fills a request for modification of the initial authorization for the new recipient to the CNIL 3- URC Eco gets the authorization and sends the data to the new recipient This process is accessible for both reviewers and other interested researchers after publication.\nFunding: This study was supported by the Regional Health Authority of the Paris Region (to IDZ). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nRetinopathy of prematurity (ROP) is a development disorder of the retina vasculature that affects approximatively 184,700 infants worldwide, with more than 50,000 progressing to potentially visual-impaired diseases [1]. In high-income countries, it affects % of surviving infants born before a Gestational Age (GA) of 32 weeks and is a leading cause of childhood blindness. ROP progression to visual impairments can be largely avoided with treatments that have proved their effectiveness [2,3] provided that screening is performed in accordance with the recommended guidelines: at post menstrual age of 31 weeks for infants born with GA of less than 28 weeks, at post menstrual age of 32 weeks for infants born with GA of 28 weeks, and at 4 weeks of chronological age for infants born after GA of 28 weeks (American Academy of Pediatrics, [4]). In France, as hospital-based ophthalmologists are increasingly rare with less than 800 in Metropolitan France in 2016 [5], tertiary as well as secondary care hospitals encounter difficulties to adhere to screening guidelines. These hospitals suffer from recurrent delays in screening and in treatment of retinal lesions. To address this issue of delayed access to care, a pilot tele-expertise project was implemented by the regional health authority in a secondary care center of the Paris region [6]. The screening consisted in a fundus examination performed with a digital camera and remote interpretation of images by an experimented ophthalmologist. Considering that all pediatricians should be able to handle the camera for providing pictures analyzed by an expert and that tele-expertise for ROP screening has recently shown good results in both effectiveness and cost-effectiveness [7,8], we hypothesized that it would substantially improve ROP screening in the CHSF center with some increase in cost due to the current high costs of its required equipment. Our objective was to assess the effectiveness and efficiency of the implementation of tele-expertise program for ROP screening in neonatal intensive care units without on-site ophthalmologists.\nMaterial and methods\nParticipants\nInfants born before GA of 33 weeks and/or with a birth weight inferior to 1500 grams hospitalized in neonatal intensive care units (NICU) and without cerebral malformations were eligible. Infants deceased during their hospitalization were not included.\nStudy design and settings\nThe implementation of a telemedicine program was decided by the regional health authority in a general hospital located in the South of the Paris Region (CHSF, Centre Hospitalier Sud Francilien, 5,163 deliveries in 2015 [9]), where there was no on-site ophthalmologist. We performed an observational, controlled before-after study with a university tertiary care center, located in the center of Paris (Port-Royal, 5,036 deliveries in 2015 [9]), and staffed with dedicated pediatric ophthalmologists who performed on site examinations as the control group. Recruitment in the "before" period took place from 1 January 2012 to 31 December 2012, and in the "after" period from 1 January 2014 to 31 March 2015.\nStandard procedure\nOphthalmologists performed a funduscopic examination using a binocular indirect ophthalmoscopy technique. In the CHSF center, as there was no on-site ophthalmologist, premature infants were either transported to a tertiary care center with specialized pediatric ophthalmologists, before their discharge from the hospital\u2013providing a consultation was available at that time\u2013or after discharge. In the control university tertiary care hospital, the on-site pediatric ophthalmologist visited the ICU department for eye examination.\nTele-expertise procedure\nThe first step of the examination was to perform a topical anesthesia with one drop of oxibuprocaine chlorohydrate instilled in each eye. Pupils were dilated 45 minutes before the examination with a combination of one instillation of % phenylephrine and 3 instillations of % tropicamide eye drops given 15 minutes apart. A few minutes before the examination, oral saccharose was given by sucking with a pacifier. A drop of local vasoconstrictor (phenylephrine) and an eyelid speculum (disposable or sterilized, suitable to child\'s size) were applied, and then a contact gel so that the camera could be placed over the cornea. After the pictures were taken with the Retcam, the camera was cleaned with an aqueous solution of sodium hypochlorite and sodium chlorite then rinsed with sterile water. The speculum was removed and cardiovascular and respiratory functions were monitored for at least 30 minutes for a hospitalized infant and one hour for an infant coming for an external visit. Once the pictures were uploaded to a secure server, they were reviewed and interpreted on a computer by a specialized pediatric ophthalmologist of the ophthalmologic department of the Rothschild foundation. No other resources were required.\nOutcomes and data sources\nWe used the MAST model (Model of Assessment of Telemedicine Applications) [10] in order to perform a multidimensional assessment. MAST is a framework for assessing the value of telemedicine that is based on the core health technology assessment model. We collected results of clinical effectiveness, patient perspective, economic aspects and organizational aspects.\nEffectiveness\nData were collected in both centers (CHSF and Port-Royal) during both periods (before and after). The following variables were recorded: sex, birth date, GA, birth weight, height and head circumference, dates of entry and discharge from NICU, date of eye examination, procedure (tele-expertise or usual care) and destination at hospital discharge (transfer to another center, return home, death). The primary outcome was the proportion of infants having a ROP screening within the guidelines of the American Academy of Pediatrics [4]. We considered that examination satisfied the primary outcome if it occurred at the theoretical recommended date +/- 6 days. The secondary endpoint was deviation from guidelines computed as the interval between recommended and effective date of examination.\nPatient perspective\nIndependently of the main study, a small sample of infants was recruited during the "after" period in the CHSF (tele-expertise) and Port-Royal (on-site examination) hospitals to compare pain scores between the two techniques. The following variables were recorded using a specific case report form: GA at birth and at examination date, weight at examination date, drug or non-drug treatments administrated, heart rate, saturation oxygen levels and pain scores before, during and after examination. We assessed pain scores during eye examination based on the validated APN pain scale (Acute Pain rating scale for term and preterm Neonates) [11]. This scale evaluates three items: facial expression, limb movements, and vocal expression with ratings per item ranging from 0 to 4, 0 to 3 and 0 to 3, respectively.\nCost analysis\nCosts before and after the implementation of tele expertise were estimated for the Centre Hospitalier Sud Francilien. The cost analysis was conducted from the hospital perspective using tariffs as a proxy for the costs when production costs were not accessible. Unit costs are presented in Table 1. All costs are in 2017 euros (US$1 = \u20ac). For usual care (before period in the CHSF), as there was no on-site ophthalmologist, the operating cost of one request was calculated by adding the cost of transportation to the tariff of the examination.\nInvestment costs associated with tele-expertise comprised the acquisition of the camera and the software. Operating costs included costs of maintenance of the camera and software subscription. Human resources costs were obtained with a micro-costing top-down approach, based upon time needed for one examination in the requesting (CHSF hospital) and the specialist institution (Rothschild Foundation). Overall cost of a fundus examination was calculated with respect to the number of requests per year, on the basis of a 5-year depreciation period and a 4% discount rate for the tele-expertise equipment.\nSensitivity analysis\nTo assess the cost drivers of eye examination using the Retcam, we performed several scenario analyses by varying the following parameters: purchase price of the Retcam (from -50% to +10%), completion time for one request (from -20% to +20%), qualification of the two health care professionals taking the pictures with the camera (whether it was one physician and one nurse or two nurses; whether the physician was a fellow or a professor), depreciation period (from 2 to 10 years) and discount rate (from 0% to 5%). We plotted results from scenario analyses on a tornado diagram.\nTrial registration and ethics approval\n: NCT02157727\nThe ethics approval was given by the "Comit\xe9 Consultatif sur le Traitement de l\u2019Information en mati\xe8re de Recherche dans le domaine de la Sant\xe9" (CCTIRS), number . It approved the lack of parent or guardian consent in the decision, as every effort has been made to provide information to parents.\nData were fully unidentified prior access to authors.\nStatistical methods\nData were described as numbers and percentages, means and standard deviations or medians and ranges. Comparisons were performed using Chi-squared test, Student or Kruskall and Wallis tests, as appropriate. We performed intention-to-treat analyses. For the primary outcome, a logistic regression model was used to assess effectiveness of the intervention adjusted on sex and (GA) at birth. All tests were two-tailed and significance level was set at . Analyses were carried out using SAS version  (SAS Institute, Cary, NC, USA).\nResults\nOverview\nIn the CHSF hospital, 158 infants were recruited during the "before" period. During the "after" period, among the 193 infants included, 149 were examined with the Retcam (%). In the hospital center of Port-Royal, 217 and 269 infants were recruited respectively during the "before" and "after" periods.\nNo significant differences regarding distributions by sex, GA and birth weight at baseline were observed between the "before" and "after" periods in the CHSF hospital (Table 2). In the Port-Royal hospital, distribution of infants according to gestational age (GA) at birth significantly differed between the before and the "after" period (Table 3). The proportion of infants with a birth weight lower than 1500g decreased between the two periods (% versus %, p<) despite an increase in absolute number (223 versus 214).\nWork flow\nThe workflows for one examination with and without tele-expertise are detailed in Figs 1 and 2. For the standard procedure, depending on the on-course step, it mobilized either one physician, one nurse, or both and lasted an average of 9 minutes (bottom-up approach). Because of losses of ttime experimented between two examinations (. solicitation of the physician or the nurse for other tasks) or examinations that sometimes lasted longer than expected, the number of examinations actually performed during a 120-minutes timeframe (top-down approach) was estimated at 8. With tele-expertise, an average of 72 minutes was necessary for eye examination performance and analysis, with about 23 minutes for taking the pictures. The ophthalmologist of the specialist institution (Rothschild) indicated that during a 240-minutes timeframe, an average of 8 patients were analyzed, corresponding to a 30 minutes examination.\nEffectiveness\nImplementation of the tele-expertise resulted in an absolute +% increase in the proportion of fundus examinations realized in accordance with the guidelines (% in the "before" period versus % in the "after" period, p<) as well as a significant decrease in the deviation from guidelines regarding the time between birth and examination ( days versus  days, p<) (Table 2) Multivariate analyses confirmed that implementation of tele-expertise significantly increased the probability for infants to be appropriately screened (OR =  CI95 [\u2013], p<).\nBetween the two periods in the control group (Port-Royal), we found no significant difference relative to the primary outcome: % (N = 93) of infants were screened in accordance with guidelines during the "before" period as compared with % (N = 120) during the "after" period. The percentage of appropriate screening in the control hospital was significantly lower than the % observed in the CHSF medical center (p = , Table 4). Multivariate analysis confirmed this finding (OR =  CI95 [\u2013]).\nPatient perspective\nData on pain during examination were collected for 56 infants (13 in Port-Royal and 43 in the CHSF center). For 2 infants, data were missing. Characteristics of infants according to the center are detailed in Table 5. No significant differences regarding distributions by GA at birth, or birth and weight at examination date observed between the Port-Royal and the CHSF medical centers (Table 2). Drug and non-drug treatments were almost systematically administrated for eye examination with the RETCAM. Median pain score evaluated during examination was significantly higher among infants examined with tele-expertise as compared with infants receiving usual eye examination (/10, range [\u2013] versus /10, range [\u2013], p = ). Heart rates were also increased when the RETCAM was used (190. 0 range [\u2013] versus  range [\u2013], p = ).\nCost analysis\nOverall cost of one eye examination using the standard procedure (transfer to the specialized center and examination by a specialist) was estimated to be 337\u20ac. On the basis of 200 examinations per year, it reached \u20ac353 with tele-expertise (base-case curve, Fig 3). Results of scenario analyses are presented on the tornado diagram in Fig 4. It appeared that depreciation period had the greatest impact on the overall cost of one examination, which ranged from \u20ac582 for a 2-years depreciation period to \u20ac278 for a 10-years period.\nDiscussion\nThe implementation of a tele-expertise procedure in a hospital center with a large maternity ward and without an on-site ophthalmologist was effective with an absolute increase of +% of infants screened in accordance with guidelines for the diagnosis of retinopathy of prematurity. This major improvement was confirmed when analysis was adjusted on age at birth and sex. The overall cost, taking account investment and operating costs were almost the same (\u20ac337 for the transfer and examination of newborns in a specialized center vs \u20ac353 for the onsite examination and tele-expertise).\nAll around the world, several other telemedicine experiments have been described in countries where either the long distances or the lack of trained specialists is a severe limitation to compliance with ROP screening guidelines [12,13]. These are not necessarily developing countries but for example USA [14], Canada [15], Australia [16], Chile [17] and India [18]. Our results are consistent with previous findings and provide new arguments in favour of tele-medicine programs in understaffed hospitals.\nSeveral methodological aspects require to be addressed. First, the choice of the outcome for effectiveness can be discussed. In the end, the goal of screening is to identify infants that need to be treated for ROP. Respect of screening timetable is a surrogate endpoint that does not directly predict the effect of the Intervention on the reduction of ROP incidence. However, in this study, we addressed the value of tele-expertise from a public health perspective. The objective was not to assess effectiveness of such a program to detect and treat ROP, which has been largely reviewed [13,19\u201321], but whether its implementation enabled an improvement in access to care in medical centers with limited medical resources. We therefore did not collect data on examination results or treatments.\nOne of the limits of our study was that costs for an examination were not prospectively collected for every infant, and individual costs of procedures could therefore not be estimated. In particular, for the "before" period in the CHSF medical center, we had no information on medical transportation after patient discharge, and the cost analysis was performed assuming that the performance of one examination systematically implied medical transportation.\nInfants that underwent RETCAM examination faced a higher pain level during examination, with a median score reaching /10 versus /10 with a standard examination. This can be explained by a longer examination time (Fig 2), by a greater mobilization of the child (local anesthesia, pupillary dilation, placing of a lid speculum, application of the camera on the eye, etc.) and by professionals\' lack of practice at the time of the study. A few studies compared pain of infants during examination with and without tele-expertise and found differing results, suggesting that there is still room for improvement of pain control [22\u201325].\nConclusions\nThe implementation of tele-expertise for ROP screening in the CHSF medical center resulted in a major improvement of access to care with only a small cost increase. In the future, costs using tele-expertise could be reduced by negotiating the purchase price of equipment or implementing specific training for physicians or non physicians [26,27]. Patient outcomes, especially regarding pain control, are yet to be further assessed and improved [21].\nAcknowledgments\nThis study was supported by the Regional Health Authority of the Paris Region.\nThe authors are deeply indebted to Ms Meryl Darlington (URC Eco Ile-de-France (AP-HP), Paris, France) for her insightful comments on the manuscript.\n3.\nGood WV, The Early Treatment for Retinopathy of Prematurity Cooperative Group. The Early Treatment for Retinopathy Of Prematurity Study: structural findings at age 2 years. Br J Ophthalmol. 2006 Nov 1;90(11):1378\u201382. pmid:16914473\n4.\nFierson WM, American Academy of Pediatrics Section on Ophthalmology, American Academy of Ophthalmology, American Association for Pediatric Ophthalmology and Strabismus, American Association of Certified Orthoptists. Screening examination of premature infants for retinopathy of prematurity. Pediatrics. 2013 Jan;131(1):189\u201395. pmid:23277315\n21.\nFierson WM, Capone A, American Academy of Pediatrics Section on Ophthalmology, American Academy of Ophthalmology, American Association of Certified Orthoptists. Telemedicine for evaluation of retinopathy of prematurity. Pediatrics. 2015 Jan;135(1):238\u201354.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:38Z', 'description': u'by Joann Romano-Keeler, Meghan H. Shilts, Andrey Tovchigrechko, Chunlin Wang, Robert M. Brucker, Daniel J. Moore, Christopher Fonnesbeck, Shufang Meng, Hernan Correa, Harold N. Lovvorn III, Yi-Wei Tang, Lora Hooper, Seth R. Bordenstein, Suman R. Das, J\xf6rn-Hendrik Weitkamp\nObjective Necrotizing enterocolitis (NEC) is the most common surgical emergency in preterm infants, and pathogenesis associates with changes in the fecal microbiome. As fecal samples incompletely represent microbial communities in intestinal mucosa, we sought to determine the NEC tissue-specific microbiome and assess its contribution to pathogenesis. Design We amplified and sequenced the V1-V3 hypervariable region of the bacterial 16S rRNA gene extracted from intestinal tissue and corresponding fecal samples from 12 surgical patients with NEC and 14 surgical patients without NEC. Low quality and non-bacterial sequences were removed, and taxonomic assignment was made with the Ribosomal Database Project. Operational taxonomic units were clustered at 97%. We tested for differences between NEC and non-NEC samples in microbiome alpha- and beta-diversity and differential abundance of specific taxa between NEC and non-NEC samples. Additional analyses were performed to assess the contribution of other demographic and environmental confounding factors on the infant tissue and fecal microbiome. Results The fecal and tissue microbial communities were different. NEC was associated with a distinct microbiome, which was characterized by low diversity, higher abundances of Staphylococcus and Clostridium_sensu_stricto, and lower abundances of Actinomyces and Corynebacterium. Infant age and vancomycin exposure correlated with shifts in the tissue microbiome. Conclusion The observed low diversity in NEC tissues suggests that NEC is associated with a bacterial bloom and a distinct mucosal bacterial community. The exact bacterial species that constitute the bloom varied by infant and were strongly influenced by age and exposure to vancomycin.', 'title': u'Distinct mucosal microbial communities in infants with surgical necrotizing enterocolitis correlate with age and antibiotic exposure', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206366', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Distinct mucosal microbial communities in infants with surgical necrotizing enterocolitis correlate with age and antibiotic exposure\n\nAffiliations\nDepartment of Medicine, Vanderbilt University Medical Center, Nashville, Tennessee, United States of America,\nResearch Bioinformatics, Medimmune, Gaithersburg, Maryland, Tennessee, United States of America\nAffiliations\nDepartment of Pediatrics, Vanderbilt University, Nashville, Tennessee, United States of America,\nDepartment of Pathology, Microbiology & Immunology, Vanderbilt University, Nashville, Tennessee, United States of America,\nVanderbilt Institute for Infection, Immunology and Inflammation, Vanderbilt University Medical University, Nashville, Tennessee, United States of America\nAffiliations\nDepartment of Medicine, Vanderbilt University Medical Center, Nashville, Tennessee, United States of America,\nVanderbilt Institute for Infection, Immunology and Inflammation, Vanderbilt University Medical University, Nashville, Tennessee, United States of America\nAffiliations\nDepartment of Pediatrics, Vanderbilt University, Nashville, Tennessee, United States of America,\nVanderbilt Institute for Infection, Immunology and Inflammation, Vanderbilt University Medical University, Nashville, Tennessee, United States of America\nFigures\nAbstract\nObjective\nNecrotizing enterocolitis (NEC) is the most common surgical emergency in preterm infants, and pathogenesis associates with changes in the fecal microbiome. As fecal samples incompletely represent microbial communities in intestinal mucosa, we sought to determine the NEC tissue-specific microbiome and assess its contribution to pathogenesis.\nDesign\nWe amplified and sequenced the V1-V3 hypervariable region of the bacterial 16S rRNA gene extracted from intestinal tissue and corresponding fecal samples from 12 surgical patients with NEC and 14 surgical patients without NEC. Low quality and non-bacterial sequences were removed, and taxonomic assignment was made with the Ribosomal Database Project. Operational taxonomic units were clustered at 97%. We tested for differences between NEC and non-NEC samples in microbiome alpha- and beta-diversity and differential abundance of specific taxa between NEC and non-NEC samples. Additional analyses were performed to assess the contribution of other demographic and environmental confounding factors on the infant tissue and fecal microbiome.\nResults\nThe fecal and tissue microbial communities were different. NEC was associated with a distinct microbiome, which was characterized by low diversity, higher abundances of Staphylococcus and Clostridium_sensu_stricto, and lower abundances of Actinomyces and Corynebacterium. Infant age and vancomycin exposure correlated with shifts in the tissue microbiome.\nConclusion\nThe observed low diversity in NEC tissues suggests that NEC is associated with a bacterial bloom and a distinct mucosal bacterial community. The exact bacterial species that constitute the bloom varied by infant and were strongly influenced by age and exposure to vancomycin.\nData Availability: All sequences reported in this paper have been deposited into the NCBI sequence short read archive (accession numbers SRR7993700-SRR7993745).\nFunding: This work was supported by the American Academy of Pediatrics Marshall Klaus Perinatal Research Award (to .) and the Eunice Kennedy Shriver National Institute Of Child Health & Human Development (NICHD) [T32HD068256 (to .), K08HD061607 (to .)]; the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) [K08DK090146 (to .)], the National Institute of Health (NIH) Division of Loan Repayment National Institute of Diabetes and Digestive and Kidney Diseases Award (to .), the National Science Foundation [DEB-1046149] and The Vanderbilt Microbiome Initiative (to .), and U19AI095227 and P30 AI110527, the National Institute of Allergy and Infectious Diseases (NIAID) (to .). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NICHD, NIDDK, NIAID or the National Institutes of Health (NIH). This project was also funded by the Vanderbilt Digestive Disease Research Center [P30DK058404], Vanderbilt Diabetes Center [P30DK20593], and the Vanderbilt CTSA Grant UL1 RR024975-01 from the National Center for Research Resources (NCRR/NIH). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nNecrotizing enterocolitis (NEC) is a common and frequently fatal intestinal complication in premature infants [1,2]. Experiments in germ-free animals and toll-like receptor targeted knock out mice strongly suggest a bacterial antigen is critical for the initiation of intestinal inflammation and NEC development [3\u20136]. Bacterial DNA is present in larger quantities in acute human NEC specimens compared to samples collected after NEC has clinically resolved [7]. A number of different gram-positive and gram-negative bacteria as well as viruses have been associated with NEC [8]. Indeed, microbial community studies using 16S rRNA gene sequencing of the fecal microbiome demonstrate a reduction in microbial community diversity with a shift towards potentially pathogenic subgroups [9\u201312].\nWe previously detected significant differences in the microbiome between surgical tissue and parallel collected fecal samples in preterm infants without NEC [13]. We hypothesized the existence of a specific microbial profile at the site of injury in the small intestinal mucosa of premature infants with NEC that has not been previously recognized in fecal microbiome studies. Hence, we sought to interrogate differences in the tissue-level and fecal microbiomes in infants with and without NEC to determine bacterial communities at the site of injury and their representation in feces. As intestinal tissue cannot ethically be collected from healthy infants, we included infants with intestinal diseases other than NEC in this study for comparison. We detected a statistically significant increase in the abundance of Staphylococcus and Clostridium_sensu_stricto in NEC compared to non-NEC tissue samples when controlling for age and history of antibiotic exposure.\nMaterials and methods\nEthics statement\nThis study was approved by the Vanderbilt University Institutional Review Board (protocol number 090161). All infants hospitalized at the Monroe Carell Jr. Children\u2019s Hospital at Vanderbilt were eligible for the study if they underwent intestinal resection at <180 days of age. We obtained written informed consent from parents, the next of kin, caretakers, or guardians on behalf of the minors/children enrolled in the study to permit collection of tissue and metadata from the medical records including gestational age, birth weight, race, sex, mode of delivery, maternal or fetal indications for delivery, antibiotic exposure, enteral feeding regimens, diagnoses and type of surgical resection.\nSample collection\nTissue collected at the time of surgery was gently rinsed with sterile saline solution, and immediately cryopreserved in sterile containers [13]. Fecal material was collected by either taking the patient\u2019s first post-operative stool or by scraping surgical tissue; samples were immediately cryopreserved (Table 1). The clinical and intraoperative diagnosis of NEC was confirmed by a pediatric pathologist after histologic examination of the resected specimen and by review of the operative and surgical pathology reports.\nDNA extraction and amplification of 16S rRNA gene\nWe extracted DNA from fresh NEC and non-NEC surgical tissue and corresponding fecal samples as previously described [13]. Briefly, we extracted DNA from 15\u201325 mg of intestinal tissue and 180\u2013200 mg of feces and amplified the V1-V3 hypervariable region of bacterial 16S rRNA with previously validated primers: 5F (5\u2019-TGGAGAGTTTGATCCTGGCTCAG-3\u2019) and 532R (5\u2019-TACCGCGGCTGCTGGCAC-3\u2019) [14]. PCR was conducted as described [13] and barcoded amplicons were gel purified (Qiagen), quantified, and pooled prior to sequencing on a 454 FLX Titanium sequencer. Sequencing negative controls\u2014template-free sterile water, processed with the same DNA extraction and PCR amplification kits as the real samples\u2014were sequenced on the same run [15].\nPyrosequencing and data analysis\nSequences generated from the pyrosequencing of barcoded 16S rRNA gene PCR amplicons were analysed using mothur (http://) [16] by following the 454 SOP as of 13 March 2017. Sequences were aligned to the SILVA database release 123 [17] and taxonomically classified with the Ribosomal Database Project (RDP) classifier 11 [18]. Chimeric sequences as detected by UCHIME were removed [19]. OTUs were clustered at 97% similarity. Prior to statistical analysis, samples with <400 reads were discarded (N = 3).\nPhylogenetic Investigation of Communities by Reconstruction of Unobserved States (PICRUSt) was used to predict metagenomic and functional composition of the samples from 16S rRNA sequences [20]. Prior to PICRUSt analyses, closed reference OTUs were picked against the GreenGenes database 13_5 [21] using uclust [22] in QIIME  [23]; taxonomy assignments were made using the RDP Classifier  [24]. Functions of genes were assigned using the KEGG Orthology database [25].\nStatistical analysis was performed in R using MGSAT (https:///andreyto/mgsat), which wraps a number of R packages, including vegan [26] to perform alpha- and beta- diversity analyses and DESeq2 [27], GeneSelector [28], and stabsel [29] for testing taxonomic associations with metadata. When testing taxonomic associations with metadata, we report the q-values computed with the Benjamini & Hochberg false discovery rate method to adjust for multiple comparisons [30].\nFor diversity and richness estimates, full count matrices as produced by the mothur annotation were used [31]. To compare microbial alpha diversity estimates between groupings, we estimated Shannon-Wiener (H\') and Simpson\u2019s diversity indices; to compare microbial richness estimates, we estimated observed OTUs and calculated S. chao1 estimates. Counts were rarefied to the lowest library size of all the samples (number of reads per sample = 445), and then abundance-based and incidence-based alpha diversity indices and richness estimates were computed. This was repeated multiple times (n = 400), and the results were averaged. Incidence-based estimates were computed on pools of observations split by the relevant metadata attribute, and in each repetition, observations were also stratified to balance the number of observations at each level of the metadata attribute. Inverted Simpson and Shannon diversity indices were converted into corresponding Hill numbers [32]. Linear models were fit to test for associations between abundance-based richness and diversity estimates and metadata attributes.\nWe applied the PermANOVA (permutation-based analysis of variance) [33] test of statistical significance (as implemented in the Adonis function of the R vegan package) [34] on the association between the abundance profile dissimilarities and the metadata variables. We used the Bray-Curtis dissimilarity index [35] and 4000 permutations. The counts were normalized to simple proportions within each observation.\nWhen differential abundance analysis was performed, in order to remove the likely non-informative features and to reduce the associated penalty from the multiple testing correction applied after univariate tests, we used unbiased metadata-independent filtering at each taxonomy level by eliminating all taxa that were detected with a mean proportional abundance of less than . The absolute counts from the removed features were aggregated into a category "other," which was taken into an account when computing simple proportions during data normalization, but were otherwise discarded. When testing taxonomic associations with metadata, for each feature, we also obtained, from the same test done on the full dataset, the p-value computed using the test implementation from R exactRankTests package [36], the q-value computed with the Benjamini & Hochberg false discovery rate method in the package function  [37], and several types of the effect size such as common language effect size and rank biserial correlation [38]. To evaluate the influence of confounders, models were built in DESeq2 with pre-selected covariates added in.\nStabsel is a stability selection approach implemented in the R package stabs [29]. This feature selection method implements a stability selection procedure described in [39] with the improved error bounds described in [40]. Elastic net (from R package glmnet [41]) was used as the base feature selection method that was wrapped by the stability protocol. For groupings with two factor levels, a binomial family model was built with the grouping as a response and the matrix of the abundance values as predictors. The mixing parameter \u03b1 of glmnet was selected based on a 15-fold cross-validation minimizing deviance on the full dataset. The predictors were first normalized to simple proportions within each multivariate observation, transformed with the inverse hyperbolic sign , and then standardized to zero means and unit variances. With its multivariate base feature selection method, this protocol can potentially detect those correlated groups of biologically relevant features that will be missed by the univariate methods. The ranking of taxa and their probability of being selected into the model were reported, as well as the probability cutoff corresponding to the per-family error rate (PFER) that is controlled by this method. Our PFER cutoff was set to , and the target number of features selected by the base classifier was set to where p is the total number of features (39). In our experience with omics datasets, the PFER control in this method is fairly conservative, and we typically look at the ranking of features as opposed to only concentrating on features that pass the PFER cutoff.\nData deposition\nAll sequences reported in this paper have been deposited into the NCBI sequence short read archive (accession no. SRR7993700-SRR7993745).\nResults\nDemographic and antimicrobial exposure characteristics were similar between NEC and non-NEC infants\nWe collected and analyzed fresh surgical tissue and corresponding fecal samples from 10 patients with NEC and 14 patients without NEC; in total, 44 samples were analyzed (fecal N = 21; tissue N = 23) (Table 1). Surgical samples included patients with spontaneous intestinal perforations, ileal and jejunal atresias, midgut volvulus, and mesenteric ischemic bowel injuries. Mean gestational age, birth weight and postnatal age were 29 weeks (range 25\u201333 weeks), 1,274 grams (range 440\u20132,101 grams), and 17 days (range 5\u201346 days) for NEC infants and 30 weeks (range 24\u201339 weeks), 1,662 grams (range 650\u20133,454 grams), and 31 days (0\u2013132 days) for non-NEC patients, respectively (all t-tests p>). Female infants represented 60% and 50% of the study population in the NEC and non-NEC groups, respectively. Except for two colon samples among the non-NEC group and two colon samples within the NEC group, all analyzed tissues were from the ileum or jejunum. For the non-NEC group, one fecal sample (C5) was adherent to the mucosa when collected, for the NEC group there was one (N27). All but one infant from the non-NEC group had perinatal antibiotic exposure. Mean number of antibiotic exposure days prior to surgery were less in the NEC group (5 days, range 1\u201322) compared to the non-NEC group (17 days, range 0\u2013131) but means were not statistically different (t-test with Welch\u2019s correction, p = ). Both the NEC and non-NEC groups contained infants receiving breast milk, infant formula, or no enteral nutrition prior to sample collection. Of non-NEC infants, 36% were delivered via C-section compared to 50% of infants in the NEC group.\nAfter quality filtering and removal of chimeras and non-bacterial sequences, barcoded 16S rRNA amplicons generated a total of 59,778 sequences for fecal and 72,791 sequences for tissue samples. The mean (range) number of fecal sample sequences was 4,719 (697\u201315,319) for NEC and 2,510 (589\u20136,530) for non-NEC subjects, and the mean (range) number of tissue sample sequences was 2,322 (445\u20136,066) sequences for NEC and 2,799 (634\u20137,906) for non-NEC subjects.\nPrior to estimating microbial alpha-diversity or richness, samples were rarefied to the lowest library size of all the samples (445 reads per sample). When testing for a non-zero coefficient of a normal linear model that used NEC/non-NEC group membership as predictor of richness, microbial richness and diversity were lower in NEC samples compared to non-NEC samples (Fig 1A). In tissue samples, when comparing microbial richness or diversity in tissue from NEC and non-NEC subjects, p-values for all tested richness estimates were < and there was a trend towards lower alpha diversity estimates in tissue from infants with NEC compared to those without NEC (p-values: N1 = , N2 = ) (Fig 1A). Both microbial richness (observed OTU counts () p-value = ,  p-value = ) and alpha diversity (N1 p-value = , N2 p-value = ) were at or near significantly lower in stool from infants with NEC compared to those without (Fig 1A).\nA) Boxplots of tissue microbial diversity and richness in infants with and without necrotizing enterocolitis (NEC) at the operational taxonomic unit (OTU) level for all samples, stool alone, and tissue alone. After rarefaction to the lowest library size of all the samples (445 reads per sample), \u03b1 diversity and richness estimates were calculated per each sample. This process was repeated 400 times and results were averaged. The Shannon and inverse Simpson indices were calculated to estimate abundance-based OTU diversity, while the Chao1 estimator and observed taxa counts were calculated to estimate abundance-based OTU richness. Displayed p-values were obtained after testing for a non-zero coefficient of a normal linear model that used NEC/non-NEC group membership as predictor of richness or diversity. All tested richness and diversity indices for both tissue and stool samples were at or near significantly lower in NEC compared to non-NEC samples. B) Principal coordinates analysis (PCoA) plot of tissue samples, labelled by NEC status. Bray-Curtis dissimilarities between samples were calculated at the genus level after normalizing read counts to simple proportions and after rarefaction to the lowest library size (445 reads per sample). The centroids between the NEC and non-NEC samples were significantly dissimilar (Adonis PerMANOVA p-value = ).\nBray-Curtis dissimilarities between samples were calculated at the genus level after normalizing read counts to simple proportions. The centroids between the NEC and non-NEC samples were significantly dissimilar (Adonis PerMANOVA p-value = ).\nSpecific taxa associated with the differential microbial profiles of NEC and non-NEC samples. Fig 3 shows a heatmap of the top 30 most abundant genera found in tissue samples across the bottom, with sample clustering on the left and each individual sample marked on the right with both infant age in days at time of collection and whether the sample was from an infant with or without NEC. NEC and non-NEC samples generally formed two distinct clusters. Bacterial genus level assignments for tissue and fecal samples comparing NEC with non-NEC patients are depicted in Fig 4; NEC tissue samples were more likely to be dominated by a single genus (Fig 1A), including Staphylococcus, Clostridium, Escherichia, or Bacteroides than non-NEC samples. Stool and tissue communities were significantly dissimilar (Bray-Curtis dissimilarities Adonis test p-value = ), with tissue and stool communities from the same infant sharing little overlap (Fig 4).\nInfant sample ID is on the x-axis. The top 15 genera with the highest average relative abundance are shown. Samples are stratified by necrotizing enterocolitis (NEC) status, and whether sample was tissue or stool. Tissue and stool samples from the same infant had dissimilar microbial profiles.\nWhen tissue samples were analyzed alone, 15 taxa at the genus level had differential abundances in NEC compared to non-NEC samples with DESeq2 test q-values <  (Fig 5). Staphylococcus was ranked first in the DESeq2 model as most significantly different between NEC and non-NEC samples. Clostridium_sensu_stricto was near significantly more abundant in NEC tissue compared to non-NEC tissue (Table 2). Both groups were the only two genera identified as being significantly or near significantly more abundant in NEC compared to non-NEC samples. Clostridium_sensu_stricto was significantly more abundant in NEC than non-NEC tissues when the GeneSelector test using Wilcoxon test rankings was applied (q-value = ). Clostridium_sensu_stricto abundance being higher in NEC infants appears to be due mostly to a single infant, N27, who had nearly 100% Clostridium_sensu_stricto abundance; the relative abundance of this genus was low for the remainder of samples (Fig 4).\nFig 5. Comparison of the abundance of tissue bacterial genera between infants with and without necrotizing enterocolitis (NEC).\nOnly bacterial genera that were significantly different between groups after adjusting for multiple comparisons using the DESeq2 package (see text for details) are indicated by an asterisk. Log2 fold change and log2 fold change standard error of tissue bacterial genera according to NEC status as calculated with the DESeq2 analysis. A log2 fold change of >0 (pink bars) indicates that abundance was detected to be higher during NEC, while a log2 fold change <0 (blue bars) indicates that abundance was detected to be higher in infants without NEC.\nWhen fecal samples were analyzed alone, while Clostridium_sensu_stricto did not differ in abundance between NEC and non-NEC samples, Staphylococcus as a genus was more abundant during NEC (Table 2), consistent with findings from a recent study describing fecal microbiome samples from NEC patients [42]. A single Staphylococcus OTU, identified as OTU0004, was dominated in NEC fecal samples (Table 2) compared to non-NEC samples. This same Staphylococcus OTU0004 was also found to be significantly more abundant in tissue samples in infants with NEC (Table 2) compared to those without NEC. Due to the limited read lengths obtained, this OTU could not confidently be classified below the genus level.\nNEC-associated changes in the microbiome were stronger than the influence of other measured potential confounders\nAlthough infants in the NEC and non-NEC groups were similar demographically and had similar environmental exposures in aggregate (all p-values >), we conducted additional analyses to assess the effect of potential gut microbiome confounders.\nMode of delivery did not have a significant correlation with infant microbiome richness, alpha or beta diversity, or abundance of specific taxa in either stool or tissue samples. Infant sex did not have a significant correlation with infant microbiome richness or alpha or beta diversity in either tissue or fecal samples; however, tissue from males had lower abundance of Staphylococcus (Table 2). Age of the infant at time of sampling was found to correlate with trends in the gut microbiome: overall, the microbial communities significantly differed between age groups (pairwise Bray-Curtis dissimilarities were calculated between each sample and infants were quartered into age groups of as even size as possible and the PermANOVA Adonis test was performed on these groupings; p-value = ). We observed an association between microbial richness, diversity and infant age and this was strongly correlated with NEC status (Fig 2).\nPrior to sampling, all but one infant had been exposed to antibiotics (Table 1). Of infants who had received antibiotics, all had received at least two different antibiotics and at least one broad-spectrum antibiotic. Half of all infants in this study (12/24) were treated with vancomycin. Staphylococcus abundance was higher in tissue taken from infants who had received vancomycin (Table 2). In contrast, Staphylococcus was not significantly more abundant in stool taken from infants with vancomycin exposure. Vancomycin exposure was not significantly associated with differential abundance of any other taxa or with alpha diversity or richness in either fecal or tissue samples.\nTo further assess the influence of confounding variables on the effect of NEC on the microbiome, we built models in DESeq2 to explicitly account for a priori selected covariates that may affect the gut microbiome (delivery mode, infant sex, infant age, diet, tissue type, exposure to vancomycin). Regardless of covariates added, the DESeq2 calculated log2 fold change in Staphylococcus abundance between infants with and without NEC directionality did not change (., Staphylococcus abundance was always higher in NEC infants). Infant age and exposure to vancomycin had the strongest effect on the association between NEC on Staphylococcus abundance: young infants with NEC who had been exposed to vancomycin generally had high Staphylococcus tissue abundance (Fig 6A).\nFor ethical reasons, intestinal tissue cannot be collected from healthy infants; therefore, all the non-NEC infants in this study were in the hospital for ailments unrelated to NEC. There were two disparate groups of non-NEC infants recruited for this study: those who were very young (<1 week old) and those who were older (40+ days). To assess the impact of these two disparate non-NEC groups, we repeated our main analyses, after separating out the samples into three groups: 1) NEC 2) "young" non-NEC and 3) "old" non-NEC. A PCoA plot constructed using pairwise Bray-Curtis dissimilarities at the genus level revealed that the two non-NEC groups clustered together, separately from samples from infants with NEC (S1 Fig). Additionally, microbial richness was lowest in infants who had NEC and was similar in the two non-NEC groups, regardless of infant age (S2 Fig). Staphylococcus abundance was highest in the NEC group, followed by the youngest non-NEC group, and lowest in the older non-NEC group suggesting intestinal Staphylococcus colonization at early age.\nDiscussion\nOnly a few studies have interrogated the tissue-level intestinal microbiome in NEC, despite the relative proximal location of intestinal injury and previous reports on the existence of a site-specific intestinal microbiome [13,43,44]. Here, we report a tissue-specific overrepresentation of Firmicutes, specifically Staphylococcus sp. and Clostridium sp. in NEC. We are aware of only two other reports on the NEC tissue-level microbiome in humans: a study from Denmark performed a retrospective analysis of formalin-fixed and paraffin-embedded tissue specimens using fluorescent in situ hybridization with bacterial rRNA-targeting oligonucleotide probes [45]. They detected Proteobacteria (%), Firmicutes (%), Actinobacteria (%) and Bacteroidetes (%) in tissue samples. More recently Brower-Sinning et al. applied 16S rRNA technology to compare the microbiome of 16 cryopreserved NEC samples and 10 controls [46]. Except for a higher bacterial load in NEC tissues, no statistically significant distinction was found between the composition of NEC and non-NEC microbial communities. The different results in our study may be explained by the fact that in the work by Brower-Sinning et al. all but one control patient were former NEC patients. In contrast, we included samples from infants with no history of NEC.\nWhile we observed that the infant gut microbiome was significantly dissimilar in infants with NEC compared to those without NEC, we conducted a number of analyses to test the influence of potential confounders. After adding multiple covariates to the model in DESeq2 suggests that a combination of variables is likely to influence the infant tissue microbiome, for example age, vancomycin exposure, and NEC were found to correlate with Staphylococcus abundance. We observed that very young infants with NEC who had been exposed to vancomycin were most likely to have high Staphylococcus abundance in their gut tissue. We do not know how to explain this unexpected finding except by the fact that vancomycin does not penetrate tissue very well. Delivery by C-section has been associated with colonization of the neonate with Staphylococcus [47]. Therefore, we were surprised by our finding that mode of delivery did not correlate with specific taxa in our dataset. However, three out of four samples with high abundance of Staphylococcus were from C-section-delivered infants indicating that our sample size may have been insufficient to detect a statistical significance.\nOne unique aspect of our study is the direct comparison between tissue and fecal samples. This allows for an additional level of quality control as each patient is his/her own control and results between fecal and tissue samples were distinct in both non-NEC and NEC patients. Consistent with previous studies in preterm infants [9,48,49], we confirmed the dominant phyla as Proteobacteria and Firmicutes, with a smaller contribution (<20%) from Bacteroidetes and Actinobacteria. Several fecal microbiome studies reported a bloom of \u03b3-Proteobacteria with a concomitant decrease in Firmicutes in NEC patients [10,12]. This shift in microbial communities in NEC patients appears to start 1\u20132 weeks prior to diagnosis and has been associated with metabolic changes [9]. While our data do not replicate this shift in Proteobacteria in fecal samples, possibly as we measured the gut microbiome during rather than prior to NEC diagnosis, we confirmed the previously reported reduced microbial diversity and loss of Actinobacteria in NEC patients, especially patients with severe (surgical) disease [10,50].\nGiven numerous previous reports on the dominance of Proteobacteria in NEC [9,10], we were surprised to find the high prevalence of Firmicutes and specifically Staphylococcus sp. in NEC tissue. However, different forms of dysbiosis have been reported in NEC [11,48] including recently an association between Clostridium and Staphylococcus with NEC in European preterm infants [42]. Importantly, NEC dysbiosis with Firmicutes including Staphylococcus has been associated with earlier disease and higher mortality [48]. Our study included only infants with surgical NEC, the group of patients with highest mortality [51]. When comparing NEC patients with heavy versus light Staphylococcus abundance, NEC patients with high abundance required surgical resection significantly earlier. Staphylococcus is the major colonizing organism of the infant gut shortly after birth [49,52,53]. In preterm neonates, culture-based studies detected Staphylococcus in 50% of meconium and 100% of fecal samples from the first week post-partum [54]. Staphylococcus sp. are frequently cultured from meconium and have been associated with increased risk for NEC [8,55].\nOur study has limitations. While we collected tissue and fecal samples prospectively, technical and ethical limitations do not allow for tissue sampling prior to surgical resection. Therefore, we cannot perform time series experiments to evaluate the dynamic microbiome changes in NEC tissue. Similarly, since it is currently not possible to sample intestinal tissue from normal infants, we lack a healthy control cohort in which to characterize the standard infant tissue microbiome. While we attempted to match for important variables such as mode of delivery, antibiotic exposure and type of feeding, given the nature of this human study that explores both tissue and stool of a surgical emergency in a very vulnerable population, we were not able to control for all possible microbiome confounders. In addition, the lack of shotgun metagenomic sequencing prohibits further classification of the bacteria, especially those of important genera ., Staphylococcus and Clostridium identified in this study. However, based on the recent findings by Roz\xe9 et al, we speculate that the majority of Staphylococcus and Clostridium species would be S. aureus and C. neonatale [42]. Future studies implementing whole genome sequencing will be necessary to address strain identification and implications for derangements in metabolic function associated with the distinct microbial community structure we detected. An additional future aim could be to measure Staphylococcus-specific endotoxin production in stool samples, especially as our PICRUSt data suggests there was an increase in bacterial toxin pathways in NEC compared to non-NEC tissue samples.\nConclusion\nTo the best of our knowledge, we define here for the first time corresponding fecal and tissue-level microbial communities comparing NEC patients with patients without a history of NEC and confirm age and antimicrobial exposure as defining factors.\nSupporting information\nS1 Fig. Principal coordinates analysis (PCoA) plots of tissue samples, labelled by necrotizing enterocolitis (NEC) status and whether the infant was from the young or old non-NEC group.\nBray-Curtis dissimilarities between samples were calculated at the OTU level after normalizing read counts to simple proportions. NEC and non-NEC samples are observed to cluster separately, while both the young and old non-NEC samples clustered together.\nS2 Fig. Microbial richness was estimated using two indices, the Chao estimator () and estimated number of operational taxonomic units (OTUs) (S. obs) and each of these indices was plotted as a function of infant age in days.\nTwo age disparate groups of non-necrotizing enterocolitis (NEC) infants were included in the analysis; however, from this figure it can be observed that NEC/non-NEC status had a much stronger effect on microbial richness than infant age.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:40Z', 'description': u'by Dinesh Panday, Bijesh Maharjan, Devraj Chalise, Ram Kumar Shrestha, Bikesh Twanabasu\n\nDigital soil mapping has been widely used to develop statistical models of the relationships between environmental variables and soil attributes. This study aimed at determining and mapping the spatial distribution of the variability in soil chemical properties of the agricultural floodplain lands of the Bara district in Nepal. The study was carried out in 23 Village Development Committees with 12,516 ha total area, in the southern part of the Bara district. A total of 109 surface soil samples (0 to 15 cm depth) were collected and analyzed for pH, organic matter (OM), nitrogen (N), phosphorus (P, expressed as P2O5), potassium (K, expressed as K2O), zinc (Zn), and boron (B) status. Descriptive statistics showed that most of the measured soil chemical variables (other than pH and P2O5) were skewed and non-normally distributed and logarithmic transformation was then applied. A geostatistical tool, kriging, was used in ArcGIS to interpolate measured values for those variables and several digital map layers were developed based on each soil chemical property. Geostatistical interpolation identified a moderate spatial variability for pH, OM, N, P2O5, and a weak spatial variability for K2O, Zn, and B, depending upon the use of amendments, fertilizing methods, and tillage, along with the inherent characteristics of each variable. Exponential (pH, OM, N, and Zn), Spherical (K2O and B), and Gaussian (P2O5) models were fitted to the semivariograms of the soil variables. These maps allow farmers to assess existing farm soils, thus allowing them to make easier and more efficient management decisions and maintain the sustainability of productivity.', 'title': u'Digital soil mapping in the Bara district of Nepal using kriging tool in ArcGIS', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206350', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Digital soil mapping in the Bara district of Nepal using kriging tool in ArcGIS\n\nFigures\nAbstract\nDigital soil mapping has been widely used to develop statistical models of the relationships between environmental variables and soil attributes. This study aimed at determining and mapping the spatial distribution of the variability in soil chemical properties of the agricultural floodplain lands of the Bara district in Nepal. The study was carried out in 23 Village Development Committees with 12,516 ha total area, in the southern part of the Bara district. A total of 109 surface soil samples (0 to 15 cm depth) were collected and analyzed for pH, organic matter (OM), nitrogen (N), phosphorus (P, expressed as P2O5), potassium (K, expressed as K2O), zinc (Zn), and boron (B) status. Descriptive statistics showed that most of the measured soil chemical variables (other than pH and P2O5) were skewed and non-normally distributed and logarithmic transformation was then applied. A geostatistical tool, kriging, was used in ArcGIS to interpolate measured values for those variables and several digital map layers were developed based on each soil chemical property. Geostatistical interpolation identified a moderate spatial variability for pH, OM, N, P2O5, and a weak spatial variability for K2O, Zn, and B, depending upon the use of amendments, fertilizing methods, and tillage, along with the inherent characteristics of each variable. Exponential (pH, OM, N, and Zn), Spherical (K2O and B), and Gaussian (P2O5) models were fitted to the semivariograms of the soil variables. These maps allow farmers to assess existing farm soils, thus allowing them to make easier and more efficient management decisions and maintain the sustainability of productivity.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: The National Land Use Project under the Ministry of Land Reform and Management, Nepal was providing financial support for Hexa International Pvt. Ltd., Lalitpur and En. Geo. Global Pvt. Ltd., Bhaktapur, Nepal for the preparation of VDC level Land Resource Maps, database and reports of twenty-three VDCs of Bara district (RFP #NLUP/QCBS/01/069/070). Author Bikesh Twanabasu was employed by Hexa International Pvt. Ltd. during the course of the study. Hexa International Pvt. Ltd provided support in the form of salary for author BT, but did not have any additional role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript. The specific role of this author is articulated in the "author contributions\u2019 section.\nCompeting interests: The National Land Use Project under the Ministry of Land Reform and Management, Nepal was providing financial support for Hexa International Pvt. Ltd., Lalitpur and En. Geo. Global Pvt. Ltd., Bhaktapur, Nepal. Author Bikesh Twanabasu was employed by Hexa International Pvt. Ltd. during the course of the study. There are no patents, products in development or marketed products to declare. This does not alter our adherence to all the PLOS ONE policies on sharing data and materials.\nIntroduction\nApplications of pedometric mapping, also called predictive mapping, ., the spatial prediction of soil variables at unobserved locations using statistical inference, have become increasingly important since their initial development in the early 1800s. The utility of such maps was due to the introduction of geostatistics, allowing researchers to accurately interpolate spatial patterns of soil properties [1]. One of the current versions of pedometric mapping, digital soil mapping (DSM), involves the creation and population of spatial soil information systems using field and laboratory observational methods coupled with spatial and non-spatial soil inference systems [2\u20135]. Field sampling is used to determine the spatial distribution of soil properties, and these surface grids point data are then interpolated to estimate soil properties in areas not sampled [6]. In contrast, existing conventional soil survey methods are relatively slow and expensive; therein, soil databases are neither exhaustive enough nor precise enough to promote an extensive and credible use of soil information within the spatial data [7].\nSeveral statistical models can be used in DSM to develop a relationship between soil properties and environmental variables (often related to soil forming factors such as terrain attributes\u2014altitude, aspect, and slope) rather than from soil observations alone [8], and McBratney et al. [9] thorough reviewed the various models used. Soil nutrients are one of the most important properties governing soil quality, and hence have a significant impact on the variability of soil productivity and crop production. The spatial variability of soil properties can be mapped using an interpolation technique [10]. Many spatial interpolation methods have been developed and several terms have been used to distinguish them, including "deterministic" and "stochastic" [11]. Deterministic interpolation methods such as thiessen, density estimation, inverse-distance-weighted, and splines, provide no assessment of errors, whereas stochastic interpolation and kriging methods do provide prediction error assessments.\nKriging is a geostatic interpolation technique that has proven sufficiently robust for estimating values at non-sampled locations based on sampled data. It provides the best linear unbiased estimates and information on the distribution of the estimation error and shows strong statistical advantages [12]. The use of the geostatistical interpolation technique also reduces the costs of field sampling and laboratory analysis, provided that a given set of soil samples sufficiently represents the study area [13]. However, the reliability of spatial variability maps depends on the adequate sampling data and the accuracy of the spatial interpolation [14].\nThere is a significantly increased trend in the use of DSM mainly due to recent advances in technology related to quantitative methodologies and geographic information systems. For example, spatial variability of organic matter (OM), pH, and potassium (K) were mapped using kriging by Lopez-Granados et al. [15] in a 40 ha field located in southern Spain. Santos Franc\xe9s et al. used the kriging interpolation method for the production of spatial distribution of the heavy metal contents in the soils of northern Spain [16] and northern Peru [17], respectively. Balkovi\u010d et al. [18] reported that the DSM model represents a complete alternative to classical soil mapping at very fine scales on erosion affecting 37 ha of arable land in Slovakia, even when soil profile descriptions were collected merely by field estimation methods. In northwestern Australia, a DSM soil carbon map at the farm scale was developed from a total of 127 soil sampling locations in an area of 2300 ha [19]. Similarly, Zhang et al. [20] produced spatial variability maps of nitrogen (N), phosphorus (P) and K in winter wheat and summer maize in northeast China. Recently Zhu et al. [21] used an alternative DSM method, individual predictive soil mapping (iPSM), to map OM content in the topsoil layer of an area of 6000 ha in China and observed that iPSM is an effective alternative when existing soil samples are limited in their ability to fully represent the entire study area.\nDespite the successful application of DSM in regions around the world, no single study has examined the use of DSM to represent soil nutrient variability in any part of Nepal. The commonly practiced soil fertility assessment is based on a random soil sampling protocol to obtain an average fertility value for a farmer\u2019s field [22]. It ignores spatial variability, or those soil testing results that do not provide randomness of variations from one place to another. Consequently, some parts of the field may receive surplus fertilizer while others may lack nutrients and experience the undesired levels of productivity. The objective of this research was to determine and map the spatial distribution of variability in soil chemical properties of agricultural floodplain lands in the southern part of the Bara district of Nepal. The country\u2019s economy relies heavily on agriculture and any breakthrough in soil mapping would immensely benefit farmers. Information on spatial variability of soil nutrients is also essential for sustainable management of soil fertility.\nMaterials and methods\nStudy area\nNepal is located in the south of Asia bordering neighbors of India and China and covers an area of approximately 147,181 km2. It has been divided broadly into three geographic regions: Himalayan, Hilly, and Terai. The study was conducted in the southern part of the Bara district, which falls under Terai region, and included the 23 Village Development Committees (VDCs) and covers 12,516 ha of land as shown in Fig 1. The topographic variation of the study area ranges from 80 to 95 m.\nFig 1. Study area in southern part of Bara district, Nepal which includes 23 Village Development Committees (VDCs).\nA large part of the study area lies in Terai region where the topographic variation ranges from 80 to 95 m, and climate is subtropical monsoon. A total of 109 soil samples were taken from the depth of 0\u201315 cm (topsoil layer) for determination of pH, OM, N, P2O5, K2O, Zn and B status on it.\nThere are four seasons in Nepal: pre-monsoon (March to May), monsoon (June to September), post-monsoon (October to November) and winter (December to February). Monsoons are the Nepal\u2019s main source of precipitation, accounting for 85% of the country\u2019s total annual rainfall of 1800 mm, with the remaining 15% occurring in winter [23\u201324]. During a monsoon, all of the rivers are in spate, with bank-full discharges that cause flooding and inundation in several parts of the Terai region [25]. The study area becomes hottest (37 to 42\xb0C) during the monsoon months compared to the country\u2019s average temperature (28\xb0C) due to seasonal changes and low altitude.\nRice (Oryza sativa L.) is the principal staple food of Nepal, accounting for about 67% of total cereal consumption. Most of the food crops for the entire country are grown in the Terai region, the granary of Nepal. The terai is generally made up of flat terrain with a hot, humid climate. About 80% of the land in this area is occupied by farmlands. Rice -wheat (Triticum aestivum L.)-fallow is the dominant cropping system in the study area followed by rice-wheat/lentils (Lens culinaris)-fallow, rice-wheat-maize (Zea mays L.), and sugarcane (Sacharum officinarum).\nThe soil association of the study area is developed by the changing river morphology. The soils have predominantly evolved from alluvial deposits and are dominated by sandy loam and silty clay, although clay loam and loamy sand are also present at considerable levels. It was observed that the majority of the area is occupied by land system unit 2b (deep alluvium: < degree slope, flat, imperfect drainage, sandy loam to silty clay, Aeric, Haplaquepts, Typic, and Fluventic) followed by 2a (deep alluvium: <  degree slope, depression, poor drainage, loam to silty clay, Aeric, Haplaquepts, and Typic), 3a (deep alluvium: < 1 degree slope, gently undulating, moderate drainage, sandy loam to silty clay, Haplaquepts, Typic, Ustocrepts, and Dystrochrepts), and 2c (stratified alluvium: < 1 degree slope, micro-relief, variable drainage, low areas subject to flooding, sandy loam to silty clay, Typic, and Fluventic).\nSoil sampling and analysis\nSurface soil samples (0 to 15 cm depth) were collected during May 2013 using a soil auger in the study area. Soil sampling locations were selected to best represent the land use condition in each VDC while considering terrain attributes and drainage conditions. A few VDCs such as Parsurampur and Golganj had only one soil sampling location. By following one soil sample per location, a total of 109 soil samples were collected from the study area, and the details of soil sampling locations are given in Fig 1. A global positioning system receiver with 1 m precision was used to record the longitude and latitude of soil sampling locations. No specific permissions were required for soil sampling in these locations and the field studies did not involve endangered or protected species.\nThe collected soil samples were air-dried and sieved through a 2 mm sieve for chemical analysis conducted at the Regional Soil Testing Laboratory, Kaski district of Nepal. The soil chemical parameters tested and methods used are given in Table 1. Sodium bicarbonate (NaHCO3) and ammonium acetate (C2H7NO2) were used as the extractants for laboratory analysis of available phosphorus and potassium, respectively.\nStatistical and geostatistical analysis\nDescriptive statistics of soil properties, including mean, standard deviation, coefficient of variation, minimum, maximum, skewness (skew), and kurtosis, were calculated. For all measured soil characteristics, the visual method (histogram, boxplot and normal plot) and values of skew and kurtosis were used and no figures were included for the univariate test of normality in SAS software [33] prior to ordinary kriging.\nThis study focused on ordinary kriging (the general name for kriging), a linear geostatistical interpolation technique. Kriging estimates were calculated as weighted sums of the adjacent sampled concentrations. It is an improvement over inverse distance weighting (another geostatistical tool) interpolation because prediction estimates in kriging tend to be less biased and are accompanied by prediction standard errors [34]. Details of the kriging formula and calculation are given in Yao et al. [14]. The main application of geostatistics in soil science has been the estimation and mapping of soil attributes out of sampled areas [35].\nRegardless of data distribution, kriging can provide the best-unbiased predictor of values at unsampled points, though data that have closer to a normal distribution can provide the best estimates of probability maps [36]. Therefore, it was necessary to normalize the dataset prior to geostatistical analysis because of high skew (Table 2) and the presence of outliers. Since the coefficient of skew was greater than one (except for pH and P2O5), the logarithmic transformation was applied for a kriging analysis (lognormal kriging, hereafter referred to as kriging) to stabilize the variance [35]. The logarithmic transformation resulted in smaller skew and kurtosis for OM, N, K2O, B, and Zn, and the transformed data passed the normality test.\nA dbf file consisting of data for X and Y coordinates with respect to sampling site location was created in ArcGIS (version ). Several digital map layers were then developed, using kriging in ArcMap, based on each soil chemical property at 1:25000 scale. The ranges for soil pH are classified as strongly acidic (<), moderately acidic ( to ), neutral ( to 7), moderately alkaline (7 to ), and strongly alkaline (>). Similarly, the rating charts for other soil parameters are given in Table 3, which is based on recommendations given by the Soil Management Directorate of the Department of Agriculture for the Terai region of Nepal [22].\nThe kriging method uses semivariance to estimate the spatial distribution structure of the soil properties [37\u201338]. Semivariogram modeling and estimation are essential for structural analysis and spatial interpolation, which is akin to fitting a least-squares line in regression analysis [39]. It produces geostatistical parameters, including nugget, structural, sill, and range [38]. The spatial dependency (Sp. D) of soil parameters (the ratio of nugget to sill variances) is expressed as a percentage [40]. To ensure Sp. D, as a rule of thumb the sampling interval (lag) should be less than half of the range of the spatial variation [15]. If the ratio is less than , the variance has strong Sp. D and if the ratio ranges between  and , the variance has moderate Sp. D [41].\nMoran\u2019s I Index was used to measure spatial autocorrelation between sample points on the semivariagram cloud, which was evaluated using z-scores. Values greater than  or smaller than \u2212 are significant at p <  [42]. Similarly, the mean error (ME) and root mean square error (RMSE) was used for a cross-validation approach (or any given variogram model) to evaluate the accuracy or best fit of the kriging tool [43]. A ME value close to zero indicates that the interpolation method is unbiased. The lowest RMSE value indicates the best fit to the variogram model.\nData analysis\nDescriptive statistics and geostatistics were used to analyze the dataset, and descriptive statistics along with a normality test were run in SAS software. All maps were produced using GIS software ArcMap (version ) and its spatial analyst and geostatistical analysis extensions. The structure of spatial variability was analyzed through semivariogram. Spatial distribution was analyzed through kriging interpolation.\nResults and discussion\nDescriptive statistics for soil chemical properties\nThe commonly used descriptive statistical summary of the pH, OM, N, P2O5, K2O, Zn, and B is presented in Table 2. The variability was interpreted using the coefficient of variation (CV) and classified into most (CV: >35%), moderate (CV: 15 to 35%) and least (CV: <15%) variable ranges [44]. The CV ranged from % (in pH) to % (in K2O). The range of CV for the soil sampling locations suggested different degrees of heterogeneity among the properties studied.\nThe pH values were ranging from  to 8 with a mean of , which was also similar to the median value of . The concentration of OM was low (ranging from 1 to %), with a mean of %. Total N was relatively low (ranging from  to %) with a median of %, though the mean was %. Available P2O5 ( kg ha-1) and K2O ( kg ha-1) were within their respective medium ranges. Between the two micronutrients measured, Zn was very low (range: < mg kg-1) with a median of  mg kg-1 and a mean of  mg kg-1, while B was at medium (ranging from  to  mg kg-1) with a median of  mg kg-1, though the mean was  mg kg-1.\nAmong the soil chemical properties, OM, N, K2O, B, and Zn were found to be not normally distributed due to higher values of skew and kurtosis. Those datasets were then subjected to logarithmic transformation to narrow down the skew and kurtosis values (Table 2) and the transformed datasets were subsequently used in the spatial analysis.\nDigital soil maps using kriging\nDigital maps of soil chemical properties were produced by using kriging on the log transformed dataset, and the results (shown in Figs 2 through 8) were grouped into various classes based on the range representing their magnitude in the soil. The estimated area of each class is given in Table 4.\nMost of the study area was with moderately alkaline (%) followed by moderately acidic (%) and neutral (%) pH. Strongly alkaline was present in about % of total area but could not see in the variable map.\nSoil pH.\nSoil pH varied from strongly acidic (< ) in % to strongly alkaline (> ) in % of the total area (Table 4 and Fig 2). These results are in agreement with those reported in a recent study of soils of the Terai region [22, 45]. The variation in soil pH could be attributed to the nature of the alluvial parent material, micro topography, and the type and history of fertilizer used [46]. The losses of basic cation and other nutrients through erosion and leaching leaves the hydrogen and aluminum ions that can cause soil acidity [47]. Management practices such as crop nutrient uptake and harvest without replenishment [48] and poor crop residue management lowers the pH and leads to low levels of soil OM [28, 49].\nUrea (46% N) and di-ammonium phosphate (18% N and 46% P) are the most commonly used fertilizers by Nepalese farmers. The national average for the use of chemical fertilizer has increased dramatically from  kg ha\u22121 in 2002 to  kg ha\u22121 in 2014 [50]. Of the major fertilizer nutrients, types of N fertilizer containing ammonium-N are the main factors affecting soil pH. As the ammonium-N in fertilizers undergoes nitrification, hydrogen ions are released, which can increase acidity [51], and Tripathi and Shrestha [52] reported an increase of acidity up to  (in 2000) from  (in 1997) after the application of fertilizers at four locations in western Nepal.\nPlant growth and most soil processes are favored by a specific pH range. The low pH leads to Al and Mn toxicity, along with deficiency and/or unavailability of plant nutrients such as P, Ca, K, Mg, and Mo as observed by Dembele et al. [53] and Tisdale et al. [54]. To produce a sustained crop growth and yield, efforts should be made to increase the pH, which can be addressed through liming and OM management or adoption of the acid tolerant crops.\nSoil organic matter.\nSoil OM was relatively low (1 to %) in the majority (%) of the study area, followed by very low (<1%) in % (Table 4 and Fig 3). The low organic content in the soils can generally be accounted for through the general sparse vegetation and competing use of crop residue as animal feed which then constrains their return to the soil [55\u201356]. A study conducted in the Dhading district of Nepal in 2003 showed that 37% of crop residue was used to feed livestock, 35% was used as fuel, 15% was burnt on lands, and the remaining 13% was incorporated into the soil through methods other than burning [57].\nAnother possible reason for low OM is a high soil OM decomposition rate resulting from soil and higher air temperature that decreases soil organic carbon (SOC). The SOC is affected by the addition of farm yard manure (FYM), tillage, and cropping pattern [58\u201359]. Around % of the study area revealed medium ( to 5%) levels of soil OM, which could be due to waterlogged conditions, leading to shallow rooting and the confinement of biological activity to the upper soil layer. Similar results were reported by Shrestha et al. [60] for the soils of lowland irrigated rice fields in Nepal.\nAmong Nepalese farmers, there is an increase in the use of chemical fertilizer in agriculture, though this increase is not being matched by an increase in the use of organic manure (manures, organic fertilizers, compost, or other soil improvers) [61]. The present rate of organic manure application is  to 3 t ha-1 for soil fertility management [62], with an estimated composition of % N, % P, and % K on a dry weight basis, far below the global average and a rate that may not meet crop demand on a long-term basis [63\u201364]. As OM decreases, it also decreases available N, P, K, and some micronutrients [65]. Zhao et al. [66] reported that this low level of OM is indication of soil degradation and a high risk of soil erosion. Farmers should be encouraged to add much crop residues to the soil along with manure and compost.\nTotal nitrogen.\nUsually, N has a greater effect on crop growth, crop quality, and yield. However, N was deficient in most of the areas with values < (low and very low) recorded in % of the total area (Table 4 and Fig 4). The variation in N content in different parts of the study area may be related to soil management, application of FYM and applied fertilizer to previous crops, etc. [67]. The acute deficiency of N is due to low OM content, increased rate of mineralization, and insufficient application of N fertilizer to nutrient exhausting crops like wheat and maize [46]. The rate of soil OM decomposition and N mineralization holds complex interactions with the microbial population and other environmental factors, mainly soil moisture and temperature. A field with 40 kg N ha-1 of soil nitrate build-up led to the loss of N from the entire field when the soil, which contained moisture levels > 46%, filled pore space at the onset of the monsoon rains in a lowland field in the west central part of Chitwan, Nepal [68].\nAvailable phosphorus.\nThe available P2O5 was medium in % and low in % of the study area (Table 4 and Fig 5). The low level of OM may account for the low level of available P2O5 in the soils. However, the relatively higher availability of P2O5 observed in some areas may be due to the dissolution of Ca-P under neutral soil reaction under cultivated conditions [69\u201370]. Phosphorous is more directly affected by soil pH than other major plant nutrients such as N, K, and S; for example, at alkaline values, greater than pH , the HPO42- phosphate ions tend to react quickly with calcium (Ca) and magnesium (Mg) to form less soluble compounds. At acidic pH values, the H2PO4- phosphate ions react with aluminum (Al) and iron (Fe) to again form less soluble compounds [71]. Soils with inherent pH values between 6 and  are ideal for P availability. Besides pH, the amount of OM and the placement of P fertilizers also control the availability of P2O5, whereas erosion and runoff are associated with its loss from soil. Studies from many developed countries have shown that the use of flue gas desulfurization gypsum, a source of Ca and S, can be used as a soil amendment, especially to reduce soil and soluble P loss from agricultural fields and improve acidic soils [72]. Hence, whether or not farmers attempt to adjust pH levels, it is important to understand methods to increase the availability and use of added nutrients [73].\nAvailable potassium.\nThe available K2O was at low levels in the majority of the study area (Table 4 and Fig 6). Soil pH also affects the availability of K2O. When soil pH is greater than 7, the greater Ca concentration increases the K availability through the displacement of exchangeable K by Ca. Conversely, when soil pH is less than , the reduction in Ca concentration reduce the K availability. In addition, low levels of OM due to low clay content, high hydraulic conductivity, and possible nutrient losses through leaching and erosion without replenishment also reduces the K level [74]. Water for irrigation to many of these study areas comes from Nepal\u2019s rivers, which are flooded during monsoon season and carry heavy sediments (for example, mica) a source of exchangeable K [75]. However, due to year-round cropping practices, there is very little time for K to release from sediments and remain in the exchangeable site [76]. This could be another reason why the majority of the study area included low amounts of K2O.\nZinc and boron.\nThe micronutrient Zn was low and B was at medium level throughout the study area (Table 4 and Figs 7 and 8), possibly due to unfavorable soil pH (moderately alkaline in % of the total study area), intensive cropping, the use of high yielding varieties, and different fertilizer application strategies practiced by smallholder farmers. The Khaira disease (leaf bronzing) in rice due to Zn deficiency [77\u201378] and sterility in wheat induced by an inadequate B supply [79\u201382] are major concerns in the study area. In a study of micronutrient deficiencies in grain legumes, Srivastava et al. [83] found that B severely restricted the growth of lentils (Lens culinaris M.), chickpeas (Cicer arietinum L.), and pigeonpeas (Cajanus cajan L.) in the Terai region. Since rice is the major staple crop in Nepal, farmers use zinc sulphate (ZnSO4) before transplanting or sowing at the time of land preparation, along with a combination of ZnSO4 and lime during the growing stage, if the crop is infected [84].\nFarmers\u2019 practice and use of digital soil maps.\nIn many developing countries including Nepal, soil fertility management recommendations are solely based on soil types and agro-ecological zones. Details about soil pH range and the recommended agricultural lime rate, as well as the recommended doses of chemical fertilizers for specific crops in Nepal are given in Pandey et al. [22]. Despite the advisory recommendation made from research, farmers do not apply balanced doses of fertilizer, and instead use mostly acid forming nitrogenous fertilizers.\nMost of the farmers apply FYM to their lands at the same rate as it is produced. The practice for FYM preparation and application is not an improved one because farmers dump FYM in open spaces and expose it to the sun, wind, and rain for several days before ploughing [85]. Farmers also follow nutrient-exhaustive high-yielding crop varieties under intensive cropping all year-round, leading a heavy loss of nutrients after every harvest. Therefore, a balanced rate of chemical fertilizers and organic manures must be applied every year.\nMaps that characterize the spatial distribution of each soil property can be produced using kriging to group individual fields into potentially low- and high-productivity areas. Hence, management strategies to enhance soil nutrients could be implemented in the study area by using these DSMs as a guide [86], such as famers following fertilizer recommendations based on buildup and maintenance levels. Normally, nutrient values that are at low levels require relatively higher amount of fertilizer application; therefore, these DSMs may lead to proper understanding of existing farm soils by allowing easier management and maintaining the sustainability of productivity. This research sets a precedent for future DSM in other parts of the country.\nGeostatistics for soil chemical properties\nSemivariogram analysis.\nThe semivariogram model and some of the geostatistical parameters of soil chemical properties are shown in Table 5. Based on the lowest root mean square error (RMSE), different theoretical semivariogram models were selected for the significant fit of soil chemical properties [87]. An exponential model provided the best fit to the semivariogram of pH, OM, N, and Zn. The spherical model was the best fit to the semivariogram of K2O and B, whereas Gaussian was the best fit for P2O5. Many findings suggest that the exponential model is the most suitable for assessing spatial variability in soil chemical properties [88\u201392] because it explains the maximum variability in the spatial dataset [93\u201394].\nTable 6 shows that Sp. D of soil parameters ranged from  (in N) to  (in Zn). There was a moderate (in N, OM, P2O5, and pH) and weak (in K2O, Zn, and B) Sp. D. of the kriging model, which could be attributed to external factors such as variable rates of fertilizer application and incorporation of amendments by farmers within a cropped region. The ranges of spatial dependencies were large and vary between 4951 m for OM to 5945 m for P2O5 indicating that the optimum sampling interval varies greatly among different soil properties. Determination of the range values provides an idea of the correlation between different sampling locations, along with the maximum spatial dependence distance between them [95]. Fluctuation in the range with different lag sizes indicates that spatial structure may merely be regarded with a single model for semivariogram [96]. This difference may not be important for semivariance calculation, but it may be important if the purpose is to understand the underlying spatial structure of the data [97].\nSpatial autocorrelation.\nThe analysis of spatial autocorrelation based on Global Moran\u2019s I Index was used to identify the spatial pattern soil chemical properties that may be dispersed, random, or clustered based on feature locations and attribute values simultaneously [42], as presented in Table 6. The hypothesis for the pattern analysis was that the soil chemical properties (including pH, OM and some nutrients) across the study area were randomly distributed.\nAccording to ESRI [98], for the theory of random patterns, when the p-value is very small (in this study, p < ) and the z-score is either very high or very low ( < z and z < \u2212), the spatial pattern is not likely to reflect a random form of distribution. A positive Moran\u2019s I index value indicates the neighboring values are similar, suggesting spatial dependency. A negative Moran\u2019s I index value indicates the neighboring values are dissimilar, suggesting inverse spatial dependence. A Moran\u2019s I index value of zero implies a lack of spatial pattern [99\u2013101]. With the exception of K2O, all other soil variables had a positive Moran\u2019s I index for their spatial pattern (Table 6).\nTest of significance for values returned by the analysis of the major soil chemical properties indicated that pH, OM, N and Zn showed clustered distributions in the study area, with low levels clustered at one location and high levels at the other (no figures included). On the other hand, the pattern of distribution of P2O5, K2O and B did not appear significantly different from a random distribution at p < .\nConclusions\nThe application of the geostatistical approach, including descriptive statistics and semivariogram analysis, improved the description of spatial variability for soil chemical properties at 0 to 15 cm depth on a field scale. The descriptive statistics showed that most of the measured soil chemical variables were skewed and non-normally distributed and the available K2O data were highly variable (5 to 696 kg ha-1). Geostatistical interpolation identified that exponential, spherical, or Gaussian models provided the best fit to the semivariograms, depending on the soil chemical variable and, in general, showed weak or moderate spatial dependency for all of the variables. The kriging maps of soil chemical properties were found effective in explaining the distribution of soil properties in non-sampled locations based on sampled data. These maps aid farmers in to making efficient management decisions based on their proper understanding of the conditions of existing farm soils. These results show geostatistical analysis using kriging is an effective prediction tool for exploring the spatial variability of soil nutrients, and we recommend this tool for future soil sampling campaigns in Nepal.\nSupporting information\nS1 File. An excel file include coordinates of 109 sampling locations and report of different soil chemical properties.\nAcknowledgments\nThe authors would like to thank Hexa International Pvt. Ltd., Lalitpur and En. Geo. Global Pvt. Ltd., Bhaktapur, Nepal for providing access and assistant with the datasets. Also thanks to the National Land Use Project, Ministry of Land Reform and Management, Government of Nepal for their supports. The residents of the study area who supported and provided valuable information are deeply acknowledged.\nOur sincere thanks to Bharat Sharma Acharya, Nikita Bhusal, and Ian Rogers for their technical support during the preparation of the manuscript. Finally, we would like to thank anonymous reviewers and an academic editor for their valuable comments and suggestions which helped us on improving this paper.\nReferences\n1.\nWebster R. The Development of Pedometrics. Geoderma. 1994;62(1\u20133):1\u201315.\n16.\nSantos-Franc\xe9s F, Mart\xednez-Gra\xf1a A, Zarza C\xc1, S\xe1nchez AG, Rojo PA. Spatial Distribution of Heavy Metals and the Environmental Quality of Soil in the Northern Plateau of Spain by Geostatistical Methods. International journal of environmental research and public health. 2017;14(6):568.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:43Z', 'description': u'by Cesar Rios-Navarro, Jose Gavara, Veronica Vidal, Clara Bonanad, Paolo Racugno, Antoni Bayes-Genis, Gema Mi\xf1ana, Oliver Husser, Ricardo Oltra, Julio Nu\xf1ez, Francisco J. Chorro, Vicente Bodi, Amparo Ruiz-Sauri\nObjective We characterized the dynamics of eosinophils in blood and in the infarcted myocardium in patients and in a swine model of reperfused myocardial infarction (MI). The association of eosinophil dynamics with various outcomes was assessed. Methods Serial eosinophil count and pre-discharge cardiac magnetic resonance were carried out in a prospective series of 620 patients with a first ST-elevation MI. In a swine model of reperfused MI, the dynamics of circulating eosinophils and their presence in the infarcted myocardium were determined. In autopsies from chronic MI patients, eosinophils were quantified. Results Patient eosinophil count sharply decreased 12h post-reperfusion compared to arrival. A lower minimum eosinophil count was associated with more extensive edema, microvascular obstruction, and infarct size as measured by cardiac magnetic resonance, and also with a higher rate of cardiac events (death, re-infarction, or heart failure) during follow-up. In the experimental model, eosinophil count boosted during ischemia and dropped back immediately post-reperfusion. Myocardial samples revealed progressive eosinophil migration into the infarcted myocardium, especially areas with microvascular obstruction. Markers of eosinophil maturation and survival (interleukin-5), degranulation (eosinophil cationic protein) and migration (eotoxin-1) were detected in the blood of patients, and in porcine myocardium. Eosinophil infiltration was detected in autopsies from chronic MI patients. Conclusion Eosinopenia post-MI was associated with an impaired cardiac structure and adverse events. The decay in circulating eosinophils soon after reperfusion mirrors their migration into the infarcted myocardium, as reflected by their presence in heart samples from swine and patients. Further studies are needed to understanding this unexplored pathway and its therapeutic implications.', 'title': u'Characterization and implications of the dynamics of eosinophils in blood and in the infarcted myocardium after coronary reperfusion', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206344', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Characterization and implications of the dynamics of eosinophils in blood and in the infarcted myocardium after coronary reperfusion\n\nFigures\nAbstract\nObjective\nWe characterized the dynamics of eosinophils in blood and in the infarcted myocardium in patients and in a swine model of reperfused myocardial infarction (MI). The association of eosinophil dynamics with various outcomes was assessed.\nMethods\nSerial eosinophil count and pre-discharge cardiac magnetic resonance were carried out in a prospective series of 620 patients with a first ST-elevation MI. In a swine model of reperfused MI, the dynamics of circulating eosinophils and their presence in the infarcted myocardium were determined. In autopsies from chronic MI patients, eosinophils were quantified.\nResults\nPatient eosinophil count sharply decreased 12h post-reperfusion compared to arrival. A lower minimum eosinophil count was associated with more extensive edema, microvascular obstruction, and infarct size as measured by cardiac magnetic resonance, and also with a higher rate of cardiac events (death, re-infarction, or heart failure) during follow-up. In the experimental model, eosinophil count boosted during ischemia and dropped back immediately post-reperfusion. Myocardial samples revealed progressive eosinophil migration into the infarcted myocardium, especially areas with microvascular obstruction. Markers of eosinophil maturation and survival (interleukin-5), degranulation (eosinophil cationic protein) and migration (eotoxin-1) were detected in the blood of patients, and in porcine myocardium. Eosinophil infiltration was detected in autopsies from chronic MI patients.\nConclusion\nEosinopenia post-MI was associated with an impaired cardiac structure and adverse events. The decay in circulating eosinophils soon after reperfusion mirrors their migration into the infarcted myocardium, as reflected by their presence in heart samples from swine and patients. Further studies are needed to understanding this unexplored pathway and its therapeutic implications.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: This work was supported by the "Instituto de Salud Carlos III and co-funded by Fondo Europeo de Desarrollo Regional (FEDER)\u2019 [grant numbers PI17/01836, PIE15/00013, and CB16/11/00486] and Generalitat Valenciana [GV/2018/116].\nCompeting interests: The authors have declared no competing interests exist.\nIntroduction\nEosinophils are granulocytic leukocytes that play an essential role in allergic reactions, asthma, and parasitic infections. Although eosinophils normally account for only 1\u20133% of circulating leukocytes, the number of both peripheral and tissue eosinophils are markedly altered in some inflammatory reactions [1\u20134]. Following activation, eosinophils quickly degranulate and release potent factors to promote protective immunity, coagulation, and platelet aggregation [2]. Indeed, they can be also recruited into an inflammatory focus to modulate the immune response [3,4].\nIn ST-segment elevation myocardial infarction (STEMI), the occurrence of an acute deregulation of the immune system, and its association with the resultant structural myocardial damage and patient outcome has been solidly demonstrated. Indeed, the role of fluctuations in neutrophil and monocyte cell counts and, more recently, in lymphocyte subsets (both in peripheral blood and in the infarcted myocardium) have been widely addressed in this scenario [5\u20138].\nThe deleterious effects of eosinophils in other cardiovascular diseases such as eosinophilic myocarditis are well established [4,9]. Preliminary studies in ischemic heart disease have reported an association between eosinophil cell count and a higher event rate and long-term risk of death after myocardial infarction (MI) [10\u201312]. Furthermore, eosinophils have been histologically detected in intra-coronary thrombi obtained via catheter aspiration in the setting of primary coronary intervention [13,14]. Overall, these observations seem to indicate a potential role of eosinophils in the immune response associated with MI. Nevertheless, a detailed assessment of the dynamics of eosinophils in blood and in the infarcted myocardium after STEMI, as well as the potential structural and clinical implications of these dynamics have been barely addressed so far.\nTo investigate the association between eosinophils (peripheral and myocardial) and outcomes, we focused on the following specific objectives: 1) To analyse serial eosinophil cell count in peripheral blood of reperfused STEMI patients and determine its association with cardiac magnetic resonance (CMR)-derived edema, microvascular obstruction (MVO), and infarct size as well as with the occurrence of major adverse cardiac events (MACE) during follow-up. 2) To determine serial eosinophil cell count in blood obtained from the coronary sinus and to quantify eosinophil cell infiltration into the infarcted myocardium and in areas with MVO in myocardial samples obtained from a swine model of reperfused MI. 3) To scrutinize the temporal evolution in blood (in patients) and in the infarcted myocardium (in swine) of crucial molecules implicated in eosinophil production, maturation, and recruitment. 4) To quantify the presence of eosinophils in myocardial samples obtained from autopsies of chronic MI patients.\nMaterial and methods\nEthics statement\nPatient samples were acquired with appropriate ethical permission from the Hospital Clinico Universitario de Valencia\xb4s Ethics Committee. All procedures involving animals were approved by the University of Valencia\u2019s Animal Ethics Committee (2016/VSC/PEA/00074).\nStudy in STEMI patients\nThe study protocol complies with the 1975 Declaration of Helsinki guidelines. All participating patients provided written informed consent.\nWe prospectively included 691 consecutive patients admitted to a university hospital for a first STEMI between 2004 and 2016 treated with primary coronary intervention and undergoing pre-discharge CMR. Inclusion criteria were stable clinical course during admission, no contraindication to CMR, and no condition related to an alteration of the immune system apart from the MI index.\nCMR.\nPatients included in the study group were examined with a  T System (Sonata Magnetom, Siemens, Erlangen, Germany) 7\xb12 days after STEMI in accordance with our previously validated study protocol [15,16]. CMR studies were analysed offline by an experienced observer blinded to all patient data using customized software (QMASS MR , Medis, Leiden, The Netherlands). Further details on the technical aspects of CMR acquisition, sequences, and quantification can be consulted in the S1 File. Inter- and intra-observer variability for all CMR indices used in the present study is shown in S1 and S2 Tables, respectively.\nLeft ventricular (LV) ejection fraction (%), LV end-diastolic volume index (ml/m2), LV end-systolic volume index (ml/m2), and LV mass index (g/m2) were determined in cine images. As proxies of the magnitude of structural myocardial damage, the extension of myocardial edema (% of LV mass), infarct size (% of LV mass), and MVO (% of LV mass) were quantified. Myocardial edema was regarded as areas of high T2 signal intensity. All short-axis view slices were separately analysed and the presence of edema was visually quantified by manual planimetry and expressed as percentage of LV mass.\nInfarct size (% of LV mass) was assessed as the percentage of LV mass showing late gadolinium enhancement. Microvascular obstruction (MVO,% of LV mass) was quantified by manual planimetry and defined as the percentage of LV mass showing a lack of contrast uptake in the tissue core showing late gadolinium enhancement [15\u201317].\nFollow-Up.\nMACE consisted of cardiac death, admission for nonfatal re-infarction, or for heart failure, whichever occurred first. Current definitions were applied [18,19]. MACE were systematically reviewed from the medical history of each patient available at hospital database and consensus between 2 cardiologists was required to finally classify a cardiac event.\nBlood sampling.\nTotal leukocyte counts, and eosinophil counts (x 1,000 cells/ml) were measured upon patient arrival, and at 12, 24, 48, 72, and 96 hours after revascularization by an automated blood cell counter. Patient serum was obtained by centrifuging blood samples at 2500 rpm for 15 min, and immediately stored at -80\xb0C until further analysis (S1B Fig).\nELISA.\nSerial serum samples obtained from STEMI patients were assayed for eosinophil cationic protein (ECP), for interleukin (IL)-5, and for eotaxin-1.\nStudy in the experimental swine model\nThe experimental study conforms to the guide for the care and use of laboratory animals published by the US National Institutes of Health (NIH Publication No. 85\u201323, revised 1993). Our study protocol has been previously validated [20] and further details can be consulted in the S1 File.\nExperimental groups.\nOne control group and five independent MI experimental groups were formed. In the MI groups, after 90-min occlusion of the mid-left anterior descending artery by an angioplasty balloon, experiments were categorized as follows: 1) no-reperfusion, 2) 1-minute, 3) 3-days, 4) 7-days, and 4) 1-month reperfusion (n = 5 each). The control group (n = 5) was subjected to the same experimental protocol used in the MI groups, but without angioplasty balloon inflation, thus ischemia and infarction were not induced.\nFurther information about macroscopic determination of MVO and infarct size as well as blood sampling is specified in S1 File.\nFlow cytometry analysis.\nFITC-CD45 and PE-CD16 conjugated antibodies (Bio-Rad Laboratories, Hercules, CA) were used to quantify eosinophils in whole blood samples obtained throughout the experimental studies. Eosinophils were gated as CD45+CD16- cells.\nSamples were analysed using a BD FACSVerse flow cytometer (standard 2-laser configuration, BD Bioscience, San Jose, CA), and a minimum of 10,000 events was acquired. FlowJo  software was applied for the analysis of all the acquired data.\nQuantitative real-time polymerase chain reaction.\nThe mRNA expression of eosinophil-specific genes (eosinophil peroxidase (EPO), IL-5, and eotaxin-1) was assessed in myocardial samples obtained from the infarcted and remote areas in the six experimental groups.\nMicroscopic study of eosinophil infiltration.\nExperimental myocardial samples were fixed, embedded in paraffin, sectioned and mounted on glass slides. Hematoxylin-eosin stain (Sigma Aldrich, MI) was performed for histological analysis. Collagen deposition was detected using picrosirius red staining [20]. Luna\u2019s technique was performed for the specific visualization of eosinophil granules [21]. The presence of eosinophils was also assessed by immunohistochemistry using mouse anti-eosinophil major basic protein (EMBP) antibody.\nStudy in autopsies from chronic MI patients.\nMyocardial samples of three patients with a chronic infarct (more than 6 months after acute MI), and three control subjects were obtained from autopsies.\nPresence of eosinophils was histologically evaluated following the same protocol described for the experimental samples (hematoxylin-eosin stain, Luna\u2019s technique, and immunohistochemistry using anti-EMBP antibody).\nStatistical analysis\nData were tested for normal distribution using the Kolmogorov-Smirnov test. Continuous normally distributed data were expressed as the mean \xb1 the standard deviation of the mean and compared using the unpaired Student\u2019s t-test or one-way ANOVA. Non-parametric data were expressed as the median with the interquartile range and compared using the Mann-Whitney U-test or Kruskal-Wallis. Group percentages were compared using the Chi-square test or Fisher\u2019s exact test where appropriate. Linear correlations were assessed using the Pearson\u2019s correlation coefficient. The association of eosinophil minimum count (high>, median value) with time to first MACE was determined by the respective Kaplan-Meier curve and the log-rank test. Statistical significance was considered for two-tailed p-value <. All statistical tests were performed using SPSS  (SPSS, Inc., Chicago, IL).\nResults\nDynamics of eosinophil cell count in peripheral blood of STEMI patients. Association with the magnitude of CMR-derived myocardial structural damage and with the occurrence of MACE during follow-up\nThe baseline and CMR characteristics of the 620 patients included in the final study are shown in Table 1. The evolution of eosinophil count is displayed in Fig 1A. Characteristically, a sharp drop in eosinophil count occurred in the first measurement (12h) post-revascularization.\nAssociation of the dynamics of eosinophil count with the magnitude of the structural myocardial damage.\nThe characteristics of patients with and without CMR-derived extensive edema, MVO, and infarct size are shown in S3\u2013S5 Tables, respectively. The evolution of eosinophil cell count according to the extension of edema, MVO, and infarct size is displayed in Fig 1B\u20131D, respectively. Patients with extensive edema, MVO, and extensive infarction displayed a significantly lower eosinophil count upon arrival than those without extensive myocardial structural damage. This tendency was sustained throughout all measurements post-revascularization with the nadir being detected at 12h post-reperfusion. Therefore, at all time-points, the lower the eosinophil counts the more severe the myocardial structural damage.\nAssociation of the eosinophil count with the occurrence of MACE.\nDuring follow-up (median: 90 weeks; range [33\u2013168] weeks), 125 MACE (38 cardiac deaths, 39 nonfatal myocardial infarctions, and 48 readmissions for heart failure) occurred. Baseline characteristics and CMR parameters related to MACE are displayed in S6 Table. The dynamics of eosinophil count within the first hours and days after STEMI in patients with and without MACE during follow-up paralleled that of patients with and without extensive myocardial damage (Fig 1E). Indeed, as shown in the survival curves analysis (Fig 1F), a minimum eosinophil count less than  x1000cells/ml (median) was strongly associated with a higher probability of MACE. Thus, eosinopenia within the first hours and days after reperfusion of STEMI patients was associated with a higher risk of cardiac events during follow-up.\nDynamics of eosinophil cell count in coronary sinus blood. Eosinophil cell infiltration into the infarcted myocardium and in areas with MVO in swine\nDynamics of eosinophil count in coronary sinus blood in the experimental model.\nTo further characterize the dynamics of circulating eosinophils after MI, especially in the period elapsed between ischemia onset and reperfusion, we investigated the dynamics of circulating eosinophils in a highly-controlled experimental swine model obtaining serial blood samples from the coronary sinus by using flow cytometry. Eosinophils were gated as CD45+CD16- cells (S2 Fig).\nInterestingly, a progressive rise in eosinophil cell count took place soon after ischemia onset (coronary occlusion) that reached its maximum value soon (30 min) after reperfusion. Later (7 days and 1 month after reperfusion), eosinophil count dropped to baseline values (Fig 2A).\nWhole blood was isolated from the experimental model at basal and at different time points of the ischemia and reperfusion process: after 5-min and 85-min of ischemia (immediately before reperfusion) as well as 5-minutes, 30-minutes, 7-days, and 1-month after reperfusion post-MI. Samples were incubated with FITC-CD45 and PE-CD16 and afterwards measured using flow cytometry. (A) Eosinophil counts in whole blood were analysed. Data were expressed as median with the interquartile range (n\u22655 independent experiments) and were analysed by Kruskal-Wallis analysis followed by Dunn\u2019s test. *P< vs. basal. (B) Dynamics of peripheral eosinophils in ST-elevation MI-patients (red) and in the swine model (green). The drop in peripheral eosinophils detected in ST-elevation MI-patients 12h after coronary reperfusion might be preceded by their progressive increase during ischemia and soon after reperfusion, as observed in the experimental model.\nThese results reveal events in a period not accessible for studies in patients and suggest that the fall in circulating eosinophils detected in STEMI patients 12h after coronary reperfusion seems to be preceded by a boost in the number of eosinophils during ischemia and immediately after reperfusion (Fig 2B).\nInfiltration of eosinophils into the infarcted myocardium.\nIn comparison to controls, histological and morphometric analysis of the infarcted myocardium isolated from the experimental model revealed infiltration of eosinophils at 3 days, 7 days, and 1 month post-reperfusion (Fig 3A and 3B). Eosinophils were not detected in myocardial samples obtained from the non-reperfused group or in those obtained immediately (1 min) post-reperfusion (S3 Fig).\n(A) Representative images from infarcted tissue isolated from control and three MI groups (90-min of ischemia followed by 3-days, 7-days, and 1-month reperfusion) stained with hematoxylin-eosin (HE) (first panel). The presence of eosinophils was revealed by staining myocardial samples with Luna\u2019s technique, specific for eosinophil granules (second panel) and with the eosinophil-specific protein eosinophil major basic protein (EMBP) (third panel). (B) Quantification of eosinophil cells in the myocardial tissue. Images from the infarcted area isolated from the four independent groups were quantified with Image-Pro Plus analysis software. Scoring was performed by a blinded observer unaware of the experimental group. (C) The expression of eosinophil peroxidase (EPO) in the infarcted myocardium at different times of the ischemia and reperfusion process. Data (mean\xb1SD, n\u22654) were analysed by one-way ANOVA analysis followed by Bonferroni test. *P<, **P< vs. control.\nA weak gene expression of EPO (an eosinophil-specific protein) occurred in myocardial samples obtained from controls and from the infarcted area of the non-reperfusion and 1-min reperfusion groups. In contrast, a significant up-regulation of EPO was detected in myocardial samples obtained from the infarcted area of the 3-day, 7-day, and 1-month reperfusion groups (Fig 3C). Neither the histological studies nor the mRNA expression demonstrated an increased eosinophil presence in myocardial samples isolated from the remote areas in any of the five MI groups in comparison with controls (S4 Fig).\nIn summary, the rapid increase in circulating eosinophils after ischemia onset detected in the experimental model is followed by a marked fall after reperfusion, both in the experimental and clinical models. Migration of eosinophils into the infarcted myocardium might explain the massive loss of circulating eosinophils.\nInfiltration of eosinophils into the infarcted areas with MVO.\nTo explore the association between the infiltration of eosinophils in the infarcted myocardium following reperfusion and the occurrence of MVO, we carried out 2 studies.\nFirstly, we analysed the extension of MVO in all experiments with macroscopic evidence of infarction. Two groups were defined: experiments with extensive (MVO> 5% of area at risk, median value), and without extensive MVO. Eosinophil infiltration in the infarct area was significantly higher in experiments classified as extensive MVO (Fig 4A). Representative microscopic images of eosinophil infiltration in hearts with extensive and without extensive MVO are shown in S5A Fig.\nFig 4. Infiltration of eosinophils into the infarcted areas with microvascular obstruction (MVO).\n(A) Quantification of infiltrated eosinophils according to the extension of MVO. Animals from the 3-days and 7-days reperfusion groups were categorized according to MVO (extensive: MVO> 5% of area at risk, median value) and the number of eosinophils was morphometrically quantified. (B) Quantification of infiltrated eosinophils in samples obtained from the same heart but comparing infarcted areas with macroscopic MVO and without MVO from the same heart.\nImages were quantified with Image-Pro Plus analysis software. Data (mean\xb1SD, n\u22654) were analysed by Student\u2019s t test. Scoring was performed by a blinded observer unaware of the experimental group. *P< vs. non-extensive MVO.\nSecondly, in the same experiments used for the previous analysis, each heart was individually evaluated and the magnitude of eosinophilic infiltration in samples obtained from the infarcted areas with macroscopic MVO was morphometrically quantified and compared with those infarcted areas without macroscopic MVO. Of note, eosinophil infiltration was significantly higher in infarcted areas with MVO compared with infarcted areas without MVO (Fig 4B). Representative microscopic images of eosinophil infiltration in areas with MVO and without MVO are shown in S5B Fig.\nTherefore, after reperfused MI, eosinophils infiltrate into the infarcted myocardium, and accumulate mainly in areas with MVO. This might in part explain the more extensive CMR-derived myocardial structural damage (especially MVO) and the higher risk of cardiac events detected in STEMI patients with more severe eosinopenia following reperfusion.\nTo investigate the temporal changes in serum levels of IL-5 (an extracellular signal related to eosinophil proliferation, maturation, and survival into the injured tissue), ECP (a cytotoxic molecule secreted after eosinophil activation), and eotaxin-1 (that selectively drives eosinophil recruitment into the damaged area) (S5 Fig), we performed repeated measurements at the pre-defined time-points (upon arrival, and 12h, 96h, and 1-month after reperfusion therapy) in serum obtained from the first 14 STEMI patients included in our final study group and in 10 control subjects. Dynamics of IL-5 and eotaxin-1 genes expression in the infarcted myocardium were investigated in the porcine hearts.\nIL-5.\nIn STEMI patients, soluble IL-5 was persistently elevated from arrival (before reperfusion) and throughout the first month after MI (Fig 5A).\nThe serum levels of interleukin (IL)-5 (A), eosinophil cationic protein (ECP) (B), and eotaxin-1 (C) were determined in samples isolated from control subjects (n = 10) and from ST-elevation myocardial infarction (STEMI)-patients (n = 14) upon arrival and after primary coronary intervention (PCI) (24h, 96h, and 1-month). The expression in the infarcted myocardium of IL-5 (D), and eotaxin-1 (F) were obtained at different times of the ischemia and reperfusion process. The correlation of IL-5 and eotoxin-1 with the expression of eosinophil peroxidase (EPO) (E,G, respectively) was assessed using Pearson correlation coefficient. Continuous normally distributed data are expressed as mean\xb1SD and were analysed by one-way ANOVA analysis followed by Bonferroni test. *P<, ***P< vs. control; +P< vs. 24h post-PCI. Non-parametric data were expressed as the median with the interquartile range and were analysed by Kruskal-Wallis followed by Dunn\u2019s test. &P< vs. control. Abbreviations: EMBP: eosinophil major basic protein.\nIn swine, a weak mRNA expression of IL-5 gene occurred in controls and in the infarcted area of the no-reperfusion and 1-min reperfusion groups. Interestingly, a significant up-regulation of IL-5 was detected in myocardial samples obtained from the infarcted area 3 days, 7 days, and 1 month after reperfusion (Fig 5D). Indeed, a positive correlation between mRNA expression of EPO (a specific marker of eosinophil granules and thus of activity) and IL-5 was detected (Fig 5E). These findings suggest that up-regulation of IL-5 occurs first in peripheral blood and then in the infarcted myocardium. This sequence would permit sustained eosinophil production and cell count recovery from onset of ischemia, and eosinophil survival following migration into the infarcted myocardium.\nECP.\nIn STEMI patients, circulating ECP was significantly elevated upon arrival (before reperfusion), peaking at 24h and 96h, and returning to values similar to control subjects 1 month after infarction (Fig 5B). These results parallel the rapid boost of eosinophil count detected in porcine blood immediately after coronary occlusion and indicate that in STEMI patients, eosinophil activation and degranulation in blood occurs very early after ischemia onset, even before reperfusion, and returns to control levels 1 month post-reperfusion.\nEotaxin-1.\nCirculating eotaxin-1 levels, a potent eosinophil chemoattractant, were significantly higher in control subjects than in STEMI patients. Indeed, no significant dynamic changes where observed in STEMI patients at different time-points of the ischemia-reperfusion process (Fig 5C).\nIn porcine hearts, the gene expression of eotaxin-1 was weak in controls and in the infarcted area of the no-reperfusion and 1-minute reperfusion groups. On the contrary, a marked increase in its expression occurred in the 3-day, 7-day, and 1-month reperfusion groups (Fig 5F). Moreover, a positive correlation existed between the mRNA levels of eotaxin-1 and EPO (Fig 5G).\nAdditionally, the augmented presence of eotaxin-1 in the infarcted tissue was also corroborated by immunohistochemistry (S7 Fig). Eotaxin-1 staining was evidenced in infiltrated leukocytes in the infarcted area of the 3-day and 7-day reperfusion groups, and in interstitial cells of myocardial samples obtained from the infarcted area in chronic phase (1-month reperfusion group). These observations further strengthen the involvement of eotaxin-1 in the recruitment of eosinophils into the infarcted area throughout the sub-acute and chronic phases post-MI.\nThe presence of eosinophils was also determined in myocardial samples of patients with chronic infarction. Clinical and autopsy characteristics of patients included in the study group are displayed in S7 Table. Similar to the porcine model, histological analyses of the infarcted myocardium revealed that, in comparison with control samples, a significant infiltration of eosinophils occurred in patients with chronic MI (Fig 6). Thus, even in chronic phase, a certain eosinophil infiltration persists in the infarcted area of patients.\nDiscussion\nWe undertook the present study in a large series of STEMI patients and in a highly controlled swine model of MI to gain knowledge on the dynamics, implications, and regulation of eosinophils in the setting of acute reperfused MI (S8 Fig).\nDynamics of circulating eosinophils in reperfused STEMI\nA highly controlled and orchestrated immune response is a necessary step for an adequate repair of the infarcted area. In contrast, an excessive and deregulated activation of the inflammatory cascade has been solidly demonstrated to mediate unnecessary myocardial damage and in turn associates with worse clinical outcomes in STEMI patients [5,6]. Peripheral leukocyte count has been traditionally used as a proxy to explore this association. Neutrophil, monocyte and, more recently, lymphocyte cell counts have been the focus of attention in this scenario [5,7,8]. The pro-coagulant and toxic role of eosinophils in the pathophysiology of other cardiovascular diseases such as eosinophilic cardiomyopathy has been previously demonstrated [9]. Nevertheless, in STEMI patients, eosinophils have been barely explored.\nIn our study, the association of these dynamics with the resulting myocardial structural damage was evaluated in 620 STEMI patients using the current gold standard non-invasive imaging technique, namely CMR. The occurrence of MACE was monitored during a 90-week median follow-up. Overall eosinophil count dramatically dropped soon after revascularization, observing the more severe the fall, the more extensive the structural myocardial damage in terms of CMR-derived edema, MVO, and infarct size. Unsurprisingly, and in view of the association of post-reperfusion eosinopenia with the magnitude of these potent prognostic parameters, a sharp loss of circulating eosinophils within the first hours after reperfusion was also related to a higher MACE rate in STEMI patients during follow-up.\nIn line with our results, some studies have reported that a lower eosinophil cell count is associated with a higher risk of cardiac events after MI [10\u201312]. For instance, Shiyovic and co-workers in a cohort of 2,129 patients showed that an increased peripheral eosinophil cell count after admission for STEMI is associated with a lower risk of death at 1-year follow-up [11]. However, Toor and colleagues concluded that augmented eosinophil count is associated with a lower risk of death at 6 month after reperfusion, and a higher death risk at long-term follow-up [12]. These discrepancies between studies could be due to study methodology, or different cohorts. Our results, obtained in a homogeneous group of STEMI patients treated with percutaneous coronary intervention and with pre-discharged CMR, are in line with those obtained by Shiyovic and co-workers [11] suggesting an association between increased lower circulating eosinophil cell count after admission with high risk of MACE.\nAlthough this finding could be incorporated into our daily armamentarium to improve early risk stratification of STEMI patients, this was not the objective of our research since widely validated scores and recommendations already very well achieve this goal. In our view the ultimate interest of the observations obtained in our clinical series lies in turning attention to the need of a deeper understanding of the true dynamics and regulation (both in peripheral blood and in the infarcted region) of eosinophils from MI onset. For this purpose and in parallel with the clinical research we investigated the course of eosinophils as well as of crucial products and regulators of these cells in a swine model of reperfused MI.\nDynamics of circulating eosinophils in a controlled experimental model of reperfused MI\nThe design of clinical studies in MI implies that analyses begin after the first medical contact or more commonly upon patient arrival at the emergency room. This prevents investigation of the dynamics of crucial players in the pathophysiology of MI, in this case inflammatory cells, at the very moment of coronary occlusion and MI onset. For this purpose we used our previously validated porcine model of MI [20] that allowed us to reveal the course of eosinophil count during the period of ischemia (from coronary occlusion until reperfusion). Interestingly a progressive augmentation in peripheral eosinophils was detected during ischemia, peaking immediately after reperfusion (30 min). In parallel to the observations in patients, marked eosinopenia occurred afterwards (Fig 2B). This course suggests a rapid activation and proliferation of theses cells very soon after MI onset, followed by cell loss shortly after reperfusion. This finding would have gone undetected if we had focused our attention only on clinical data and highlights the need for translational research to better understand the complex inflammatory response related to acute MI.\nUsing the same approach, our group has recently reported that circulating lymphocyte count exhibits a similar pattern as that shown in the case of eosinophils: a rapid proliferation during ischemia and immediately post-reperfusion, followed by a sharp decline afterwards [7]. Research on inflammatory cells in MI has traditionally focussed on neutrophils and monocytes. It has been solidly demonstrated that neutrophil and monocyte counts progressively increase during the first hours and days after coronary reperfusion [5]. Although beyond the scope of the present study, according to these data the course of circulating inflammatory cells subsets seems to display two different patterns following MI: a rapid rise after ischemia onset and a fall after reperfusion in the case of eosinophils and lymphocytes, and a more progressive and sustained increase in the case of neutrophils and monocytes [5,7]. It could be speculated that these patterns may exert an influence on the two waves of myocardial edema following reperfused MI in swine and patients as recently reported [22]. However, further and dedicated research would be needed to verify this and other plausible hypotheses derived from our observations.\nEosinophil migration into the infarcted myocardium\nAccording to our results, eosinophil cell count boost after MI onset is followed by severe decay in peripheral circulation in the hours after coronary revascularization. The mechanisms underlying this sequence are not yet fully understood. Involvement in coronary thrombi formation [14] might in part explain this vanishing of eosinophils from circulation. In fact, Jiang et al. histologically examined aspirated coronary thrombi after acute coronary syndrome, and all samples displayed eosinophil deposition [13]. However, it is difficult to understand that such a massive loss of peripheral cells could be explained just by eosinophil plugs at the point of occlusion. Moreover in the swine model, where thrombosis is not the leading cause of coronary flow interruption, massive eosinopenia following reperfusion occurred in a similar fashion to that observed in patients. Although accumulation of eosinophils in the occluding thrombus occurs, and may even participate in the initial steps of the pathophysiology of coronary occlusion, the presence of these cells at this point may also be in part the consequence of their retention when making their way towards the infarcted myocardium where release of potent signals massively attract inflammatory cells. Examining our results, it seems progressive migration and infiltration of eosinophils into the infarcted myocardium post-reperfusion of the coronary occlusion are crucial to understanding their rapid decline in the blood stream.\nIn 1978, Fishbein and coworkers first demonstrated the presence of eosinophils in the infarcted myocardium [23]. Since then, management of MI has dramatically changed and the use of coronary reperfusion therapies is now mandatory. However, as far as we know, no further studies have closely investigated the dynamics of eosinophils cells into the infarcted area. Thus, updating knowledge on this issue under current standards appears highly recommendable.\nWe histologically detected the presence of eosinophils in the infarcted area soon (3 days, 7 days) and late (1 month) after reperfusion in experimental samples. These cells persisted in myocardial samples obtained from patients late (>6 months) after MI. Migration of eosinophils into injured tissues has been described in many pathological situations, where they undergo degranulation, exert pro-coagulant and toxic effects, and modulate the immune response through different mechanisms [3,4].\nInterestingly, eosinophil infiltration was more intense in areas with the most severe structural damage, namely with MVO. This is a multifactorial process characterized by microvascular disruption leading to severe myocardial structural damage. Not surprisingly this phenomenon exerts deleterious effects on LV remodelling and on patient outcomes. The mechanisms underlying microvascular damage in reperfused MI are far from being completely understood [24]. Neutrophil plugging has been traditionally related to the occurrence of MVO. Similar to neutrophils, eosinophils also display potent pro-coagulative and disruptive functions. In fact, eosinophil extracellular traps have been evidenced not only in coronary thrombi but also in a variety of inflammatory pathologies [25]. The presence of eosinophils in zones with MVO in experiments parallels the more severe eosinopenia detected in STEMI patients with MVO. These findings strongly suggest that eosinophils play an important role in the inflammatory response associated with reperfused MI and the resulting structural myocardial damage. Tissue-infiltrating eosinophils are reported to be responsible for modulating acute phase and innate inflammatory reactions. Therefore, a plausible mechanism is that the marked eosinophilia in areas with more severe cardiac damage might provoke a local deregulated inflammatory reaction, and consequently higher myocardial damage [26].\nTo further clarify the dynamics of eosinophils in this setting, we sequentially determined crucial proteins related to their maturation, activation and recruitment, both in peripheral blood and in myocardial samples.\nDynamics of crucial molecules related to eosinophils after MI\nEosinophils are granulocytic leukocytes actively involved in numerous inflammatory processes [3,4]. Infiltration into damaged tissue is a complex process orchestrated by a number of crucial cytokines and chemokines (S5 Fig). Briefly, IL-5 is specifically responsible for eosinophil differentiation in bone marrow, activation, and survival both in peripheral blood and in tissue. Eotaxin-1/CCL11, eotaxin-2/CCL24, and eotaxin-3/CCL26 are eosinophil-specific chemokines implicated in eosinophil trafficking and attraction towards the inflammatory focus [1,2]. Although data regarding cardiovascular diseases are scarce, studies related to eosinophilic myocarditis suggest that eotaxin-1 plays a pivotal role in the attraction and migration of eosinophils into the myocardium [4]. Once activated, eosinophils degranulate and release a number of cytokines and chemokines (. EPO, ECP, and EMBP) implicated in coagulation disturbances and tissue disruption among others [1,2]. Although this pathway has been fully described in different pro-inflammatory scenarios, whether the same sequence occurs in the setting of MI is unclear. To investigate this point, we monitored the dynamics of crucial products related to the activity, recruitment, and survival of these cells in peripheral blood and in the infarcted myocardium.\nECP, a marker of eosinophil activity, is released by cell degranulation and participates in the activation of the coagulation cascade. It has been previously reported that ECP can increase in the whole spectrum of stable and unstable ischemic heart disease [27,28]. In STEMI patients we detected raised ECP levels upon patient arrival that returned to control levels 1 month post-reperfusion. This tendency paralleled the rapid boost of eosinophil count detected in porcine blood immediately after coronary occlusion and indicates that eosinophil activation and degranulation in blood occurs very early after ischemia onset, even before reperfusion. It could be speculated that this early activation and degranulation of eosinophils may exert a role in the pro-coagulant milieu in coronary macro- and micro-circulation and as a consequence in the initial stages of edema, MVO, and necrosis.\nEotaxin-1 is a potent eosinophil-specific chemoattractant that has been related, not only to eosinophil recruitment, but also to vascular inflammation [29] and has been implicated in a variety of pathological situations [1,2,4]. A strong up-regulation of this protein was observed in infarcted hearts during acute (3 days and 7 days), and chronic phases after MI. Simultaneously, an enhanced expression of EPO (a marker of eosinophil activity in tissues) and progressive eosinophil infiltration took place. Together, these findings suggest that shortly after the acute degranulation detected in peripheral blood, eotaxin-1 mediates eosinophil trafficking and infiltration, thus enabling the subsequent activity of these cells in the infarcted myocardium.\nFinally, involvement of IL-5 has been demonstrated in eosinophil differentiation, activation and survival, both in peripheral blood and in tissue [1,2]. Serum IL-5 levels were persistently elevated in STEMI patients from arrival and throughout the first month of follow-up. In the swine model, IL-5 expression in the infarcted area increased at 3 days and remained elevated at 1 month. These findings corroborate the sequence described for the other products: up-regulation of IL-5 occurs first in peripheral blood and then in the infarcted myocardium. Finally, this sequence permits peripheral cell count recovery and eosinophil survival following migration into the infarcted myocardium.\nLimitations of the study\nThe present study demonstrates the participation of eosinophils and their products in the pathophysiology of reperfused MI and their association with the magnitude of the myocardial structural damage and the clinical course of patients. The causal role of eosinophils in these associations and the potential therapeutic interventions that could be derived need to be addressed in future studies.\nFurthermore, since some differences in eosinophil physiology between humans and swine may exist, further clinical investigation might be carried out in order to continue elucidating the role of eosinophils after MI.\nConclusions\nIn the setting of reperfused MI, eosinophils exhibit important dynamic changes, both in peripheral blood and in the infarcted area. Peripheral eosinophilic cells display a rapid activation immediately after coronary occlusion, followed by a massive loss soon after reperfusion. This sequence induces massive eosinopenia, that in STEMI patients is associated with more severe structural myocardial damage and higher risk of cardiac events. Simultaneously, release of potent mediators induces sustained eosinophil proliferation, activation, and migration into the infarcted area. Finally, the acute peripheral cell count decay appears to be mediated by myocardial infiltration that takes place mainly in zones with the most severe structural damage, namely with MVO, and persists in chronic phases.\nThe presented results strongly suggest the need for further studies to better understand the pathophysiological role of this almost unexplored pathway as well as the potential therapeutic implications that could be subsequently explored.\nSamples were incubated with FITC-CD45 and PE-CD16 and afterwards measured using flow cytometry. Eosinophils were identified from the rest of leukocytes as CD45+CD16- cells (left panel). Representative histograms from basal (central panel) and 30-min post-reperfusion (right panel) samples were displayed.\n(A) Representative images from infarcted tissue isolated from control and two MI groups (90-min of ischemia followed by no reperfusion and 1-min reperfusion) stained with hematoxylin-eosin (HE) (upper panel). The presence of eosinophils was revealed by staining myocardial samples with Luna\u2019s technique, specific for eosinophil granules (lower panel). (B) The expression of eosinophil peroxidase (EPO) in the infarcted myocardium at different times of the ischemia and reperfusion process. Data (mean\xb1SD, n\u22654) were analysed by one-way ANOVA analysis followed by Bonferroni test.\n(A) Representative images from infarcted tissue isolated from control and five MI groups (90-min of ischemia followed by no reperfusion, 1-min, 3-days, 7-days, and 1-month reperfusion) stained with hematoxylin-eosin (HE) (upper panel). The presence of eosinophils was revealed by staining myocardial samples with Luna\u2019s technique, specific for eosinophil granules (upper panel). (B) The expression of eosinophil peroxidase (EPO) in the remote myocardium at different times of the ischemia and reperfusion process. Data (mean\xb1SD, n\u22654) were analysed by one-way ANOVA analysis followed by Bonferroni test.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:46Z', 'description': u'by Joshua S. Park, Ravneet Vohra, Thomas Klussmann, Niclas E. Bengtsson, Jeffrey S. Chamberlain, Donghoon Lee\n\nIn this study, multi-parametric magnetic resonance imaging (MRI) was conducted to monitor skeletal muscle changes in dystrophic (mdx4cv) and age-matched control (C57BL/6J) mice starting at 3 weeks of age. The objective of this study was to evaluate and characterize changes in muscle tissue characteristics of hind limbs in young, dystrophic mice using MRI. Mdx4cv (n = 25) and age-matched C57BL/6J (n = 5) were imaged at 3, 5, 7, 9, and 11 weeks of age. Multiple MR measurements were taken from the tibialis anterior, gastrocnemius, and soleus muscles. There were significant differences between dystrophic and control groups for all three muscle types when comparing transverse relaxation times (T2) in lower hind limb muscles. Additionally, fractional anisotropy, radial diffusivity, and eigenvalue analysis of diffusion tensor imaging also demonstrated significant differences between groups. Longitudinal relaxation times (T1) displayed no significant differences between groups. The earliest time points in the magnetization transfer ratio measurements displayed a significant difference. Histological analysis revealed significant differences in the tibialis anterior and gastrocnemius muscles between groups with the mdx mice displaying greater variability in muscle fiber size in later time points. The multi-parametric MRI approach offers a promising alternative for future development of a noninvasive avenue for tracking both disease progression and treatment response.', 'title': u'Non-invasive tracking of disease progression in young dystrophic muscles using multi-parametric MRI at 14T', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206323', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Non-invasive tracking of disease progression in young dystrophic muscles using multi-parametric MRI at 14T\n\nAffiliations\nDepartment of Neurology, University of Washington, Seattle, WA, United States of America,\nSenator Paul D. Wellstone Muscular Dystrophy Cooperative Research Center, University of Washington, Seattle, WA, United States of America\nAffiliations\nDepartment of Neurology, University of Washington, Seattle, WA, United States of America,\nSenator Paul D. Wellstone Muscular Dystrophy Cooperative Research Center, University of Washington, Seattle, WA, United States of America,\nDepartment of Biochemistry, University of Washington, Seattle, WA, United States of America,\nDepartment of Medicine, University of Washington, Seattle, WA, United States of America\nFigures\nAbstract\nIn this study, multi-parametric magnetic resonance imaging (MRI) was conducted to monitor skeletal muscle changes in dystrophic (mdx4cv) and age-matched control (C57BL/6J) mice starting at 3 weeks of age. The objective of this study was to evaluate and characterize changes in muscle tissue characteristics of hind limbs in young, dystrophic mice using MRI. Mdx4cv (n = 25) and age-matched C57BL/6J (n = 5) were imaged at 3, 5, 7, 9, and 11 weeks of age. Multiple MR measurements were taken from the tibialis anterior, gastrocnemius, and soleus muscles. There were significant differences between dystrophic and control groups for all three muscle types when comparing transverse relaxation times (T2) in lower hind limb muscles. Additionally, fractional anisotropy, radial diffusivity, and eigenvalue analysis of diffusion tensor imaging also demonstrated significant differences between groups. Longitudinal relaxation times (T1) displayed no significant differences between groups. The earliest time points in the magnetization transfer ratio measurements displayed a significant difference. Histological analysis revealed significant differences in the tibialis anterior and gastrocnemius muscles between groups with the mdx mice displaying greater variability in muscle fiber size in later time points. The multi-parametric MRI approach offers a promising alternative for future development of a noninvasive avenue for tracking both disease progression and treatment response.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nThe muscular dystrophies are a group of inherited diseases that are characterized by progressive muscle wasting and weakness. Duchenne muscular dystrophy (DMD) is the most prevalent, and severe, form of muscular dystrophy affecting approximately 1 in every 5000 male births [1, 2]. DMD is an X-linked recessive degenerative condition with no cure and an average life expectancy of approximately 25\u201330 years [3]. Mutations in the dystrophin gene at locus Xp21 result in abnormal or absent expression of dystrophin: a 427 KDa cytoskeletal protein [4]. Dystrophin is responsible for linking actin filaments underlying the muscle sarcolemma to the extracellular matrix via assembly of the dystrophin-glycoprotein complex (DGC). Disruption of the DGC reduces lateral transmission of forces from muscle cells, affecting membrane integrity and intracellular signaling, which leads to necrosis and replacement of muscle with fatty and connective tissues [5\u20137]. This steady and progressive muscle deterioration ultimately results in respiratory and cardiac failure.\nThe most commonly used animal models in preclinical studies of DMD are various strains of mdx mice. Previous studies have shown critical periods of muscle degeneration and regeneration within the first 2\u20134 months of life, peaking between weeks 4 and 5 [8]. Additionally, differences and abnormalities in muscular integrity have been seen in cardiac muscle as early as one month of age while skeletal muscles have shown differences for mice as early as 5 weeks of age [9]. After this early period, necrosis gradually decreases until a low and persistent level is reached in the adult mdx mouse [10]. The phenotype observed in the mdx mouse is much less severe than in human DMD patients. Regardless, there are similar aspects between the mdx and DMD phenotype such as centrally nucleated muscle fibers, widespread myofiber necrosis, variations in myofiber size, and an increased susceptibility to contraction-induced injury [6, 10]. One of the significant hurdles encountered so far is lack of sensitive quantitative biomarkers to monitor disease progression in both preclinical and clinical models of DMD. Both preclinical and clinical assessment of tissue characteristics has historically been achieved through surgical biopsy that fails to provide detailed information throughout the whole muscle because the invasive nature of the procedure greatly restricts both the sampling regions and sampling frequency [11\u201314].\nOver the last decade, the emergence of non-invasive measures has provided an alternative means for acquiring such tissue information without the same limitations [9, 15, 16]. Indeed, magnetic resonance imaging (MRI) has been used to monitor disease progression in both human and preclinical models. One of the limitations of the aforementioned studies is that a single MRI parameter was used to monitor the disease progression in preclinical and human populations [17\u201321]. However, recent utilization of multi-parametric MRI (mp-MRI) involving a host of different parameters; such as longitudinal (T1) and transverse (T2) relaxation times, magnetization transfer ratio (MTR), and diffusion MRI, have been incorporated to study treatment effects of adeno-associated viral (AAV) vector-mediated gene therapy in mdx mice [22, 23]. These multimodal MR approaches to tissue characterization have shown the ability to detect pathological changes in a variety of diseases at the cellular level.\nThe previously documented cyclical pattern of degeneration, regeneration, and inflammation; which stabilizes around 11\u201312 weeks of age, is poorly characterized beyond the gold standard MR measures of T1 and T2. Because of this, there remains an incomplete understanding of the cellular processes occurring during this critical time of development and how to utilize MR to capture this data. This period of cyclical changes has been observed but not characterized for possible treatment at such an early age using many MR parameters [24]. A more complete understanding of the disease progression is necessary in order to open possible avenues for future treatment regimens and translation into human clinical studies.\nThe goal of this study was to evaluate and characterize changes in muscle tissue characteristics in young mdx4cv mice using in vivo MRI and histology to better understand the progression of the disease at this early stage to enable development of potential therapeutic plans exploring the possibility of better treatment outcomes.\nMaterials and methods\nAnimals\nIn this study, we conducted multi-parametric MRI for two groups of mice: one group of normal (C57BL/6J) mice and one group of mdx4cv (-Dmdmdx-4Cv/J) mice [25]. All mice were housed and treated in strict accordance with the National Institutes of Health (NIH) Guide for the Care and Use of Experimental Animals and approvals from the Institutional Animal Care and Use Committee (IACUC, protocol number 4210\u201301) of the University of Washington. The mice were housed in specific pathogen free (SPF) facilities running 12:12 light/dark cycles at ambient temperatures of 22\u201323\xb0C with access to food and water ad libitum. All of these conditions were maintained for the duration of the study.\nStudy design\nBoth mdx4cv and C57BL/6J mice were obtained at 3 weeks of age. These groups were longitudinally tracked beginning at 3 weeks of age and ending at 11 weeks of age. The mice were imaged utilizing T1, T2, diffusion weighted imaging (DWI), diffusion tensor imaging (DTI), and magnetization transfer imaging (MTI) every two weeks for a total of 5 time points to monitor disease progression and differences between the groups. Additional groups of 5 mdx4cv mice were imaged at each time point and subsequently sacrificed and used for histological assessments. In total, there were mdx4cv (n = 25) mice along with the age matched normal C57BL/6J (n = 5) mice that were imaged at 3, 5, 7, 9, and 11 weeks of age as part of the longitudinal or single time point groups. For histological measurements, mice were anesthetized and euthanized by cervical dislocation while under anesthesia. All mice were euthanized following the conclusion of the study.\nMR data analysis\nImage analysis of MR images was conducted using ImageJ software (), developed by the National Institutes of Health, to measure mean values of tibialis anterior (TA), gastrocnemius (GA), and soleus (SOL) muscles. Maximum cross sectional area (CSAmax) of individual muscles was outlined to determine CSAmax, which was calculated as the mean of the consecutive three slices having the greatest CSA for all the muscles. Furthermore, T1, T2 and MTR were calculated using the same region of interests [23]. Finally, for each muscle, four parameters . three eigenvalues (\u03bb1 > \u03bb2 > \u03bb3) and Fractional Anisotropy (FA) were calculated. Mean diffusivity (MD) was calculated by averaging the three eigenvalues and Radial diffusivity was calculated by averaging \u03bb2 and \u03bb3. FA is a function of all three eigenvalues that varies from 0 to 1 [26]. To improve coverage and reliability, muscles were measured for three consecutive slices at the mid-belly of the hind limb muscles [23].\nHistological analysis\nHistology was conducted to correlate MRI results between various age groups of mdx4cv mice. Right hind limbs were collected and fixed in 4% paraformaldehyde (PFA) solution for 24 hours while the individual muscles (TA, GA, and SOL) of the left leg were harvested and immediately frozen in optimum cutting temperature medium (OCT). The right hind limbs were subsequently decalcified in 5% formic acid for another 24 hours before rinsing and being placed into sucrose solutions (10, 20, and 30%) overnight. These right hind limbs were then frozen in OCT before being sectioned (alongside the individual muscles of the left leg) into serial, 8-\u03bcm thick sections cut with a cryostat (CM1950, Leica Biosystems Inc., Buffalo Grove, Illinois) and stained with hematoxylin and eosin (H&E) and Masson\u2019s trichrome. All sections were examined using an 80i upright microscope (Nikon, Melville, New York). Muscle fiber cross sectional area was measured using NIH ImageJ software. All the individual muscle fibers were manually traced and fiber area was recorded for 150\u2013200 muscle fibers in each mouse.\nStatistical analysis\nAll statistical analysis was conducted using Graph Pad Prism  software (GraphPad Software, USA). Values of TA, GA, and SOL muscles were compared at each time point between the right and left legs of the mdx4cv and control mice. All Statistical analyses were performed using GraphPad Prism 6 software (GraphPad Software, La Jolla, CA, USA) and included one-way analysis of variance (ANOVA) followed by Tukey\u2019s multiple comparisons test. Independent sample t test was used to make comparisons between mdx4cv and control mice at 11-week time point. All data was presented in means and standard deviations with a statistical significance of p <  being accepted.\nResults\nTemporal changes in muscle cross sectional area in mdx4cv and control groups\nT1 and T2 relaxation time and MTR differences between mdx4cv and control groups\nMp-MRI displayed significant differences when comparing different parameters between mdx4cv and normal mice. Fig 2 displays the longitudinal tracking of average T2, T1, and MTR values for mdx4cv mice versus controls. There were significant differences between the groups when analyzing the results of the T2. P-values ranged from < to , < to , and < to  for the GA, TA, and SOL, respectively. T2 measurements in control mice displayed an average decrease in relaxation time of approximately 10% between the first (3 weeks of age) and final (11 weeks of age) time points across all three muscles (TA, GA, and SOL). In mdx4cv mice, the average percentage change for the analyzed muscle types was far more variable (., % decrease in T2 of TA muscle, % decrease for GA and % decrease for SOL muscles). Statistical analyses for each group of mice from week to week revealed no significant changes in either mdx4cv mice. Significant drop in T2 was detected in control muscles from 3 weeks (mean \xb1 SD, TA;  \xb1  ms, GA; \xb1 ; SOL,  \xb1  ms) to 11 weeks of age (TA;  \xb1  ms, GA;  \xb1  ms; SOL,  \xb1  ms). T1 measurements revealed no significant differences between groups with control mice having slightly higher average values than the mdx4cv mice with few exceptions. MTR measurements show little significance between groups, with only the earliest time points demonstrating significant differences in MTR as shown in Fig 2G, 2H and 2I. There were no significant changes within groups over the course of the study. Longitudinal quantitative T2, T1, and MTR maps overlaid on the corresponding images are displayed in Fig 3.\nGraphs displaying the average longitudinal values of the mdx4cv and control mice muscles in the T2, T1, and MTR measures. T2 values for the mdx4cv mice were significantly higher at all time points versus age-matched controls. *p \u2264 , **p \u2264 , ***p \u2264 , and ****p \u2264 . Significant higher T2 values were detected in ctrl mice at 3 weeks of age compared to other time-points. \u2021p \u2264 .\nGraphs displaying average longitudinal eigenvalues \u03bb1, \u03bb2, and \u03bb3 of mdx4cv and control mouse muscles. \u03bb1 values for mdx4cv mice were significantly lower at the 3- and 5-week time points versus age-matched controls in all muscles (top panels), while \u03bb3 values for mdx4cv mice were significantly higher at 9 and 11 weeks (bottom panels). \u03bb2 values were not significantly different between groups until the 11-week time point in the TA muscle (middle panels). *P \u2264 , **P \u2264 , ***P \u2264 , and ****P \u2264 .\nFig 6. Average muscle fiber area, and \u03bb3 versus average muscle fiber area for TA and GA muscles.\nIndividual muscle fiber areas were measured for the TA and GA muscles and then averaged for comparison between groups. Mdx4cv mice exhibit significantly reduced average individual muscle fiber area for both TA and GA muscles. This data was then plotted against the \u03bb3 values for correlation of diffusivity across single muscle fibers and average fiber size. *P \u2264 , **P \u2264 , ***P \u2264 , and ****P \u2264 .\nDiscussion\nUtilization of mp-MRI has been shown to be a valuable tool in the investigation of skeletal muscle pathology and the present study used mp-MRI to explore young adult mdx4cv mouse muscle pathology versus healthy age-matched controls. Previous studies have demonstrated that the cyclical changes occur in skeletal muscles of young dystrophic mice [17, 27]. However, these studies did not begin as early as 3 weeks of age nor used a multi-parametric characterization approach. The results of the present study demonstrate that 1) T2 continues to be the most sensitive parameter for observing dramatic changes in dystrophic muscle tissue 2) FA is particularly sensitive during this early phase and 3) radial diffusivity and eigenvalue comparisons (\u03bb1 and \u03bb3 in particular) display moderate sensitivity for detecting dystrophic muscle changes.\nTemporal behavior of MR parameters\nT2 measurements of TA, GA, and SOL muscles showed significant differences when comparing mdx4cv mice compared to age-matched controls. This confirms previous findings demonstrating increased sensitivity of T2 measurements in both preclinical and clinical models of DMD [23, 24, 28]. There was an age dependent T2 decline in healthy control mice from 3 weeks to 5 weeks of age after which the T2 values were stable. However, mdx4cv mice underwent demonstrated cyclical changes in the lower hind limb muscles. In fact, increased body of evidence has reported that younger mdx mice go through cycles of inflammation, necrosis, and regeneration between 3\u201310 weeks of age, with decreased but ongoing cycles of necrosis and regeneration thereafter [8, 29]. Additionally, it has been reported that there is 2-4-fold increase in utrophin protein in dystrophic muscles and it localizes at the sarcolemma of regenerating fibers [30, 31]. The T2 values from mdx4cv mice were always elevated when compared to control mice\u2013a pattern which was not reflected as strongly in other MR parameters. The average T2 values in our study ranged between 22\u201326 ms in mdx mice and 17\u201320 ms in control muscles were smaller as compared to previously published (~ 30 ms in mdx mice and 27 ms in controls measured at ) [24]. Tissue T2 has been shown to decrease with increase in magnetic field strength thus providing one explanation of difference between the two studies. The T2 relaxation in skeletal muscle has been attributed to three primary signal components (<5, 25\u201345, and >100 ms) with the intermediate value range contributing most to the overall signal [32\u201335]. In particular, these intermediate values are related to the hydration of macromolecules as well as the presence of intracellular- and extracellular water. Utilizing T2 scans to effectively identify responses for such intracellular and extracellular water in conjunction with fat suppression has been hypothesized to reflect either increase of extracellular compartments, necrotic regions, or inflammation and edema [36\u201339], but not from fatty infiltration [40\u201342]. As seen in the values obtained for normal muscle, T2 values were at their highest in the earliest weeks of the study and gradually decreased towards later time points. These values stabilized and previous research indicates that such T2 values are associated with normal hydration of the extracellular space of skeletal muscle [33, 34]. Because the T2 can be readily affected by any of such changes, the utilization of mp-MRI to capture a more nuanced understanding of possible biomarkers is highly informative.\nMagnetization transfer ratio (MTR) is a measure of the efficiency of magnetization transfer between bound ("restricted") and adjacent mobile ("free") water protons. When tissue is damaged, there are fewer hydrogen atoms bound to macromolecules, which leads to a decreased magnetization transfer [43]. Additionally, because muscle fibers that are well organized can be expected to have an increased abundance of macromolecules, MTR should be higher in the muscles of healthy controls [44]. Furthermore, studies using MT imaging have suggested its utility in evaluating skeletal muscles [45, 46]. While not significantly higher at all time points, the MTR measurements displayed a general trend with lower values found in the mdx4cv group versus controls at earlier time points. MT could still prove to be useful in measurements of mdx mice because fatty tissue does not show MT due to the lack of water molecules [44]. Additionally, MT has been shown to be sensitive to fibrosis formation in other diseases such as Crohn\u2019s disease [47] and pancreatic tumors [48, 49]. Thus, measurements of MT in mdx4cv mice at a young age could be further refined to capture early fibrotic tissue formation in young muscle as well as fibrosis seen in older mdx4cv mice for useful translation to human studies of DMD where fatty infiltration and higher levels of fibrosis also occur in skeletal muscle.\nIncreased body of evidence suggests that any insult to skeletal muscles may lead to alteration in FA and corresponding changes in diffusivity measures [50\u201352]. Although, techniques like T2 and MT imaging are sensitive to various underlying pathological processes, they are not ideal for quantifying changes in muscle fiber morphology [52]. Specifically, eigenvalues have been suggested as indicators of water diffusion across various axes of muscle fibers [53], with \u03bb1 representing diffusion along the long axis of the fiber [54, 55]. Galb\xe1n et al. demonstrated that \u03bb2 represents diffusion within the endomysium and \u03bb3 represents diffusion within the cross section of a muscle fiber [53]. Furthermore, a study by Zhang et al. has demonstrated decrease in secondary and tertiary eigenvalues in a complete denervation and chronic denervation models [56]. In addition, Heemskerk et al., in an ischemic model, have demonstrated an increase in mean diffusivity and a correlation between swollen myocytes and smallest eigenvalue, . \u03bb3 [51]. Our findings are in-line with these previous observations and suggest that secondary and tertiary eigenvalues are markers of muscle fiber atrophy. The diffusion and MTR values, in conjunction with the three eigenvalues themselves suggest diffusion along the axis of individual muscle fibers is disrupted in mdx4cv mice while diffusion perpendicular to individual and bundles of fibers is increasing. Possible explanations for these observations include that the presence of compromised myofiber membranes could increase diffusion out of myofibers; as well as that areas of necrotic/degenerating fibers would greatly increase multi-directional diffusion until regeneration, fibrosis or adipogenesis occurs.\nMuscle fiber cross-sectional area analysis revealed a significant difference in TA and GA muscles of mdx4cv and control mice. Additionally, at 11 weeks of age we observed greater degree of variability in muscle fiber size of mdx4cv mice compared to age-matched control mice. This could be attributed to cyclical periods of degeneration and regeneration, which leads to higher number of smaller fibers and occurrence of hypertrophic fibers [8, 57]. Finally, the analysis of the fiber size distribution revealed a tendency of a shift toward a higher number of smaller myofibers in mdx4cv mice compared to control mice. Our findings are in agreement with previously published results [57, 58].\nThe study had limitations that should be acknowledged. The multi-parametric nature of the study meant that because of the many parameters being acquired, the scans had to be modified and optimized in order to ensure the mouse\u2019s condition did not deteriorate due to excessively prolonged anesthesia. For example, the maximum TR of  seconds used for T1 determination was slightly short considering the T1 of muscle is close to 3 seconds. This in turn affects the quality of the maps being used for the measurements, which may increase standard deviation. Future studies should focus on optimizing scan protocols further, particularly for T1 measurements with longer TR (9 seconds or longer) than  seconds and ADC measurements using recent advances in DWI. Additionally, such studies could also incorporate more nuanced histological assessment for additional corroboration. Finally, future studies could operate at preclinical/clinical field strengths for direct translation into tracking of human trials of DMD treatment.\nConclusions\nMp-MRI can be used to identify quantifiable differences between mdx4cv and normal mice that can be monitored over time noninvasively. Mp-MRI parameters such as T2, FA, radial diffusivity, and eigenvalues are sensitive and significantly different between mdx4cv and normal groups and could prove highly useful in preclinical settings for monitoring disease progression and response to treatments. Radial diffusivity, MT, and eigenvalue analysis also show promise for understanding cellular differences between normal and dystrophic muscle. This multi-parametric data suggests that many MR techniques could be used in preclinical and clinical models of muscular dystrophy treatment.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:48Z', 'description': u'by Michelina Pusceddu, Alessandra Mura, Ignazio Floris, Alberto Satta\n\nThe German yellowjacket (Vespula germanica) is an opportunist predator and a scavenger, whose eclectic diet also includes honey, brood, dead and live honey-bees. There is no evidence in this species of coordinated attacks against bees involving other conspecifics, although intraspecific competition has been already reported between two or more individuals during feeding. Our aim was to gain further knowledge on the feeding behavior of V. germanica in order to evaluate its role in an apiary. Sight observations of predation and necrophagy behaviors were carried out at the ground level near hives. We also investigated how intraspecific competition can influence the feeding display in this species. Our results confirm the major role of the German yellowjacket as a scavenger, because its diet is based mostly on bee carrions. Intraspecific competition during feeding was sometimes observed. When these events occurred, the interference of another wasp led to the bee escaping only in three cases. Our study also revealed that intraspecific competition events increase when the resource is fresh (predation vs necrophagy), and that the number of competing wasps was significantly higher when the food consisted of pupae and drones, compared to adult bees. When competition involved two individuals (the most frequent case), the winner was frequently the first wasp to reach the resource in both predation and necrophagy events. This suggests that the energy invested in foraging or predating activity and in defence of prey is usually rewarded.', 'title': u'Feeding strategies and intraspecific competition in German yellowjacket (Vespula germanica)', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206301', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Feeding strategies and intraspecific competition in German yellowjacket (Vespula germanica)\n\nFigures\nAbstract\nThe German yellowjacket (Vespula germanica) is an opportunist predator and a scavenger, whose eclectic diet also includes honey, brood, dead and live honey-bees. There is no evidence in this species of coordinated attacks against bees involving other conspecifics, although intraspecific competition has been already reported between two or more individuals during feeding. Our aim was to gain further knowledge on the feeding behavior of V. germanica in order to evaluate its role in an apiary. Sight observations of predation and necrophagy behaviors were carried out at the ground level near hives. We also investigated how intraspecific competition can influence the feeding display in this species. Our results confirm the major role of the German yellowjacket as a scavenger, because its diet is based mostly on bee carrions. Intraspecific competition during feeding was sometimes observed. When these events occurred, the interference of another wasp led to the bee escaping only in three cases. Our study also revealed that intraspecific competition events increase when the resource is fresh (predation vs necrophagy), and that the number of competing wasps was significantly higher when the food consisted of pupae and drones, compared to adult bees. When competition involved two individuals (the most frequent case), the winner was frequently the first wasp to reach the resource in both predation and necrophagy events. This suggests that the energy invested in foraging or predating activity and in defence of prey is usually rewarded.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nVespula germanica is a social wasp that is widespread in much of the world. Its native distribution includes Europe, northern Africa, northern India, Korea and China [1], however it is also a successful invasive species in Argentina [2] and Australia [3]. The global success of this species is mainly determined by its food plasticity, which makes it easily adaptable to different environments [4,5,6]. In fact, the European wasp is an opportunist predator and a scavenger because its eclectic diet includes small prey, vertebrate and invertebrate carrions, food and garbage from humans, and also carbohydrates from nectar, fruits and honeydew [7,8,9,10]. Coelho and Hoagland [11] reported that in the late summer and early autumn, German yellowjackets feed on dead honey-bees found at the ground level near hives. They also steal honey or prey on adult bees and brood [12,13]. Usually the wasps dismember their prey at the cervix and/or petiole level [14], and fly off with selected parts of the dead bee [15]. Aebi and Aebi [16] reported that Vespula spp. prefer to sequestrate the abdomen, while according to Duncan [15] and Winston [17] they prefer the thorax, and according to Free [12], they prefer the thorax and abdomen over the head, but specific studies on V. germanica are lacking.\nDespite this opportunistic feeding behavior, German yellowjacket foragers preserve the memory of their past experience, in fact they return to eat at previously successful foraging sites [9,6,18,19] and show an associative learning between local landmarks (visual, spatial and odor cues) and a certain food source [9,5,20,21,22,23]. The foraging behavior of V. germanica may change in relation to the habitat: wasps returned to the original feeding site more frequently in closed habitats than in open ones, probably because closed habitats offer more landmarks to guide the foragers to the food source [2].\nOther abiotic factors that affect the daily foraging activity of V. germanica include rain, low and high temperatures and low light (. fog) which reduce foraging [24]. Social mechanisms may also contribute to successful finding of alimentary resources. In fact, V. germanica foragers are attracted by the presence of conspecifics at food sources by local enhancement processes [25,26] and they can influence other naive foragers to search for an odor sampled inside the nest [27]. Lozada et al. [10] show that there is evidence of social communication for forager recruitment even at a distance from the resource: when foragers return to the nest after the foraging trip, the subsequent number of wasp foragers was approximately four times higher compared to when communication with the nest was not possible.\nHowever, individual foraging and independent hunting typology have been described for this species that explain how several individuals from different colonies can find themselves at the same foraging site and defend their own prey from other conspecifics [12,13]. Intraspecific competition for food as an aggressive interaction between two or more German yellowjackets has also been reported by Parrish and Fowler [28] also when food supplies were not scarce. In areas with a high wasp density but without enough prey, cannibalism has also been observed [3].\nIn areas where it has been introduced, V. germanica, may also have an ecological impact on the natural ecosystem and is considered a pest for certain human activities [29,30,31,32]. In particular, the economic damage caused by this wasp on beekeeping is due to the costs incurred for destroyed or damaged hives (approx. 9% of the total number of hives) and to productivity losses [29], due also to the strong competition for the honeydew resource [33]. Controlling the V. germanica population, which is normally based on the use of poison-baits [29,34], also has a financial cost.\nAlthough these studies show that yellowjacket represents a problem in many countries, the biology of this species in native areas has not been studied sufficiently. In a previous work [13] we studied the agonistic interactions between V. germanica and A. mellifera [13], our aim in the present work was to assess the economic damage of this species for the beekeeping industry through the evaluation of the impact on the bee colonies of the wasp\'s feeding activity. Through behavioral observations in the field, we investigated the predation and necrophagy behavior, as well as the dismemberment pattern and preferences in the collection of body parts. Finally, the influence of intraspecific competition on the feeding display of this wasp was also assessed.\nMaterials and methods\nExperimental apiary\nThe study was performed in an experimental apiary in northwest Sardinia in fall 2017, at the experimental farm of the University of Sassari, Department of Agriculture (latitude 40\xb046\u201923", longitude 8\xb029\u201934"). The apiary, which is located in an area where the predation activity of V. germanica on honeybees has been reported since September 2014 [13], comprised 10 A. mellifera ligustica colonies maintained in Dadan-Blatt hives containing 10 combs each. During the experimental period, the hives were checked every week to confirm the presence of the queen, as well as the pollen and nectar provision, and to evaluate the sanitary status (symptoms of diseases and varroosis) [35].\nThe presence of V. germanica in our experimental apiary was also monitored from August 2017 using two wasp-traps (a bottle with beer) placed near the hives. After the arrival of the wasps (29/09/2017), the weekly number of V. germanica individuals along a transect ( m x  m) traced in line with the apiary was recorded.\nBehavioral observations\nThe feeding behavior of wasps on bees at the ground level was observed using the "all-occurrences sampling" method [36], by which the frequencies of a series of behavioral events were recorded as set out in the ethogram described below. We focused on the attacks targeted on isolated bees and bees removing other bees at the ground level (failed attacks and predation), and on dead bees (necrophagy behavior). It was not possible to record blind data because our study involved animals in the field. A total of 99 observation hours were conducted during the period in which the predatory and foraging activity of V. germanica is more intense (from late September 2017 to early November 2017) [12]. Two operators simultaneously observed the ground surface under five hives in two sessions per day, each lasting 45 min. These observations were conducted by sight, and the frequency (number of events per unit of time) for each of the observed predation and necrophagy behaviors was annotated. In addition, for each predation and necrophagy events, the degree of dismemberment and the specific body part sequestered by the wasps were reported.\nIntraspecific competition between wasps\nFor each predation or necrophagy event in which intraspecific competition between wasps was observed, the arrival of subsequent wasps after the first was registered as well as the type of resource for which they competed (adult bees, drones, or pupae). When possible, the winner (the wasp that monopolized the resource) was identified in terms of arrival order (first, second etc.).\nEthogram at the ground level\nAttack\u2013The wasp grasps the bee and starts biting it (usually on the abdomen or between the head and thorax) [13].\nPredation\u2013The wasp kills the honeybee. The wasp usually goes on to dismember and consume the honeybee, or to carry off parts to its offspring (see below) [37].\nNecrophagy\u2013The wasp consumes the body parts of dead bees that it finds at the ground level [11].\nDismemberment\u2013After predation or during necrophagy, the wasp divides the honeybee into different parts (head, thorax, abdomen; head + thorax and abdomen; head and thorax + abdomen) [12]. If the resource is a dead bee not intact (. without head or without abdomen), the wasp may divide it further (. head and thorax; thorax and abdomen).\nSequestration\u2013After predation or necrophagy and having divided the honeybee into different parts, the wasp flies off with one of the parts, usually the thorax [15,17]. In some cases, the wasp may also carry the whole bee.\nRetreat\u2013The wasp escapes when the attack has not been successful and the honeybee defends itself effectively [13].\nKilling wasp\u2013Wasps can be killed by a single bee sting or by balling [13].\nIntraspecific competition\u2013Aggressive interactions between two or more individuals of V. germanica during feeding [28].\nStatistical analysis\nA chi squared test was used to measure the proportional difference in intraspecific competition, between necrophagy and predation events. The same test was used to measure the proportional difference in dismemberment and in sequestration behavior between competitive and non-competitive events during predation and also during necrophagy. To reduce the chances of a type I error, continuity correction was used for the chi-squared test when the sample size was less than 200 [38]. The Wilcoxon rank sum test (unpaired comparisons) was used to compare the number of wasps that compete in the predation and necrophagy events. To reduce the chances of a type I error in this analysis, we used Bonferroni correction in the case of multiple testing with significance set at \u03b1 = /2 = .\nThe Kruskal Wallis test was used to compare the number of wasps that competed (in the predation + necrophagy events) for different resources: pupae, drones and adult bees. Subsequently Dunn\u2019s post-hoc test with Bonferroni correction was used to find the significant differences. We also verified the correlation between the density of wasps under 10 hives and the number of competitive events detected in the following three hours using non-parametric Spearman correlation. All tests were carried out using R v  implemented with library: exactRanktests, coin and asbio.\nRaw experimental data are available in supporting materials (S1 Datafile).\nResults\nAttack behavior\nWe observed 816 attacks at ground level in 99 hours, representing ~  attacks per hour. Specifically, 760 attacks (93%) were targeted at isolated bees and 56 (7%) at bees removing other bees. The most frequent outcome was the wasp escaping without the prey (450 events, corresponding to 55%), while predation occurred on another 364 occasions (45%). Only in two cases was the wasp killed (%). No significant differences in the success rate of the attacks comparing the two targets: isolated bees and bees removing other bees were observed (45% vs 34%; chi-squared = , df = 1, P = ). The attack data are summarized in Fig 1.\nPredation behavior\nOf the 364 bee predation events observed, 304 cases (83%) also involved victim dismemberment (Fig 2). The wasp eating its prey on-site was observed 42 times (11%), but more often, after predation and dismemberment, sequestration occurred (322 events, corresponding to 88%) with a preference for the thorax followed by the abdomen and the head + thorax (Fig 3). In 29 cases (9%) the prey was sequestered without dismemberment.\nNecrophagy behavior\nWe observed 775 bee necrophagy events at ground level in 99 hours, corresponding to ~  cases per hour. Necrophagy on integral carrions was observed 707 times (91%), while, in the remaining cases, we observed the wasp eating non-integral carrions (Head+Thorax or Thorax+Abdomen). The pattern of dismemberment observed on integral carrions was similar to that observed during predation (Fig 2), however the frequency was significantly lower (34% vs 83%) (chi-squared = , df = 1, P < ). Conversely, when the target of necrophagy was non-integral carrions, dismemberment was always reported. After necrophagy, sequestration was observed in 575 cases, corresponding to 74%. This frequency was statistically lower than in the case of predation (88%) (chi-squared = , df = 1, P < ). In the other 200 occasions (26%), the carrion was consumed on-site. The preference of body parts sequestered is summarized in Fig 3. In nine cases (%) the carrions were sequestered without dismemberment.\nIntraspecific competition\nWe observed intraspecific competition in both predation and necrophagy events however, in the first case, the rate at which it occurred was significantly higher (50% vs 23%) (chi-squared = , df = 1, P < ). Only in three cases (%) did the interference of another wasp lead to the failure of the attack and the bee escaping.\nDiscussion\nIn a previous study regarding the agonistic interactions between A. mellifera and V. germanica, we observed that the wasp attacked the hive entrance infrequently due to the low success rate of this strategy, while preferring a specialized attack aimed at weak or isolated adult honeybees at ground level [13]. The results of the present work showed that the number of attacks on live bees at the ground level was balanced by the number of necrophagy acts. Considering that only half of the attacks on live bees were successful with predation, we can affirm that the diet of V. germanica is based mostly on bee carrions. This suggests that in our apiary context the main role of the German yellowjacket was as a scavenger and highlights the highly opportunistic behavior of the wasp which, avoiding any physical fight with the live bees defending themselves from the attack, minimizes the risk of dying or losing prey and obtains a good reward from carrions. The evolution of this low-cost foraging strategy can be explained by the optimal foraging theory, which in particular postulates a trade-off between the foraging behaviour and lifetime fitness [39]. However, considering the large plasticity of the alimentary behaviour of this species [4,5,6], there may be a serious impact on honey bee colonies when favourable environmental conditions occur (wasp nest density, food source availability, weak colonies). However, contrary to the general opinion of beekeepers, our research did not find evidence that the presence of the V. germanica represents a threat for the hives in native areas.\nUnlike findings described for Vespa tropica [40], Vespa velutina and Vespa crabro [41], we never observed V. germanica capturing foragers in flight returning to the hive, despite being easy prey because they are weighed down by nectar or pollen load, and "tired" after the flight activity. V. germanica probably does not adopt this attack strategy because it is smaller than the other species of wasps cited above, preferring to attack its prey on the ground. Another attack strategy that we observed at the ground level was aimed at bees removing other bees. In this case the attacked bee is less ready to defend itself as it is engaged in another activity. In addition, it is weighed down by the carried bee who, if still alive, fights to avoid its removal from the nest. However, when this attack strategy is successful, the reward that the wasp obtains is represented by the removed bee and not by the bee that is doing the removing.\nDuring the period of observation (from late September 2017 to end of October 2017) and within individual observation sessions, we noted a progressive increase in the number of foraging wasps at the same site. This can be explained by considering that German yellowjacket foragers are attracted by the presence of conspecifics at food sources [25,26] and by the fact that they preserve the memory of their past experience, particularly regarding the reward obtained at a food site [9,6,18,19]. Although this type of social facilitation probably took place during our experiments, competitive interactions between wasps were also observed. It is highly probable that several individuals from different colonies may find themselves at the same foraging site and defend their own prey from other conspecifics [12]. On the other hand, competitive interactions between individuals of V. germanica during feeding, even when the food resource was not scarce, have been described by Parrish and Fowler [28].\nAs in other animal species, a greater density of individuals at the same site favors the intraspecific competition for resources [42,3,43]. In fact, our data showed a positive correlation between the number of wasps present at the ground level and the number of agonistic interactions for food. However, only in three cases (%) of the total intraspecific competition events observed, did the interference of another wasp lead to the failure of the previous attack and the bee escaping.\nOur study also revealed that intraspecific competition increases when the resource is fresh (predation vs necrophagy). This outcome suggests that necrophagy, compared to predation, may represent the best trade-off between reward and energy costs (in terms of risk, energy investment in foraging on carrion and also in defending food from conspecifics).\nWe found the highest number of competing wasps when the food consisted of pupae and drones, compared to adult worker bees. In fact, pupae and drones are a larger and "unarmed" source of food compared to workers, and consequently represent a low risk for the wasp. Furthermore, Free [12] reported that the alimentary preference of V. germanica and V. vulgaris for pupae compared to adult bees, is probably due to the difference in cuticle hardness.\nIn addition, intraspecific competition led to a significant increase in the rate of the dismemberment and sequestration in both predation and necrophagy events. However, it did not affect the dismemberment pattern and body parts sequestered by the wasp, which was preferentially the thorax, probably due to its higher protein content compared to the head and abdomen [12].\nOur study also revealed that many German yellowjacket individuals are able to sequester a whole bee. It has been already reported that V. germanica have a higher load-lifting capacity, compared to V. squamosa and V. maculifrons [11]. The highest theoretical load can be calculated considering different factors, including for example flight muscle mass. However, the wide intraspecific variation in load-carrying capacity, mainly depending on the size of the wasp, can influence the foraging ability of each individual [11]. Individual size and arriving early at the resource are factors that can also play an important role in intraspecific competition [44]. In fact, we found that when competition involved two individuals, the winner was frequently the first wasp that reached the resource in both predation and necrophagy events. This suggests that the energy invested in foraging or predating and in defence of their own prey is usually rewarded.\nFinally, in the future it would be interesting to quantify how the individual size influences intraspecific competition in this species, particularly in relation to the competition involving two individuals which was the most frequent event observed in our study.\n35.\nPappas N, Thrasyvoulou A. Searching for an accurate method to evaluate the degree of Varroa infestation in honeybee colonies. European research on varroatosis control, Commission of the European Communities, Rotterdam; 1988. pp. 85\u201392.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:50Z', 'description': u'by Vivian Mau, Gilboa Arye, Amit Gross\n\nDetailed assessment of hydrochar wetting properties, which could provide an essential understanding of underlying mechanisms during its application to soils, is lacking. We characterized hydrochar produced from hydrothermal carbonization (HTC) performed on poultry litter at various temperatures and for different times in terms of hydrophobicity and surface free energy properties. Hydrochar was more hydrophobic than untreated poultry litter, and its hydrophobicity increased with increasing HTC temperature (contact angle > 130\xb0). These changes were correlated with degradation of hemicellulose and cellulose. Hydrochar produced at 250\xb0C contained mostly lignin and displayed high hydrophobicity over both prolonged wetting periods and repeated wetting cycles. Surface free energy was calculated using the Owens\u2013Wendt\u2013Rabel\u2013Kaelble and Wu models, with the latter resulting in lower standard errors. The surface free energy decreased as HTC treatment severity increased from 26 mJ/m2 in the poultry litter to 8 mJ/m2 after treatment at 250\xb0C for 60 min. The dispersive component fraction of the surface free energy increased with increasing treatment severity. This study demonstrated that changes in the physical composition of hydrochar due to increased treatment severity increase its hydrophobicity and decrease its surface free energy. Moreover, due to non-persistent hydrophobicity, hydrochar produced at temperatures lower than 250\xb0C will likely not show adverse effects on soils.', 'title': u'Wetting properties of poultry litter and derived hydrochar', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206299', 'keywords': '', 'ID_RSS': u'606', 'contents': u"Wetting properties of poultry litter and derived hydrochar\n\nWetting properties of poultry litter and derived hydrochar\nFigures\nAbstract\nDetailed assessment of hydrochar wetting properties, which could provide an essential understanding of underlying mechanisms during its application to soils, is lacking. We characterized hydrochar produced from hydrothermal carbonization (HTC) performed on poultry litter at various temperatures and for different times in terms of hydrophobicity and surface free energy properties. Hydrochar was more hydrophobic than untreated poultry litter, and its hydrophobicity increased with increasing HTC temperature (contact angle > 130\xb0). These changes were correlated with degradation of hemicellulose and cellulose. Hydrochar produced at 250\xb0C contained mostly lignin and displayed high hydrophobicity over both prolonged wetting periods and repeated wetting cycles. Surface free energy was calculated using the Owens\u2013Wendt\u2013Rabel\u2013Kaelble and Wu models, with the latter resulting in lower standard errors. The surface free energy decreased as HTC treatment severity increased from 26 mJ/m2 in the poultry litter to 8 mJ/m2 after treatment at 250\xb0C for 60 min. The dispersive component fraction of the surface free energy increased with increasing treatment severity. This study demonstrated that changes in the physical composition of hydrochar due to increased treatment severity increase its hydrophobicity and decrease its surface free energy. Moreover, due to non-persistent hydrophobicity, hydrochar produced at temperatures lower than 250\xb0C will likely not show adverse effects on soils.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nMaintenance of soil fertility has been an issue in agriculture since its inception [1]. Continuous land cultivation leading to nutrient depletion, and soil erosion resulting in loss of soil organic matter are extant problems to this day [1,2]. To solve them, soil amendments such as animal manure and compost are commonly used. However, these can lead to pollution of surface and groundwater, and spread of pathogens, heavy metals, and pharmaceuticals [3]. Recently, these materials have begun to be dried and treated by pyrolysis to improve their properties and reduce the presence of pathogens [4]. Biochar, the product of pyrolysis, has been widely investigated in the last 20 years as a potential soil amendment, and has been found to improve soil fertility in some cases [5,6]. A meta-analysis on the effect of biochar application to soils on crop productivity determined that positive effects are most noticeable in soils with acidic to neutral pH and coarse to medium texture, at application rates of 100 t/ha [7]. Crop yield increase is mainly due to improved water-holding capacity and nutrient availability. Moreover, of the studied feedstocks, poultry litter demonstrated the greatest improvement in crop productivity [7].\nToday, another possible treatment is being considered to produce soil amendments. Hydrothermal carbonization (HTC) is a fairly new technology that converts wet organic matter into a char-like compound termed hydrochar. Common feedstock for this technology are animal manures, sewage sludge and lignocellulosic agricultural waste [8\u201311]. Typically, HTC takes place in a temperature range of 180\u2013250\xb0C, under autogenous pressure, and reaction times varying from minutes to several hours [12]. Anoxic or low oxygen concentrations are required to retain the carbon in its solid form. Treating wet organic matter by HTC is intrinsically more energy efficient than other thermal processes, such as pyrolysis, because a specific phase change is avoided by heating at pressures greater than saturated pressure [13,14]. Therefore, it has been suggested for the treatment of animal manure, which has a naturally high moisture content. Traditionally, hydrochar is considered an energy source [14,15]; however, hydrochar has also been proposed as a potential soil amendment due to some similarities with the properties of biochar [8], but only a handful of studies have explored this possibility [10,16,17]. Moreover, a detailed comparison reveals many physico-chemical differences between the two products [15]. For example, hydrochar possesses an acidic pH, high N concentration, and aliphatic structure, whereas biochar has a basic pH, low N concentration, contains mostly aromatic structures, and has high thermal stability [9,18,19]. Consequently, the effect of hydrochar on soil properties needs to be thoroughly investigated.\nA characterization of hydrochar wetting properties is essential to understanding the underlying mechanisms during its application to soil. Hydrochar has been found to be more hydrophobic than the raw material from which it is produced, based on analysis of functional groups on its surface, and the ease of separation of hydrochar from the liquid phase [11,12,20]. Some studies have indirectly assessed hydrochar hydrophobicity by measuring equilibrium moisture contents [21\u201324]. However, to the best of our knowledge, only two studies have directly investigated hydrochar hydrophobicity [16,20]. Results from those studies suggested that temperature and time of digestion, or in other words, the severity of the HTC, affect the hydrophobic properties of the hydrochar, although the effect may be substrate-dependent. For example, an increase in temperature from 200 to 250\xb0C resulted in increased hydrophobicity for hydrochar produced from corn digestate but not for hydrochar produced from woodchips [16]. Knowledge of hydrochar wetting properties is still limited and warrants special consideration.\nThis study provides a detailed assessment of the wetting properties of hydrochar produced from poultry litter. Poultry litter, a mix of poultry manure, bedding materials, feathers, and spilled feed, was chosen because its direct application to fields can result in spread of pathogens, and contamination of water bodies [25], and stringent regulations such as the European Union nitrates directive result in the need to treat it [26]. Moreover, produced quantities are on the rise as poultry production is growing at a global annual rate of % [27], generating 625\u2013938 million tons of litter [28,29]. The natural moisture content of poultry litter indicates that treatment by HTC would be more energetically efficient than pyrolysis [14]. Finally, positive experiences with application of poultry litter-derived biochar to soils [7,25] indicates that this feedstock has potential as a soil amendment. By characterizing hydrochar wetting properties through hydrophobicity and surface free energy components, it is possible to elucidate its behavior as a potential soil amendment. Specifically, this study had three main goals: (i) to characterize the effect of HTC treatment temperature and time on poultry litter-derived hydrochar hydrophobicity; (ii) to investigate the persistence of its hydrophobicity during wetting cycles; and (iii) to determine the surface free energy components of the hydrochar that govern the hydrophobic effects.\nMaterials and methods\nHydrochar production\nHydrochar was produced from poultry litter originating from a chicken farm in the Negev region of Israel following the procedure outlined by Mau et al. [30]. Briefly, the poultry litter consisted of chicken feces, wood chips, spilled feed, and feathers. Clean wood chips were placed in the house when a new flock of chicks was introduced. When the chickens achieved maturity at 22 weeks, the farm staff removed the poultry litter from the house. With permission from the farm owner, the researchers obtained the poultry litter for experiments in the laboratory. It was then dried at 105\xb0C for 24 h, and aggregates were crushed using a mortar and pestle and then sieved through a no. 8 mesh. The dried and homogenized feedstock was stored in a desiccator prior to HTC experiments. The dried poultry litter was mixed with doubled-distilled water at a solid-to-water ratio of 1:3. The poultry litter sludge was placed in HTC reactors, one of which had a temperature probe to provide a representative measure of the temperature inside the reactors. Reactors were heated by immersion in Paratherm HR heat-transfer fluid (Conshohocken, PA) that was preheated to temperatures of 180\xb0C, 220\xb0C and 250\xb0C. Once the reactors reached the set temperatures, carbonization was run for 5, 30 and 60 min. When the desired reaction time had elapsed, the reaction was quenched by placing the reactors in an ice bath. All combinations of temperature and reaction time were conducted in triplicate using the same poultry litter to ensure repeatability. All subsequent analyses were performed separately for each sample or replicate. The generated hydrochar was separated from the liquid phase and oven-dried at 105\xb0C for 24 h. The dried hydrochar was ground using a mortar and pestle and then sieved. The <150 \u03bcm fraction was used in the study.\nFiber analysis was conducted to determine the poultry litter and hydrochar contents of hemicellulose, cellulose and lignin by the van Soest method of neutral detergent fiber, acid detergent fiber and acid detergent liquid (aNDF\u2013ADF\u2013ADL) [31]. This was performed with a fiber analyzer (model A200, Ankom Technology, Macedon, NY) following the manufacturer's procedures [32\u201334] at the Forage and Feed laboratory (Gedera, Israel). Due to the need for a large amount of sample for these analyses, they were performed in duplicates from a composite sample formed by mixing the triplicate samples of each treatment.\nContact-angle measurements\nContact angle (CA), a measure of hydrophobicity, was estimated by the sessile drop method and the Wilhelmy plate method. The first method measured the stability of hydrochar wettability over time [35], and the initial CA was used for the calculation of surface free energy components. The Wilhelmy plate method [36] was used to estimate the advancing and receding dynamic CA under multiple wetting cycles, thus assessing the persistence of hydrophobicity. Applying both methods provides a more complete evaluation of the hydrophobic properties of the material and its behavior over time.\nSessile drop method.\nHydrochar hydrophobicity was assessed using the sessile drop method according to Bachmann et al. [37]. Specifically, the hydrochar particles were sprinkled on double-sided adhesive tape placed on a glass slide. The excess particles on the slide were removed by gentle tapping until a one-grain-thick hydrochar layer was obtained. The CA formed between the hydrochar and a water droplet was monitored as a function of time. A 10-\u03bcL droplet of double-distilled water was placed on the hydrochar-coated slide and the CA was measured over a period of 3 min at 30 frames per second using an optical goniometer (OCA20, Dataphysics, Filderstadt, Germany). The horizontal view of the water drop on the hydrochar slide was used to calculate the CA with the software SCA 20 (Dataphysics). The CA was measured for hydrochar produced at all temperatures and reaction times, as well as for the untreated poultry litter. In a similar manner, the initial advancing CAs of four additional wetting liquids (ethylene glycol, formamide, glycerol and diiodomethane) were measured. The initial advancing CAs for all wetting liquids were used to calculate the surface free energy components as detailed in the section on surface free energy calculations.\nWilhelmy plate method.\nThe dynamic CA was evaluated by the Wilhelmy plate method as described by Bachmann et al. [36] with slight modifications [38]. Specifically, glass slides (76 mm long, 26 mm wide and 1 mm thick) were covered with a double-sided adhesive tape. Each slide was sprinkled with hydrochar particles until the tape on both sides and edges was completely concealed [36]. Excess particles were removed until a one-grain-thick hydrochar layer was obtained. Slides were secured (one at a time) to an electronic micro balance (DCAT 11, Dataphysics) with surfaces perpendicular to a glass vessel containing double-distilled water. Slides were immersed in the glass vessel to a depth of 5 mm at a rate of  mm/s and subsequently emersed at the same rate. Four immersion/emersion cycles were performed with 1-s pause between cycles. The immersion/emersion process and the corresponding CA calculations were performed with SCAT-12 software (Dataphysics).\nThe advancing and receding CAs were calculated from the total force (Ft, kg) measurements during immersion and emersion, respectively, according to Eq 1.\n(1)\nwhere \u03b8 (\xb0) is the CA, V (m3) is the volume of the immersed section of the slide, \u03c1 (kg/m3) is the density of the wetting liquid, g (m/s2) is the acceleration due to gravity, lw (m) is the wetted perimeter and \u03b3lv (N/m) is the surface tension of the wetting liquid at the liquid/vapor interface. For each cycle, the CA hysteresis (., the difference between the advancing and receding CAs) was calculated, serving as an additional measure for hydrophobicity persistence.\nThree measurements were performed for each hydrochar replicate produced at 180\xb0C, 220\xb0C and 250\xb0C at a reaction time of 60 min, and the poultry litter. Thus, in total, 9 measurements were performed for each treatment temperature and the untreated material.\nSurface free energy calculations\nAdditional quantitative insights into the surface characteristics of the poultry litter and derived hydrochars can be gained from the surface free energy (mJ/m2) at the solid/air interface, which can also be viewed as the interfacial tension (mN/m). Following the concept that interfacial tensions (solid/air or liquid/air) are comprised of additive polar and dispersive (., apolar) components, one can calculate the interfacial tension at the solid/air interface from knowledge of interfacial tension of the wetting liquids and their corresponding CA. As mentioned, the sessile drop method was used to measure the CA formed by ethylene glycol, formamide, glycerol and diiodomethane on the surface of the poultry litter and derived hydrochar. The surface tension of the wetting liquids and their polar and dispersive components are shown in Table 1.\nThe consistency between two models that quantify the solid surface free energy and its components were examined: (i) the Owens\u2013Wendt\u2013Rabel\u2013Kaelble (OWRK) method [39,40] (Eq 2) and (ii) the Wu method [41] (Eq 3).\n(2)(3)\nwhere \u03b3 (mJ/m2) is the interfacial tension; \u03b8 (\xb0) is the measured CA, the subscripts l and s stand for the liquid and solid phases, respectively, and the superscripts d and p stand for the dispersive and polar components, respectively. The surface free energy calculations were carried out using the SCA 21 software (Dataphysics).\nStatistical analysis\nAnalysis of variance was conducted to determine statistical differences between treatments (p < ). Treatment temperature and time were set as the fixed factors, and the above-described measured or calculated parameters were the dependent variables. When a significant difference was detected, Tukey\u2019s post hoc test was performed. For surface free energy experiments, an exponential decay regression analysis was performed. The severity factor was set as the independent variable, and the surface free energy was set as the dependent variable. Analysis of variance analyses were performed with Statistica version 10 (StatSoft, Tulsa, OK), and regression analyses were performed with SigmaPlot  (Systat Software Inc., Chicago, IL).\nResults and discussion\nThe poultry litter and derived hydrochar were characterized in terms of fiber composition, specifically hemicellulose, cellulose and lignin fractions. The hemicellulose fraction decreased significantly (p < ) from 28% in the poultry litter to less than 7% in hydrochar produced at all temperatures after 60 min (Fig 1). The HTC process degraded hemicellulose, a hydrophilic fiber, resulting in a hydrochar composed of more hydrophobic fibers\u2014cellulose and lignin [15]. At the treatment temperature of 250\xb0C, significant cellulose degradation was observed (p < ). The resulting hydrochar was mainly composed of lignin fibers, differentiating it from those produced at 180 and 220\xb0C. In total, the fibers accounted for 38\u201367% of the hydrochar composition. The remaining 33\u201362% consisted of ash, sugars, protein, fat and starch. For example, at 250\xb0C, the cellulose fraction underwent degradation, probably forming sugars\u2014which were not measured, thus reducing the fraction of the hydrochar composition that was accounted for. A general chemical characterization of the poultry litter and hydrochars focusing on elemental composition and FTIR spectra can be found in Mau et al. [30].\nTime-dependent contact angle\nThe time-dependent CA of a water drop placed on the surface of poultry litter before and after the HTC treatments (Fig 2) served as a quantitative measure for the degree of hydrophobicity and its persistence. For each surface, the initial advancing CA was calculated from the first frame (corresponding to about 33 ms). The average value obtained from all hydrochar samples was 145\xb0 \xb1 3\xb0 with no significant difference between HTC production temperature and time (p > ). The initial CA obtained for the poultry litter was 138\xb0 and found to be significantly different (p < ) from all hydrochar samples.\nFig 2. Contact angle of water drop formed on the surface of poultry litter and derived hydrochar.\nData for hydrochar generated at 180\xb0C, 220\xb0C, and 250\xb0C at 5, 30 and 60 min is shown. Standard errors were less than 2% for all curves, except for poultry litter and hydrochar produced at 180\xb0C after 5 and 30 min, where it was up to 13%. Photos demonstrate drops created on samples after 60 min of carbonization.\nFor all samples, a rapid decrease in CA was observed in the first few seconds of measurement (Fig 2). This rapid decrease continued for the untreated poultry litter, and at a slower rate for samples generated at 180\xb0C. After 67 s, the CA for poultry litter decreased to 22\xb0 and could no longer be determined with precision. After 3 min of measurement, the CA decreased to 33\xb0, 40\xb0, 63\xb0 for the 180\xb0C hydrochar produced after 5, 30 and 60 min, respectively (Fig 2). With respect to the hydrochars produced at temperatures of 220 and 250\xb0C, after the initial rapid decrease, the CAs remained elevated, relatively constant and statistically similar to each other. In total, after 3 min, the reduction in CA was of 13\xb0 or less, remaining above 130\xb0 (Fig 2). These results are similar to sessile drop method experiments performed on woodchip-derived hydrochar that was carbonized at 200 and 250\xb0C for 6 h [16]. The woodchip hydrochar was also highly hydrophobic (initial CA > 130\xb0), and over 5 s, the CA decreased by about 5 and 15\xb0 for hydrochar produced at 250 and 200\xb0C, respectively.\nThe marked difference between the degree of hydrophobicity of untreated poultry litter and hydrochar can be explained in part by the fiber composition of the materials. The poultry litter consisted of 28% hemicellulose, a hydrophilic fiber, which was degraded to less than 7% during HTC.\nIt should be noted that in the sessile drop method, the sample's roughness can influence CA measurements, leading to a higher CA than would be measured on a smooth surface [37]. This might explain in part why the CAs measured in this study were so much higher than those measured by He et al. [20] on compressed disks of sewage-sludge-derived hydrochar.\nSurface free energy components\nAs already noted, the initial advancing CAs from the sessile drop method for poultry litter and hydrochars were similar. Since water is a highly hydrophilic wetting liquid (72 mJ/m2) and the hydrochars were found to be highly hydrophobic, it was difficult to distinguish between the surface characteristics of the different hydrochars from the initial advancing CA, when water was the wetting liquid. Therefore, further CA measurements were conducted with the sessile drop method using other wetting liquids with lower total surface tension and different polar and dispersive components (Table 1).\nTo combine the effects of varying HTC temperatures and reaction times, we used the severity factor (SF), developed by modeling HTC kinetics according to hydrochar oxygen loss [42]. The model was calibrated with data from HTC of feedstocks ranging from cellulose to sub-bituminous coal treated at temperatures of 120\u2013390\xb0C and reaction times ranging from 1 min to 6 months.\n(4)\nwhere t is the reaction time in seconds, and T is the temperature in K. According to the SF, different combinations of time and temperature that lead to the same SF may result in similar effects on reactions and hydrochar properties. The SFs of the studied poultry litter and derived hydrochars are presented in Table 2.\nIn Fig 3, the CA as a function of SF is presented for the wetting liquids employed (Table 1), excluding diiodomethane. The latter exhibited instantaneous and complete wetting (., CA = 0) when placed on any one of the surfaces. It should be noted that the total surface tension of diiodomethane is moderate ( mJ/m2), but its polar fraction is zero. Namely, wetting interaction took place between the dispersive fraction of the liquid and solid phases, implying a highly hydrophobic nature for the hydrochar.\nContact angles were measured using different test liquids, poultry litter, and hydrochar generated at 180\xb0C, 220\xb0C, and 250\xb0C at 5, 30 and 60 min. The effect of temperature and time is combined in the severity factor [42]. Bars indicate standard errors.\nIn contrast to the similar CAs obtained for water, the CAs obtained for ethylene glycol, formamide and glycerol were sensitive to the HTC treatments. Specifically, for these wetting liquids, the CA as a function of SF (Fig 3) exhibited a sigmodal-like pattern of increasing CA with increasing SF. In general, the CA values corresponded to the total surface tension, where the CA obtained for glycerol ( mJ/m2) was highest and that obtained for ethylene glycol ( mJ/m2) was lowest. At the highest SF (), however, no significant differences could be observed among the three wetting liquids.\nThe measured CA values (Fig 3) were further used to calculate the surface free energy and its components using the Wu and OWRK models. The resultant total surface free energies as a function of SF are presented in Fig 4, together with regression curves and 95% confidence bands. Both models produced total surface free energy values of similar magnitude, which followed a similar trend. The Wu model resulted in smaller standard errors than the OWRK model, especially for samples with SF > . As the SF increased, the surface free energy decreased following an exponential decay. The Wu model demonstrated a better correlation with the SF (Fig 4). The total surface free energy of the untreated poultry litter (., SF = 0) was about 26\u201330 mJ/m2, whereas the surface free energy for hydrochar with SF \u2265  was about 10 mJ/m2. These values are relatively low, implying that the hydrochar surface is extremely hydrophobic and may indirectly impact crop yields by inducing water repellency when added to mineral soils. In comparison, agricultural cultivated loess soils have a surface free energy of 39\u201368 mJ/m2 [43,44]. These high surface free energy values demonstrate the hydrophilic nature of the mineral soils in comparison to the hydrochar. Therefore, the addition of hydrochar to mineral soils could significantly change its hydrophobicity. Nevertheless, more research is necessary to assess the impact of hydrochar on soil's hydraulic properties in conjunction with crop yields. It should be noted, however, that the hydrophobicity of hydrochar produced at temperatures lower than 250\xb0C was not persistent, as will be shown in the following section.\nCalculation was performed with values from poultry litter and hydrochar generated at 180\xb0C, 220\xb0C, and 250\xb0C at 5, 30 and 60 min. The effects of temperature and time are combined in the severity factor [42]. Bars indicate standard errors. Solid lines indicate the regression line, and the dotted lines the 95% confidence bands. Regression equation and coefficient of determination are shown for each model.\nThe OWRK and Wu models separate the surface free energy into dispersive and polar components. The two components and the fraction of the total surface free energy associated with the dispersive component are shown in Table 2. In general, the models agreed on the proportion of surface free energy associated with the dispersive component. This represented a close to negligible fraction of the surface free energy for the poultry litter. As the SF increased, the dispersive component increased and accounted for almost all of the total surface free energy, except for the hydrochar produced at 250\xb0C after 60 min. In comparison, in agricultural cultivated loess soils, the dispersive component represents one-third of the surface free energy [43].\nAdvancing and receding contact angles\nThe advancing CA measured during the first cycle was similar for all samples (Fig 5A). This is in agreement with the similar initial advancing CAs obtained by the sessile drop method (Fig 2). However, the values obtained were smaller than the initial advancing CA measured with the sessile drop method. This disparity has also been observed in other studies [37,45] where it was found that in general, the Wilhelmy plate method underestimates the advancing CA because the actual wetted perimeter is larger than the perimeter of the slide due to the roughness created by the sample particles. Both methods, however, will yield higher advancing CAs relative to an ideal smooth surface with the same chemical characteristics. In general, the CA measured on rough hydrophobic surfaces (., CA > 90\xb0) is larger than it would be on an ideal smooth surface [37].\nWith subsequent wetting cycles, the advancing CA decreased drastically, by more than 74\xb0, for the poultry litter and hydrochar produced at 180 and 220\xb0C. The advancing CA of hydrochar produced at 250\xb0C decreased only slightly with each wetting cycle; the advancing CA measured in cycle 4 was only 13\xb0 lower than that from the first cycle. The behavior observed for the 250\xb0C hydrochar was similar to the effect of the prolonged static contact time investigated by the sessile drop method. In fact, the time elapsed to measurement of the advancing CA in cycle 4 was similar to the prolonged static contact time (153 vs. 180 s). Therefore, hydrochar produced at 250\xb0C is highly hydrophobic over a long wetting period as well as over repeated wetting periods. On the other hand, hydrochar produced at 220\xb0C is hydrophobic over long periods but not with subsequent wetting cycles.\nThe receding CA was measured when the slide was emersed from the water. The receding CA measured in cycle 1 was significantly smaller (p < ) than the advancing CA of that same cycle for all samples excluding the 250\xb0C hydrochar (Fig 5B). In other words, in cycle 1, hysteresis was high for poultry litter and hydrochar produced at 180 and 220\xb0C, and close to zero for hydrochar produced at 250\xb0C (Fig 5C). With each wetting cycle, hysteresis decreased for all samples, except for the 250\xb0C hydrochar where hysteresis remained relatively constant and low throughout all cycles. The increase in receding CA observed from cycle 1 and 2 for poultry litter and hydrochar produced at 180\xb0C was likely due to the methodology's lower sensitivity at low CA values. With each subsequent cycle, the receding CA converged to values similar to the advancing CA and thus, hysteresis was negligible.\nThe significant decrease in receding CA compared to advancing CA in cycle 1 for poultry litter and hydrochar produced at 180 and 220\xb0C may be the result of water adsorption to the particles\u2019 surface during measurement, whereas the surface was dry for the advancing CA measurement. Thereafter, the advancing CA measured in cycle 2 was similar to the receding CA measured in cycle 1 because it contained a similar amount of adsorbed water. It is well known that ordination and/or configuration of hydrophilic and hydrophobic functional groups at the surface is dependent upon their interaction with water. Specifically, when water is adsorbed, polar functional groups interact with the water molecules. However, as the surface dries, polar groups interact with each other, increasing the fraction of hydrophobic functional groups at the surface [46\u201348]. This mechanism might explain the rapid decrease in advancing CA and receding CA observed for poultry litter and hydrochar produced at 180 and 220\xb0C.\nThe measurements of advancing and receding CA showed that hydrochar hydrophobicity is persistent for hydrochar produced at 250\xb0C, but not for hydrochar produced at lower temperatures. This discernible difference can be explained by the hydrochars' chemical composition. The 250\xb0C hydrochar has a lower amount of cellulose than the other hydrochars (Fig 1). Cellulose has both hydrophobic and hydrophilic components, and can reorient itself at the surface, resulting in more hydrophilic behavior [49]. Since the cellulose was degraded, the more hydrophobic lignin, which has less OH-binding sites for water [50], probably had a stronger influence on the hydrochar's hydrophobicity. A smaller presence of OH-bonds has been reported for this 250\xb0C hydrochar [30]. Principal component analysis of FTIR spectra of these hydrochars also confirmed that the 250\xb0C hydrochar is markedly different from the other hydrochars [30]. The persistent hydrophobicity of 250\xb0C hydrochar implies that it could have adverse effects on soil hydraulic properties; however, hydrochar produced at lower temperatures could be a good soil amendment. More research is needed to determine hydrochar performance in supporting crop yield.\nConclusions\nWetting properties of poultry litter and derived hydrochar were investigated. A hydrophobic material was generated by HTC, with treatment temperature having a greater influence than time. Only hydrochar produced at 250\xb0C demonstrated hydrophobic behavior under repeated wetting cycles, probably due to lower amounts of cellulose which resulted in less water adsorption and hydrophilic molecule reorientation at the surface. Due to this persistent hydrophobicity, the hydrochar produced at 250\xb0C could negatively impact soil hydraulic properties; however, based on its wetting behavior, hydrochar produced at lower temperatures would likely not present a problem when added to soil. The total surface free energy decreased with treatment severity. Poultry litter had a weak dispersive component, which increased with increasing severity of HTC treatment. Further experiments should be conducted to correlate hydrochar wetting characteristics with soil hydraulic properties, and subsequently with crop yield. This study contributes basic knowledge toward utilizing hydrochar as a soil amendment, thereby increasing its applications and value.\nAcknowledgments\nThe authors would like to acknowledge Paratherm for donating the heat-transfer fluid used in this research.", 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:53Z', 'description': u'by Natasha Housseine, Marieke C. Punt, Joyce L. Browne, Tarek Meguid, Kerstin Klipstein-Grobusch, Barbara E. Kwast, Arie Franx, Diederick E. Grobbee, Marcus J. Rijken\nBackground The majority of the five million perinatal deaths worldwide take place in low-resource settings. In contrast to high-resource settings, almost 50% of stillbirths occur intrapartum. The aim of this study was to synthesise available evidence of strategies for foetal surveillance in low-resource settings and associated neonatal and maternal outcomes, including barriers to their implementation. Methods and findings The review was registered with Prospero (CRD42016038679). Five databases were searched up to May 1st, 2016 for studies related to intrapartum foetal monitoring strategies and neonatal outcomes in low-resource  authors extracted data and assessed the risk of bias for each study. The outcomes were narratively synthesised. Strengths, weaknesses, opportunities and threats analysis (SWOT) was conducted for each monitoring technique to analyse their  were 37 studies included: five intervention and 32 observational studies. Use of the partograph improved perinatal outcomes. Intermittent auscultation with Pinard was associated with lowest rates of caesarean sections (10\u201315%) but with comparable perinatal outcomes to hand-held Doppler and Cardiotocography (CTG). CTG was associated with the highest rates of caesarean sections (28\u201334%) without proven benefits for perinatal outcome. Several tests on admission (admission tests) and adjunctive tests including foetal stimulation tests improved the accuracy of foetal heart rate monitoring in predicting adverse perinatal outcomes. Conclusions From the available evidence, the partograph is associated with improved perinatal outcomes and is recommended for use with intermittent auscultation for intrapartum monitoring in low resource settings. CTG is associated with higher caesarean section rates without proven benefits for perinatal outcomes, and should not be recommended in low-resource settings. High-quality evidence considering implementation barriers and enablers is needed to determine the optimal foetal monitoring strategy in low-resource settings.', 'title': u'Strategies for intrapartum foetal surveillance in low- and middle-income countries: A systematic review', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206295', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Strategies for intrapartum foetal surveillance in low- and middle-income countries: A systematic review\n\nFigures\nAbstract\nBackground\nThe majority of the five million perinatal deaths worldwide take place in low-resource settings. In contrast to high-resource settings, almost 50% of stillbirths occur intrapartum. The aim of this study was to synthesise available evidence of strategies for foetal surveillance in low-resource settings and associated neonatal and maternal outcomes, including barriers to their implementation.\nMethods and findings\nThe review was registered with Prospero (CRD42016038679). Five databases were searched up to May 1st, 2016 for studies related to intrapartum foetal monitoring strategies and neonatal outcomes in low-resource settings.\nTwo authors extracted data and assessed the risk of bias for each study. The outcomes were narratively synthesised. Strengths, weaknesses, opportunities and threats analysis (SWOT) was conducted for each monitoring technique to analyse their implementation.\nThere were 37 studies included: five intervention and 32 observational studies. Use of the partograph improved perinatal outcomes. Intermittent auscultation with Pinard was associated with lowest rates of caesarean sections (10\u201315%) but with comparable perinatal outcomes to hand-held Doppler and Cardiotocography (CTG). CTG was associated with the highest rates of caesarean sections (28\u201334%) without proven benefits for perinatal outcome. Several tests on admission (admission tests) and adjunctive tests including foetal stimulation tests improved the accuracy of foetal heart rate monitoring in predicting adverse perinatal outcomes.\nConclusions\nFrom the available evidence, the partograph is associated with improved perinatal outcomes and is recommended for use with intermittent auscultation for intrapartum monitoring in low resource settings. CTG is associated with higher caesarean section rates without proven benefits for perinatal outcomes, and should not be recommended in low-resource settings. High-quality evidence considering implementation barriers and enablers is needed to determine the optimal foetal monitoring strategy in low-resource settings.\nData Availability: All relevant data are within the paper and its Supporting Information files.\nFunding: NH received funding from the UMC Utrecht Global Health Support Program, FM/mvr/D-15-038286. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. No additional external funding received for this study.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nOver two million stillbirths are estimated to occur yearly worldwide, of which >98% are in low-resource settings [1,2]. Almost half of the number of stillbirths in low- and middle-income countries (LMICs) occur during labour, whereas most stillbirths in high-income countries (HICs) take place during the antenatal period [3,4]. The time of labour and delivery is a challenging period for the foetus and can result in foetal asphyxia and associated irreversible organ damage and mortality [5\u20138]. Intrapartum foetal monitoring allows for prompt and effective intervention when needed, and avoids unnecessary interventions like caesarean sections (CS) by offering confirmation of a favourable foetal condition [9]. Methods of foetal surveillance include foetal heart rate (FHR) monitoring by intermittent auscultation (IA), cardiotocography (CTG) with foetal blood sampling and foetal electrocardiogram with ST-wave analysis [10,11]. Nearly all methods are considered to be high-tech, complex in operation, and require significant financial resources [12,13].\nAlthough global consensus exists that some form of foetal monitoring should be used during labour to improve maternal and neonatal outcomes, there is no evidence for an ideal foetal monitoring system [8,11,14]. Studies on foetal monitoring have been primarily conducted in HICs and, based on variable level of evidence, consensus-based guidelines were developed for foetal surveillance, which may not be readily applicable to LMICs due to context-specific factors [11,15\u201317]. Thus, in many low resource settings, low-cost and low-tech methods such as IA by Pinard stethoscope or hand-held Doppler, are the only accessible methods [18]. A review on intrapartum foetal surveillance (implementation) strategies for LMICs is not available. Therefore, the aim of this systematic review was to synthesize the available evidence for intrapartum foetal surveillance in low resource settings and a SWOT analysis was applied to analyse the implementation.\nMethods\nThis review was registered with the PROSPERO registry for systematic reviews (CRD42016038679). It adhered to PRISMA guidelines (S1 File) [19] and was conducted according to the Cochrane methodology [20].\nResearch questions\nThis review aimed to answer two research questions: (1) what is the available evidence for strategies of intrapartum foetal surveillance in low- and middle-income countries and their associated neonatal and maternal outcomes? (2) what are the strengths, weaknesses, opportunities, and threats (SWOT) associated with the implementation of these intrapartum foetal surveillance strategies?\nEligibility criteria\nObservational or intervention studies concerning women receiving intrapartum foetal surveillance with reported neonatal outcomes in low resource settings were eligible for inclusion. These included studies on admission tests, which were defined as tests performed to determine foetal wellbeing upon arrival in labour in a birth facility. Low resource settings were defined as low-income, lower-middle- and upper-middle income countries (LICs, L-MICs, and UMICs respectively), according to the World Bank classification [21]. Conference abstracts, reports, editorials, presentations, and project protocols were excluded.\nInformation sources and search\nThe search was conducted in the following electronic databases: Pubmed/MEDLINE, The Cochrane Library, EMBASE, POPLINE and Global Health Library to include all articles up to May 1st, 2016. For every database, a search string was developed with the support of a librarian specialised in medical sciences, using pre-defined search (Title/Abstract) and MeSH/Emtree terms when applicable. References were manually searched for additional studies. Only for the Global Health Library, limits were used (humans/English). The full search strings are available in Appendix A in S2 File.\nStudy selection\nMendeley reference software was used to remove duplicates. Subsequently, two reviewers (MCP and NH) independently screened articles based on title and abstract, after which full-text screening was performed. In case of disagreement, a third reviewer (MJR) was consulted. Authors were contacted once in case of inaccessible full-texts, and a study excluded if no reply was received.\nData collection process\nData extraction of the included studies was conducted by one reviewer (MCP) and double-checked for accuracy by a second reviewer (NH). A standardised data extraction sheet was created (Appendix B in S2 File) SWOT analysis was applied to the methods, results and discussion sections of the selected articles whenever mentioned and recorded in the same extraction sheet as all other outcomes. Outcome measurements were noted as percentages and calculated when possible in case of different reporting strategy. Sensitivity, specificity, positive and negative predictive values (PPV and NPV respectively) were collected when available. The corresponding author or organisation was emailed once in case of incomplete data. In case of disagreements during the extraction process, other members of the review team were contacted (JB, MJR).\nRisk of bias assessment\nThe level of bias was assessed for each study using the Cochrane Risk of Bias Tool (S3 File) and the Newcastle-Ottawa Quality Assessment Scale for intervention and observational studies, respectively (S4 and S5 File) [20,22,23]. Colour coding of the table was assigned as red, green and yellow for high, low and unclear (Cochrane) or intermediate (Newcastle-Ottawa) risk respectively. Judgement of bias was determined (MCP) and double-checked for accuracy (NH). Any disagreement during this process was resolved by contacting other members of the review team (JB, MJR).\nData synthesis\nDue to heterogeneity in domains, determinants, study designs and reported outcomes, a senior statistician from the Cochrane Collaboration advised not to conduct a meta-analysis. This review, therefore, consists of a narrative analysis of strategies for intrapartum foetal surveillance and their corresponding outcomes. The quantitative results of all studies were summarised according to study design: intervention and descriptive studies. For each method of foetal monitoring, SWOT findings were summarised according to each component.\nRisk of bias of studies\nA summary of quality assessment for intervention studies is provided in Table 1 and for observational studies in Table 2. Study performance of the five intervention studies was overall moderate, however, blinding of the participants or researchers was not done (5/5 high risk) and confounders were often not considered (1/5 high risk; 3/5 unclear risk and 1/5 low risk). Quality of observational studies was low to moderate; classified as low risk in: % for selection process, in 25% for comparability and in 25% outcome/exposure of studies.\nNarrative synthesis of quantitative results\nA summary of the FHR monitoring strategies and their outcomes is provided in Table 3. Detailed results of each intervention and descriptive study are presented in S1\u2013S3 Table.\nAdmission tests\nNeonatal outcomes.\nWe identified only observational studies for admission tests. The study of IA on admission (n = 1) showed that absent FHR by hand-held Doppler was associated with a much higher perinatal mortality (938/1000 deliveries) compared to when FHR was present (13/1000 deliveries) [59].\nOngoing intrapartum foetal surveillance\nNeonatal outcomes.\nThere were three RCTs comparing IA and CTG: Uganda (n = 1971) [27], Zimbabwe (n = 1255) [26], India (n = 100) [28]. In Uganda, hand-held Doppler and Pinard stethoscope were compared [27]. The RCT in Zimbabwe had four arms: 1) intermittent CTG traces(n = 318) 2) hand-held Doppler (n = 312), 3) Pinard (n = 310)and 4) routine monitoring with Pinard (n = 315). In the first three groups, research midwives ensured they assessed FHR every 30 minutes for 10 minutes per study protocol and caregiving midwives were supposed to adhere to the same frequency by following hospital protocol [26]. Continuous CTG monitoring (n = 50) was compared to IA (n = 50) in women with a history of CS in India [28]. In these studies, detection of FHR abnormalities was significantly different in Pinard, Doppler and CTG groups (Table S1and S2). However, no significant changes in perinatal deaths, low Apgar scores at 1 and 5 minutes and admission to NICU were observed [26\u201328].\nThe study in Zimbabwe reported fewer cases of neonatal seizures and hypoxic-ischaemic encephalopathy (HIE) in the hand-held Doppler group compared to the Pinard groups (zero vs 15; and one vs 17 respectively) [26]. Although foetal distress was diagnosed in the three treatment groups, protocol violations, delays or unavailable operative deliveries led to the majority of perinatal deaths [26].\nThe multi-centre partograph-intervention study in Southeast Asia which included 35 484 women showed a significant reduction in intrapartum stillbirths (% to %, p = ), but no significant reduction in Apgar scores, neonatal deaths, NICU, and resuscitation [24,25]. Training midwives to use the partograph reduced low Apgar scores at 1 minute but no improvement in other perinatal outcomes [29]. Observational studies showed that crossing the alert and action lines on the partograph was associated with a higher incidence of neonatal resuscitation and fresh stillbirths [54,55]. Substandard use of partograph was associated with low Apgar score [40].\nMaternal outcomes.\nThe RCT in Zimbabwe showed that CTG and hand-held Doppler significantly increased CS rates due to foetal distress compared to Pinard. (63%, 67% and 41% respectively) [26]. The RCT in India showed a trend towards increasing CS rate in the CTG group due to foetal distress compared to IA (47% vs 18%) [28]. The Uganda RCT showed no difference in overall CS rates between hand-held Doppler and Pinard [27]. No clear difference was observed for operative vaginal delivery [26,28]. Duration of labour [26]. postpartum haemorrhage, maternal fever, ruptured uterus and maternal death [28] were similar. Meconium was associated with increased CS rates in India (clear liquor 17% vs meconium 33%) [39,58]. Nonreactive FSST detected by IA was associated with a significant increase in operative vaginal deliveries and CS rates [45]. Two clustered RCT on the partograph showed that training and the use of partograph led to significant reduction in length of labour and obstructed labour and oxytocin use but no changes in CS rate or maternal mortality [24,25,29]. There was no increased CS rate due to foetal distress. There was a reduction in vaginal examinations but no change in postpartum haemorrhage and maternal ,33 The partograph significantly increased the number of referrals of women in labour to higher level centres [29].\nNarrative synthesis of SWOT analysis\nDetailed SWOT results of the given foetal monitoring methods are provided in Table 4. Admission CTG were recommended for triaging labours and resource allocation when resources are scarce [32,48,57]. The Pinard, hand-held Doppler and partograph were strategies reported as simple and low-cost [25\u201327,36,54,59]. IA allowed for greater mobility of the women than CTG and was easily accessible, but difficult to carry out in busy maternity wards [43]. The hand-held Doppler may be more mother- and user-friendly than the Pinard [27,59] but required consumables [36]. Some of these challenges were eliminated when using the wind-up Doppler. The use of CTG required a high level of skills, resources, and costs [26,31]. Combining FHR monitoring with simpler adjunctive tests such as meconium, FAST, FSST, and FPO may provide non-invasive and reliable ways to confirm foetal wellbeing, avoiding unnecessary interventions [42,45,56,60,61].\nStrengths of the partograph were its low-cost, pictorial overview of labour allowing timely recognition for complications and action [25,29,40,54,55]. A major threat was an underuse of partograph due to a shortage of staff, lack of knowledge, training, and guidelines, unavailability of copies and hesitant attitudes of staff [29,40,54]. Opportunities to increase partograph use lie in providing partograph copies, training, and appropriate management guidelines [25,29,40,54]. A major threat to all intrapartum foetal surveillance studies was limited or unavailability of intervention including timely operative deliveries [26,27,31,36].\nDiscussion\nMain findings\nThis systematic review and SWOT analysis provide an overview of the evidence of intrapartum foetal monitoring strategies in low-resource settings on perinatal and maternal outcomes. The use of CTG increased the rates of CS but had no effect on adverse perinatal outcomes compared to IA [26,28]. IA and the partograph is the preferred method in low-resource settings for FHR monitoring.\nThe observational studies in this review suggest that admission tests (including CTG, IA or FAST) can predict adverse outcomes in LMICs, and mode of delivery in both low and high-risk pregnancies [32,34,48,56,57,60,61]. We suggest that admission tests might have a much better use in low resource settings because of: 1) the incidence of intrapartum stillbirths could modify the predictive test results [11], 2) inadequate risk assessment and stratification during antenatal care, making admission tests a good screening tool to identify high-risk foetuses and 3) a triaging tool for better allocation of resources in settings with heavy workload and scarce (human) resources [32,34,48,57].\nThe overall evidence shows that CTG does not improve outcomes but increases the number of CS compared to IA. It is unclear whether hand-held Doppler improves neonatal outcomes, and it may increase CS rate. Similar findings on CTG and hand-held Doppler are reported in the Cochrane meta-analyses [11,62]. A study in South Africa showed pregnant women preferred hand-held Doppler over Pinard or CTG [63]. However, the number of CS presents real concerns for maternal safety in low resource settings [64\u201368]. Foetal heart monitoring may have false positivity for foetal distress leading to unnecessary intervention. The current review identified simple and cheap strategies to strengthen the test performance of intrapartum FHR monitoring including foetal stimulation tests (FAST and FSST) and meconium. However, their effectiveness is not known and should be tested in future studies. Contrary to a Cochrane review, which did not include the large study in South East Asia [69], the partograph was useful for monitoring and decision-making for the intrapartum care of the mother, foetus and labour progress, and was associated with reduced intrapartum stillbirths in low-resource settings [25,29,40,54,55]. The BOLD initiative and WHO guidelines stress the importance of supportive, person-centred care during labour and childbirth rather than focus on cervical dilatation only [70\u201372].\nChallenges exist in up-scaling effective interventions in low-resource settings [18,73]. Given the resource constraints, the SWOT analysis shows that the ideal method of intrapartum foetal monitoring should be: simple, affordable, robust, safe, reliable and sustainable [18,74]. Yet, most monitoring systems require maintenance and adequate staffing who need to be trained and supervised. For example, although IA and partographs are low-tech and -cost technology, they highly depend on human resources. A strong commitment to investing in high quality research of existing and new strategies of real-life implementation for intrapartum foetal monitoring is required. These may include new ways to monitor foetal well-being, context-appropriate guidelines, and healthcare workforce strengthening [15,75]. A substantial time-lag between recognition of foetal compromise and delivery as a major cause of severe asphyxia and death was identified in this review [26,27,31,36]. Importantly, emergency obstetric and newborn care including operative vaginal deliveries and neonatal resuscitation should be readily available to ensure both prompt diagnosis and successive intervention.\nStrengths and limitations\nA strength of this review is the systematic assessment of neonatal and maternal outcomes and SWOT analysis. Although an extensive and inclusive search in five international databases was conducted, studies performed in low-resource settings and published in national journals might not have been indexed in the searched databases. Limitations are also inherent in the reviewed articles and include the quality of the evidence, the lack of detailed reporting of implementation factors and relevant outcomes such as contraction monitoring, maternal morbidity and mortality, CS rates, professional and maternal opinion. RCTs did not guarantee appropriate and timely interventions which confounded the results. We intended to evaluate evidence for all intrapartum foetal monitoring strategies in low-resource settings using a meta-analysis, however, due to heterogeneity in designs and outcomes, only a narrative review could be performed.\nConclusion\nOf the foetal monitoring strategies that have been studied in LMICs, the partograph and intermittent auscultation is the preferred strategy for intrapartum foetal surveillance in low-resource settings because of reduced intrapartum stillbirths (partograph), lower caesarean section rates (Pinard) and easier implementation. CTG is associated with higher caesarean section rates without proven benefits for perinatal outcomes, and should not be recommended in low-resource settings until new research delivers evidence for better perinatal outcomes. The benefit and harms of admission tests, adjunctive tests and hand-held Doppler on perinatal and maternal outcomes should be determined in future studies in low resource settings. High-quality RCT studies of foetal monitoring should include clear management protocols with timely interventions. Moreover, there is a need to harmonise core outcomes in foetal monitoring studies. Consideration of implementation factors will also be essential to determine the real-world optimal foetal monitoring approach.\nS3 Table. Characteristics and quantitative results of included observational studies.\nAcknowledgments\nWe would like to acknowledge the valuable support of the UMC Utrecht Librarians (Paulien Wiersma and Tessa Pronk) regarding the search string for the databases and the Dutch Cochrane Centre (Rob Scholten) for consultation in data analysis.\n13.\nThe Royal College of Obstetrics and Gynaecology. The use of electronic monitoring: The use and interpretation of cardiotocography in intrapartum fetal surveillance. Clinical Guideline number 8. 2001.', 'subject': u'Sciences'}, {'category': '', 'dateS': '2018-10-29T10:15:55Z', 'description': u'by Hang Xie, Yang Jiao, Qihui Fan, Miaomiao Hai, Jiaen Yang, Zhijian Hu, Yue Yang, Jianwei Shuai, Guo Chen, Ruchuan Liu, Liyu Liu\n\nA systematic understanding of the evolution and growth dynamics of invasive solid tumors in response to different chemotherapy strategies is crucial for the development of individually optimized oncotherapy. Here, we develop a hybrid three-dimensional (3D) computational model that integrates pharmacokinetic model, continuum diffusion-reaction model and discrete cell automaton model to investigate 3D invasive solid tumor growth in heterogeneous microenvironment under chemotherapy. Specifically, we consider the effects of heterogeneous environment on drug diffusion, tumor growth, invasion and the drug-tumor interaction on individual cell level. We employ the hybrid model to investigate the evolution and growth dynamics of avascular invasive solid tumors under different chemotherapy strategies. Our simulations indicate that constant dosing is generally more effective in suppressing primary tumor growth than periodic dosing, due to the resulting continuous high drug concentration. In highly heterogeneous microenvironment, the malignancy of the tumor is significantly enhanced, leading to inefficiency of chemotherapies. The effects of geometrically-confined microenvironment and non-uniform drug dosing are also investigated. Our computational model, when supplemented with sufficient clinical data, could eventually lead to the development of efficient in silico tools for prognosis and treatment strategy optimization.', 'title': u'Modeling three-dimensional invasive solid tumor growth in heterogeneous microenvironment under chemotherapy', 'country': u'Etats-Unis', 'source': u'PLOS', 'subject2': u'National', 'source-link': u'https://journals.plos.org/plosone/feed/atom', 'link': u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206292', 'keywords': '', 'ID_RSS': u'606', 'contents': u'Modeling three-dimensional invasive solid tumor growth in heterogeneous microenvironment under chemotherapy\n\nFigures\nAbstract\nA systematic understanding of the evolution and growth dynamics of invasive solid tumors in response to different chemotherapy strategies is crucial for the development of individually optimized oncotherapy. Here, we develop a hybrid three-dimensional (3D) computational model that integrates pharmacokinetic model, continuum diffusion-reaction model and discrete cell automaton model to investigate 3D invasive solid tumor growth in heterogeneous microenvironment under chemotherapy. Specifically, we consider the effects of heterogeneous environment on drug diffusion, tumor growth, invasion and the drug-tumor interaction on individual cell level. We employ the hybrid model to investigate the evolution and growth dynamics of avascular invasive solid tumors under different chemotherapy strategies. Our simulations indicate that constant dosing is generally more effective in suppressing primary tumor growth than periodic dosing, due to the resulting continuous high drug concentration. In highly heterogeneous microenvironment, the malignancy of the tumor is significantly enhanced, leading to inefficiency of chemotherapies. The effects of geometrically-confined microenvironment and non-uniform drug dosing are also investigated. Our computational model, when supplemented with sufficient clinical data, could eventually lead to the development of efficient in silico tools for prognosis and treatment strategy optimization.\nFunding: This work was supported by Grant No. 11474345 and 11674043, and 11604030 issued by the National Natural Science Foundation of China, Grant No. 2013CB837200 issued by the State Key Development Program for Basic Research of China, and the Start-Up fund issued by Arizona State University. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\n1. Introduction\nCancer is a group of highly fatal diseases that usually involve abnormal cell growth and emergent migration behaviors due to complex tumor-host interactions, leading to invasion and metastasis. For a typical solid tumor, the proliferative cells take up oxygen and nutrition from surrounding microenvironment and actively produce daughter cells to expand the tumor mass. The cells in the inner region of the tumor become inactive (quiescent) due to starving and eventually turn necrotic. In malignant tumors, mutant daughter cells with invasive phenotype ., low cell-cell adhesion, high mobility and strong drug resistance, are produced and can detach from the primary tumor and migrate into the surrounding stromal [1\u20134]. Such invasive cells can enter the circulation systems (., blood vessels) and reside in distant organs, leading to the emergence of secondary tumor and metastasis, and thus makes it very difficult for cancer treatment [5].\nTo better understand the evolution and invasive of malignant tumors and the influence of the host microenvironment, a variety of computational models on tumor growth have been devised, which can be generally categorized continuum [6\u201315], discrete [16\u201323] and hybrid [24\u201332] models, to name but a few. The continuum models typically employ coupled partial differential equations (., diffusion-reaction equations) characterizing tumor population evolution in homogeneous microenvironment as well as the evolution oxygen and nutrient concentrations due to cancer cell consumption and metabolism. The continuum models are able to capture the complex diffusion dynamics of the nutrients, the tumor growth and cell apoptosis as well as the effects of chemotaxis and cell adhesion, and can be easily employed to investigate large systems containing millions of cancer cells in the mature tumor. However, the detailed evolution and phenotype heterogeneity of individual tumor cells cannot be studied using the continuum models.\nIn the discrete models, individual tumor cells are explicitly considered and the tumor system can be represented using either the particle-assembly model [21] or the cellular automaton (CA) model [16\u201320]. In the particle-assembly model, each tumor cell is represented as a bag of incompressible fluid enclosed by a hyper-elastic membrane with prescribed properties, which can capture detailed morphology evolution of the entire proliferative colony. In the CA model, the simulation domain is pre-tessellated into "automaton cells", and each automaton cell is assigned a value representing either a biological cell in a particular state (., proliferative, quiescent or necrotic) or a region of host microenvironment. The state of a specific automaton cell depends on those of the neighboring cells via prescribed CA rules. The original CA models were devised to simulate the proliferative growth of brain tumors [17] and have been recently generalized to investigate phenotype heterogeneity, invasive growth [33,34], effects of confined heterogeneous environment [16,34], angiogenesis [18,25], and tumor dormancy [23]. The hybrid models typically integrate the continuum model for nutrient concentration evolution and the CA model for individual cell dynamics, explicitly considering the coupling of the two via nutrients up-take and consumption for cell proliferation [24\u201327]. Due to the computational cost, most existing hybrid models are focused on 2D systems. The readers are referred to recent reviews for a more detailed discussion of the aforementioned tumor simulation models [35\u201338].\nAn outstanding issue in oncotherapy is the lacking of a systematic understanding of the evolution and growth dynamics of invasive solid tumors in response to different chemotherapy strategies. Such an understanding is crucial for the development of individually optimized oncotherapy. Typical chemotherapeutic agents (drugs) interfere with cancer cell division (mitosis) to cause cell damage or death, suppressing the overall growth of the tumor [39,40]. Generally, drug macromolecules are transported to the tumor site via diffusion in the stromal and then up-taken by the tumor cells. The effectiveness of chemotherapy strongly depends on the drug concentration around the tumor cells. However, a high drug concentration also damages normal and healthy tissue cells, leading to significant side effects for the patient. An optimized dosing strategy that can result in efficient elimination of tumor cells while maintaining the integrity and functionality of normal healthy tissues is crucial to the success of the cancer treatment. Periodic dosing [41,42] has recently been suggested as a promising treatment strategy. In order to maximize the treatment effectiveness, the heterogeneity of the tumor-host system [43,44] as well as the variation in the drug\u2019s cytotoxicity (cell killing) and the effects of tumor hypoxia [39,40] should also be taken into account.\nIn most chemotherapy, the anti-tumor drugs are either absorbed in the digestion system or directly injected into the circulation systems, and then transported different organs and tumor sites by the blood vessels. The drugs then diffuse into the avascular tissues while being metabolized by cells. The evolution of average drug concentrations in plasma, interstitial tissues and different organs can be captured via the pharmacokinetic (PK) calculations [45\u201347]. Such PK calculations involve master ordinary different equations (ODE) that take into the consumption of drugs due to decomposition and metabolism, as well as transport of drugs between different counterparts (., organs) in the body. Although the PK models can provide average drug concentration in different organs, it is not able to describe the detail temporal-spatial evolution of drug concentration within an organ or tissue. To solve such temporal-spatial evolution, diffusion-reaction models are usually employed, in which the consumption of drugs is quantified via the "sink" terms in the associated partial differential equations (PDE).\nRecently, significant research efforts have been devoted to computational modeling of various aspects of chemotherapy. For example, the effects of spatial heterogeneity in drug concentration [48], vascular structure and heterogeneous host environment [7,49], cell packing density [50], intrinsic heterogeneity in cell phenotypes and cell cycles [51\u201356] on the effectiveness of treatment and acquired drug resistance [57,58] have been systematically studied. Computational tools for treatment optimization have been devised [59\u201362] and data-based platform has been developed to assess robustness of treatment [63].\nIn this work, we develop a hybrid three-dimensional computational model that integrates the physiologically based pharmacokinetic model, continuum diffusion-reaction model and discrete cell automaton model to investigate 3D invasive solid tumor growth in heterogeneous microenvironment under chemotherapy. In particular, we explicitly consider the effect of heterogeneous environment on drug diffusion, tumor growth and invasion as well as the drug-tumor interaction on individual cell level. We employ the hybrid model to investigate the effectiveness of two ideal used dosing strategies, ., constant and periodic dosing, in controlling the growth of avascular invasive solid tumors. Our model indicates the observation that constant dosing is generally more effective in suppressing primary tumor growth compared to periodic dosing, due to the resulting continuous high drug concentration [64\u201367]. However, the suppression of primary tumor progression does not necessarily lead to a suppression of invasive cell migration, which results in complex invasion branches emitting from the primary tumor [68\u201371]. Moreover, we show that microenvironment heterogeneity can significantly enhanced the malignancy of the tumor and thus, reduce the effectiveness of the chemotherapy with even periodic dosing [72].\nIt is important to emphasize that the key component of our framework, ., the hybrid CA model coupled with diffusion reaction equation (DRE) for drug concentration evolution, does not depend on the pharmacokinetic model, vascular/avascular conditions, and assumptions of the dosing scenarios, which only provide different (transient) boundary conditions for the hybrid model. Therefore, we also believe that our 3D hybrid model (CA+DRE) is also a suitable tool in the simulation for the drug screening assays with the tumor spheroid [73,74] in vitro, given proper boundary conditions for drug concentration. These high-throughput-screening techniques are very common in the present anticancer drug tests.\n2. Materials and methods\nIn our model, the computational domain is a sub-region in an organ that contains both the growing avascular tumor with possible invasive branches and the surrounding stroma. Specifically, we consider two types of the host micro-environment respectively with avascular tissues (Fig 1A) and with vascular tissues (Fig 1B). In the early stage of tumor growth, there are no capillary vessels around the tumor cells; in the later stage angiogenesis often appears by the VEGF and the micro-environment around the tumor becomes vascularized. In this later stage the nutrients, as well as the drugs are much easy to reach the tumor region. In our model, we use the pharmacokinetics to simulate different drug variations, as is stated below.\nFig 1. Schemes of the tumor-drug model and the time-dependency of drug concentration.\n(a) and (b): 2D schematic illustrations of the tumor-drug models in this paper for the avascular tumor in an avascular (a) and vascular (b) host micro-environment, respectively. The Voronoi polyhedral in the figure is used in the CA model. The necrotic cells are black, quiescent cells are yellow, proliferative cells are red and the invasive tumor cells are green. The ECM associated automaton cells are white and the degraded ECM is blue. And the overlapped square grid (blue) is used in the finite difference calculation for the drug diffusion. (c) The drug (CPT-11) concentration dependence on time in the plasma (C1) and the avascular tumor (C2) calculated by the two-compartmental PBPK model (Eqs 1 and 2). The parameters used in the calculation are: k21 =  day-1; k12 =  day-1; k10 =  day-1; V1 =  \xd7 103 ml; V2 =  \xd7 103 ml. The initial condition at t = 0 is set as C1 =  \u03bcg/ml and C2 =  \u03bcg/ml. (d) Schematic illustration of the hybrid-parallel algorithm coupling the drug diffusion/consumption and cell division processes. The Fortran commands (do i = 1, N; enddo) in the rectangles indicate the loops in our algorithm.\nWe consider that within the simulation domain, there are no blood vessels and the drugs are transported to the tumor region via diffusion. The drug contraction in the organ will first be obtained via the physiologically based pharmacokinetic (PBPK) model and imposed as boundary condition at the boarder of the computational domain.\nThe evolution of drug concentration within the computational domain is described by a diffusion-reaction equation, which includes position dependent diffusion coefficient for heterogeneous microenvironment and consumption terms characterizing the drug\u2019s metabolism and decomposition. Different dosing strategies are simulated using different time-dependent boundary conditions. The evolution of the invasive solid tumor is simulated using the cellular automaton model. Specifically, the probability of division of each proliferative cell is now considered a function of not only the local microenvironment (., ECM density, rigidity and pressure) but also the local drug concentration computed using the diffusion-reaction equation. We consider the migration an invasive cell depends only on the microenvironment. In the subsequent subsections, we will provide detailed descriptions of these models and their integration.\nIn most chemotherapy, the anti-tumor drugs are either absorbed in the digestion system or directly injected into the circulation systems, and then transported to different organs and tumor sites by the blood vessels. The decay of average drug concentrations over time in different organs (due to transport of drugs among different organs and drug consumption) is usually described by a set of coupled ordinary differential equations referred to as the physiologically based pharmacokinetic (PBPK) models [45,47,75]. Here, we apply a two-compartment PBPK model, in which the drug concentrations in a vascularized compartment (C1) and the concentration in an avascular compartment (C2) are considered. For the vascularized compartment, ., a tumor micro-environment with a high density of blood vessels in the stromal tissue, the transport of drugs is mainly through blood vessel. For the avascular compartment, ., an avascular tumor, the drug transportation is mainly via diffusion in the stromal. The corresponding PBPK equations characterization the temporal evolution of C1 and C2 are given below:\n(1)(2)\nwhere k21, k12, k10 are transport rate constants (for example, k21 is the transport rate from compartment 2 to compartment 1; k10 is the transport rate from compartment 1 to compartment 0: which is the other organs); V1 and V2 are volumes of the compartments, S(t) is the time-dependent dosage as a drug source. Eq 1 means that the change rate of C1 consists of the incoming flow from the compartment 2 (the first term); the outgoing flow (the second term) and the injection flow from the dosage source (the last term).\nUsing the same set of model parameters and initial conditions given in Ref. [45] (see the values in the caption of Fig 1C, we can calculate of the average drug (CPT-11) concentration as a function of time in the vascularized and avascular compartments, representing respectively a vascularized and avascular tumor environment, for a given dosing condition. Fig 1C shows the results for an impulse dosing at t = 0. It can be seen that in both compartments, the average drug concentration decays monotonically with time and C1 in the vascularized compartment possessing a much higher initial value, also drops much faster than C2 in the avascular compartment. This is due to the different drug transport mechanism. These PBPK results are imply that the drug concentration in tumors in avascular micro-environments decays much slower than that in those in vascularized micro-environments, although the initial concentration value in the avascular micro-environment is lower than that in the vascularized micro-environment for the same initial dosage.\nBased on the PBPK calculations, in our subsequent simulations, two distinct types of time-dependent boundary conditions characterizing the drug concentration at the boundary of our simulation domain will be used respectively for tumors in vascularized and avascular micro-environments. In particular, we consider that for the avascular micro-environment, the drug concentration has very slow decay after each bolus injection; and in the vascularized micro-environment, the drug concentration decays quickly after a bolus injection. On the other hand, for constant dosing, the drug is continuously supplied leading to an almost constant concentration level of the drugs in different compartments.\nTo simulate the temporal-spatial evolution of drug concentration in tumor systems, we employ the following diffusion-reaction model:\n(3)\nwhere D0 is the diffusion coefficient of the drug; the last two terms result from drug consumption. Specifically, the parameter Kmet is the first-order decay rate due to the chemical decomposition as the drug macromolecules diffuse in the stroma. The last term on the right hand side of Eq 3, usually referred to as the Michaelis-Menten metabolism term [26,46], characterizes the drug up-take by tumor cells, ., drug concentration will decrease in the presence of the tumor cells, and we set \u03bb0 = \u03bb14n, where n is the tumor cell number density, which is computed from CA model as described below.\nWe consider the simulation domain is initially drug free and the drugs enter the domain through the boundary. For constant dosing, a time-independent drug concentration value will be used of the boundary condition. For periodic dosing, a general time-dependent boundary condition suggested by the PBPK calculations is employed to capture the time-evolution of drug concentration in the tumorous organ due to pharmacokinetics as well as different dosing cycles. Specifically, in the early stage of one dosing cycle, ., the drug infusion period characterized by the infusion time \u03c4infusion, the drug concentration approximately remains a level in the system and then decays to zero after \u03c4infusion as indicated by pharmacokinetics. This infusion-decay process corresponds to a complete dosing cycle with a period \u03c4cycle and such a process is repeated to simulate periodic dosing. For different tumor micro-environment (., vascularized vs. avascular), the rate of decay for the drug concentration is taken differently according the PBPK calculations.\nTo numerically solve the diffusion-reaction Eq 3, we use the finite difference method. In particular, the simulation domain containing the solid tumor and stroma is discretized into a cubic grid with points. The Euler forward-finite difference scheme is used, .,\n(4)\nwhere the Laplacian operator for spatial finite difference is written as\n(5)\nThis algorithm is numerically stable for the pure diffusion equation, if the following condition is satisfied [76]\n(6)\nWe have verified that Eq 6 is also sufficient to guarantee numerically stability for Eq 4. ni,j,k is the cell density from the CA model, as is described later.\nThe obtained drug concentration value on each grid point is then mapped to the nearest automaton cells, which is then used to determine the decrease factor for the division rate of the proliferative cells in the CA model. The number of automaton cells representing the tumor cells within the volume element associated with a grid point is also obtained and used to calculation the tumor cell number density n for Eq 3. The detailed implementation for coupling the continuum diffusion-reaction model and the discrete CA model is provided in Sec. .\nWe employ the cellular automaton (CA) model to simulate the evolution of invasive tumor in heterogeneous microenvironment under the effects of chemotherapy. Our CA algorithm follows closely that described in Refs. [33] and [34]. In particular, the simulation domain is tessellated into polyhedra (or polygons in 2D) associated with a prescribed point configuration (., the centers of randomly packed congruent hard spheres) via Voronoi tessellation. Each polyhedron is defined as an automaton cell, which in our model can either represent a real biological cell or a region of tumor stroma (which consists of a cluster of ECM macromolecules). The tumor cell can be proliferative, quiescent, necrotic or invasive in our model (see details below). Accordingly, the tumor-associated automaton cell can take distinct numerical values representing the different tumor cell state. Each ECM-associated automaton cell possesses a local density value \u03c1ECM to take into account the ECM heterogeneity, which is also positively correlated with the local ECM rigidity. When an ECM-associated automaton cell is taken by a tumor cell due to either proliferative growth or invasion, we set its \u03c1ECM = 0.\nIn our simulation, the tumor cells in the proliferative rim (mainly in the outer shell of the primary tumor which has access to the nutrients such as oxygen and glucose) can produce daughter cells taking nearby ECM-associated automaton cells via cell division. This process leads to the growth and expansion of the primary tumor mass. The tumor cells in the inner region may turn into quiescent (alive but inactive) and then necrotic (dead) if they could not acquire sufficient nutrients for a long time. A small fraction of daughter cells may acquire invasive phenotype (., weak cell-cell adhesion, strong mobility and ECM degradation ability) via mutation, which can leave the main tumor body and immigrate into the surrounding tissue leading tumor invasion. In our simulation, time is discretized into days, and for each day, the state of all tumor cells are checked for possible update. During each day, the evolution of the tumor is simulated by applying the following cellular automaton (CA) rules:\n1. The quiescent cells more than a certain distance \u03b4n from the tumor surface are turned necrotic due to starving. The critical value of \u03b4n is given as\n(7)\nwhere a is a prescribed scaling parameter (see Table 1) and d is the spatial dimension. Lt is the distance between the geometric centroid (xc) of the tumor and the tumor edge cell that is closest to the quiescent cell considered. xc is defined as , where N is the total number of noninvasive tumor cells, which is updated when a new noninvasive daughter cell is added to the tumor.\n2. Each proliferative cell can produce a daughter cell the probability Pdiv, which will occupy an ECM-associated automaton cell in the surrounding stroma. We consider that the probability of division depends on both the heterogeneous environment and local drug concentration and possess the following expression [33,34]\n(8)\nwhere p0 is the base probability of division, P\u03b3,\u03c6 is the cellular division reduction factor due to the chemotherapy and is considered a linear function of normalized local drug concentration (\u03c6), ., P\u03b3,\u03c6 = 1 \u2013(1- P\u03b3) \u03c6; is the distance of the dividing cell from the tumor centroid; Lmax is the distance between the tumor centroid and the closest growth-permitting boundary cell in the tumor growth direction. Eq 8 implies that Pdiv depends on both the physical confinement imposed by the boundary of the growth-permitting region and the local mechanical interaction between tumor cell and the ECM, as well as the local drug concentration.\n3. A proliferative cell turns quiescent if it is more than a certain distance \u03b4p from the tumor surface or there is no space for the placement of the forthcoming daughter cells. The distance \u03b4p, which corresponds to the thickness of nutrient-rich proliferative rim of the primary tumor, is given by\n(9)\nwhere b is a prescribed scaling parameter (see Table 1), Lt is the distance between the tumor centroid and the tumor edge cell that is closest to the proliferative cell considered.\n4. A newly produced daughter cell can gain invasive phenotype (weak cell-cell adhesion, high motility and strong ECM degradation ability) and become an invasive cell with the mutant probability \u03b3 (see Table 1). Only when the daughter cell has such mutation probability and the number of its neighboring cells is less than the adhesion value Ai, can it turn into the invasive cell.\n5. A mutant invasive cell has the ability to degrade the nearby ECM and migrate into the surrounding stroma. We consider that the invasive cell has the mobility: \u03bc, which is the upper bound on the number of attempts the cell makes to degrade the surrounding ECM and migrate into the ECM-associated automaton cell. For example, an arbitrary invasive cell can make m attempts to degrade ECM and move, where m is an arbitrary integer in [0, \u03bc]. In each degradation/moving attempt, the density of the ECM-associated automaton cell will be decreased by \u03b4p, where \u03b4p is an arbitrary real number in [0, \u03c7] characterizing the cell\u2019s ECM degradation ability. After m attempts, if the ECM in the automaton cell is completely degraded (\u03c1ECM \u2264 0), the invasive cell will migrate into this automation cell, leaving behind a path composed of degraded ECM-associated cells. The direction of motion is the one that maximizes the nutrient concentration.\n. Spatial-temporal coupling of the diffusion-reaction and cellular automaton models\nIn order to investigate the effects of chemotherapy on tumor growth, one needs to couple the diffusion-reaction model describing the drug diffusion and consumption with the CA mode for tumor dynamics. Although the spatial coupling of the two models is straightforward by mapping the computational grid points for PDEs to the CA cell positions, the temporal coupling can be nontrivial.\nWe first estimate the characteristic drug diffusion time in the tumor. From the analytic solution of diffusion equation in a homogenous medium: for the initial condition [77], we can define a characteristic "diffusion time" , at which the concentration at x0 is high enough (about compared to that at the source). For an example of a real tumor, if we set D =  \xd7 10\u22126 cm2s-1, x0 =  cm, we see tm =  \xd7 104 s, or about 0. 2 day. Comparing the common cell cycle time (ranging about 8 hours to 24 hours), we see that for the ordinary drug, the characteristic diffusion time is typically less than one cell cycle.\nThe above analysis suggests that the drug can diffuse rapidly into the tumor, and thus the drug concentration may change significantly in one cell cycle due to cellular uptake of the drug macromolecules and metabolism. However, the traditional CA model usually sets the cell division rate (Pdiv) as a constant in one cell cycle. So in our hybrid model, it is not suitable to do the drug diffusion calculation between two cell cycles. In the actual system, drug diffusion and cell division occur simultaneously and can have instant effects on one another: on one hand the drug concentration reduces the cell division rates (see expression of P\u03b3,\u03c6 in Eq 8); on the other hand, the growing tumor increases the tumor density n, which leads the drug consumption (see the last term in Eqs 3 and 11) and the variation of diffusion coefficient. The diffusion coefficient (D) is also related to the cell density, as will be presented a gas diffusion model in Eq 13 later.\nIn our model, we develop a quasi-parallel algorithm for coupling these two processes: We divide one cycle of the proliferation process (during which cell divides) and one dosing period (during which the drug diffuses into the tumor mass) into the same number of (Np) steps. In each step, these two dynamical processes are simulated in sequence for different iterations. Then at the end of each step, the updated drug concentration distribution obtained from the diffusion-reaction model is passed to the CA model to compute updated cell division reduction factor; and the updated cell density distribution and heterogeneous diffusion coefficient distribution obtained from the CA model are passed to the diffusion-reaction model. Fig 1D schematically illustrates this procedure. We note that the aforementioned procedure not only enables easy parallelization of our hybrid algorithm but also more realistically mimics the actual tumor proliferation process compared to traditional CA method. In particular, in traditional CA method, the fact that tumor cells divide at different times within a proliferation cycle is not explicitly considered. Here, by coupling a sub-spatial region of the tumor with a sub-temporal process of drug diffusion, we consider that the cells within this sub-region divide during the time span in which the diffusion occurs. This implies that tumor cells in different sub-region divide at different times. When Np is sufficiently large (., = 50 ~ 100), the quasi-parallel algorithm can approximate the actual coupled processes. At last, we notice that in this coupling algorithm, we calculate the cell density in CA model by the expression: , where nm = 0 or 1, for all the tumor cells in the neighbor of a finite difference grid point (i,j,k), \u0394V is the unit volume of the grid. This is used in the consumption calculation for Eq 4. We use a mapping scheme to relate these quantities (such as ni,j,k, , ) between the finite difference grid and the Voronoi tessellation.\n3. Results and discussions\nIn this section, we first study the drug dynamics in a steady-state tumor (., with constant cell density distribution), in order to understand the spatial-temporal evolution of drug concentration within one proliferation cycle for both constant dosing and periodic dosing conditions. Then we employ the model to investigate the growth of avascular tumors in both vascularized and avascular homogeneous environments under constant and period dosing conditions. Finally, the coupled hybrid model is employed to study the effects of periodic dosing conditions on invasive tumor growth in heterogeneous microenvironment.\nIn the constant dosing condition, the boundary condition is set as a time-independent constant in the outer spherical shell (with the radius R =  cm) without any decay due to pharmacokinetics and is zero within the tumor region. In addition, we assume that steady-state tumor possess an ideal isotropic morphology, and tumor cell density distribution as one moves away from the tumor center can be characterized by a Fermi function (1/(1 + exp[(r\u2014r0)/\u03c3]), where r0 is the tumor radius and \u03c3 is the effective boundary-layer thickness.\nThe diffusion-reaction Eq 3 is employed to obtain the drug concentration distribution as a function time. In particular, we consider tumors with different sizes r0 and drug consumption ratio \u03bb14. Fig 2A and 2B show respectively the distribution of drug concentration in a steady-state tumor with r0 =  cm and \u03c3 =  at t = 100 minutes and t = 5 hours for different consumption ratios (\u03bb14 =  \xd7 10\u22124 s-1, \u03bb14 =  \xd7 10\u22125 s-1 and \u03bb14 = 0). When there is no consumption, the evolution of the drug concentration is entirely controlled by the diffusion and chemical decomposition (Kmet) terms, and the concentration values in the inner tumor region is larger compared to the other two cases. In addition, it is clear that a larger consumption ratio leads to a lower drug concentration in the inner tumor region. The long-time drug concentration shown in Fig 2B represents steady-state solution to Eq 3. We note that the typical time to achieve this steady-state (5 hours in the current case) is faster than a typical cell proliferation cycle, which is consistent with our time-scale analysis discussed in Sec. . Fig 2C shows the drug concentration distribution in a smaller tumor (r0 =  cm and \u03c3 =  cm) as a function of time with a large drug consumption ratio \u03bb14 =  \xd7 10\u22124 s-1. Compared to Fig 2B, the steady-state of drug concentration distribution is established in a longer period of time, ., at t = 1000 minutes. This suggests that drugs need to diffuse through a wider region to achieve a steady distribution. Due to fast diffusion of drug and rapid establishment of the steady-state of drug concentration in the tumor region, we may approximate the actual drug distribution as a uniform constant for the constant dosing condition, as shown in later Sec. .\nWe now consider the periodic dosing condition and employ a time-dependent periodic boundary condition to simulate the dosing condition [78]. For the periodic dosing, due to different pharmacokinetics in vascularized and avascular host micro-environments (see discussion in Sec. ), we will consider these two cases separately. In particular, for the vascularized micro-environment, the drug is transported to the tumor region by blood vessels. For the avascular micro-environment, the drug reaches the tumor region mainly via diffusion. In the former case the drug concentration decays very quickly with an initial high value; and in the latter case, the drug concentration decays relatively slowly. In our simulation, we model these two cases by using different decay time parameters in the time-dependent boundary condition. Specifically, we assume that the drug concentration has the following time dependency\n(10)\nwhere \u03c4cycle is the dosing period and \u03c4decay is the decay time for the drug in the tumor (for taking into account the pharmacokinetics effects).\nFig 3 shows the spatial-temporal evolution of drug concentration in ideal isotropic tumors with r0 =  cm and \u03c3 =  cm for both vascularized [(a) and (b)] and avascular [(c) and (d)] micro-environments under different periodic dosing conditions. Specifically, two periodic dosing conditions are applied, which are shown as the black curves in Fig 3. We clearly can see that in the vascularized micro-environment, the drug decays rapidly (\u03c4decay = 600 mins) and in avascular micro-environment the drug decays slowly (\u03c4decay = 1800 mins). Moreover, in the avascular case, the drug is difficult to escape due to the pharmacokinetic analysis as shown in the black curves (on the tumor boundaries), the average drug concentration within the tumor always maintains in a relatively high level. This gives a positive effect on chemotherapy. Due to the decomposition and the small \u03c4decay (600 mins) leads to a very rapid decay of the drug concentration in the tumor, consistent with the pharmacokinetic analysis (see Fig 1B). In an avascular micro-environment, the large decay time (\u03c4decay = 1800 mins) leads to a slow decay of the drug within the tumor. Moreover, in the avascular case, the average drug concentration within the tumor always maintains in a high level. Due to the diffusion and consumption, the drug concentrations in the central tumor region exhibit smaller values as shown by the red dashed curves in Fig 3. With smaller drug consumption, the maximum concentration in the tumor center is larger, which is consistent with the cases for constant drug dosing conditions. Finally, we observe that there is a phase shift for the periodic variation of dosage (black curves) and drug concentration in the tumor (red curves). This is because that drug needs some time to diffuse from the outer boundary to the inner region.\n(a) and (b) are associated with the vascularized micro-environment with quick drug decay (\u03c4decay = 600 min); (c) and (d) are associated with the avascular micro-environment with a slow drug decay (\u03c4decay = 1800 min). (a) and (c) are associated with a small drug consumption ratio (\u03bb14 =  \xd7 10\u22125 s-1); (b) and (d) are associated with a large drug consumption ratio (\u03bb14 =  \xd7 10\u22124 s-1). The chemical decomposition parameter is the same in all cases: Kmet =  \xd7 10\u22124 min-1. The black curve indicates the applied time-dependent boundary condition and the red curve indicates the drug concentration in the tumor center region. The dosing period is set as \u03c4decay = 1 day = 1440 min. The tumor size parameters are set as r0 =  cm and \u03c3 =  cm.\n. Evolution of invasive tumors in homogeneous microenvironment under chemotherapy\n. Invasive tumor growth under constant dosing condition.\nWe now employ the hybrid model to study the growth dynamics of invasive tumor under constant dosing condition in homogeneous microenvironment. To simulate the constant dosing condition, we apply a time-independent constant drug concentration at the boundary of the simulation domain. As discussed in Sec. , in this case, the drug concentration evolution is the same for both vascularized and avascular micro-environments as the pharmacokinetics does not play a role here. The effects of different drug concentrations are taking into account by using different cell division reduction factor (=  and ). Here P\u03b3,\u03c6 in the CA rule 2 in Sec.  is spatial independent, P\u03b3,\u03c6 = ). We chose the cell cycle time as one day. In the subsequent simulations, we focus on the early growth stages of the tumor.\nThe growth dynamics of proliferative tumors, ., the tumor size (radius) as a function of time is shown in Fig 4A. We can see that when the drug is infused in the tumor, its growth is significantly suppressed. Higher drug concentration (., associated with a larger of division reduction ) leads to the slower growth of the tumor. This is expected as the drug can significantly suppress the division of proliferative cells which is a determinant factor for the tumor growth process.\n(a) The growth dynamics of proliferative tumors with different drug concentrations in homogeneous microenvironment. (b) The average sizes of invasive tumor cells as a function of growth time without chemotherapy. (c) The average sizes of invasive tumor cells as a function of growth time with a division reduction factor = . (d) A snapshot of the simulated growing tumor without chemotherapy on day 120 (with 142 invasive cells); (e) A snapshot of the simulated growing tumor under constant dosing condition ( = ) on day 120 (with 31 invasive cells). As stated in the context, in this figure the micro-environment can be either avascular or vascularized. In (d) and (e), only the proliferative cells (red), the invasive cells (yellow) and the degraded ECM cells (cyan) are plotted.\nNext, we consider invasive tumor growth under the constant dosing condition with a high drug concentration ( = ). The mutation rate and mobility of the invasive cells are respectively set as  and 3 following Ref. [34]. The ECM degradation ability is . Fig 4B and 4C shows the average linear size associated with the quiescent region, proliferative rim and invasive branches as growth time for a freely growing invasive tumor and one under chemotherapy for purposes of comparison. Snapshots of the morphology of the growing invasive tumors are also shown in Fig 4D and 4E.\nWe can see from Fig 4B and 4C that when the drug is applied, the expansion of both the proliferative tumor and the invasive cells are apparently surprised. A more quantitative comparison shows that although proliferative cells grow much slower (the final primary tumor size is decreased by 50%) with drug infusion, the growth of the invasive cells is only weakly suppressed (the final extent size is decreased by 20%). In the chemo treated tumors, the invasive cells can still develop long invasive branches (see Fig 4E compared to the free growth case. The apparent decrease of the overall extent of the invasive branches is due to the significantly reduced size of the primary tumor. In fact, the average linear extent of the invasive cells remains roughly the same as in the free growth case. This is because the drug does not affect the motility and ECM degradation of the invasive cells. However, the number of invasive cells is reduced by applying the drug, which is again due to the reduced division rate of the proliferative cells (., less mutant daughter cells with invasive phenotype are produced).\n. Invasive tumor growth under periodic dosing condition.\nWe now investigate the effects of drugs on the tumor growth under periodic dosing condition. In this condition, drugs are periodically applied and the drug concentration decays in a different manner in vascularized and avascular micro-environments as predicted by the pharmacokinetic calculations. Specifically, for the vascularized micro-environment, the drug concentration at the simulation domain boundary drops very quickly due to the fast transport via blood vessels; and for the avascular micro-environment, the drug concentration at the tumor boundary decays relatively slowly due to diffusion.\nFig 5A shows the growth dynamics of both proliferative and invasive tumors in vascularized micro-environment under periodic dosing conditions. The distribution of drug concentration within the tumor during one proliferative cycle is discussed in Sec. . Different dosages are applied, which leads to different cellular division reduction factors ., P\u03b3 = ;  and  used in the simulations. For purpose of comparison, we also consider the growth proliferative tumor without chemotherapy and with two different constant dosing conditions (P\u03b3 =  and ).\n(a) Growth dynamics of the tumor in vascularized homogeneous microenvironment under different periodic dosing conditions. Effects of different dosages are modeled via different division reduction factor P\u03b3, with a dosing period and decay time of \u03c4decay = 1 day and \u03c4decay = 600 min, respectively. For purpose of comparison, the results for constant dosing with P\u03b3 =  and  as well as freely growing tumors are also shown. (b) Growth dynamics of the invasive tumor in avascular homogeneous microenvironment under different periodic dosing conditions. The dosing period \u03c4cycle, decay time \u03c4decay are shown in the figure. Here a division reduction factor P\u03b3 =  is used. The results for tumor in vascularized micro-environment with small decay time (cases 1 and 2) are also shown for purpose of comparison with the tumors in avascular micro-environment (cases 3 and 4). The consumption parameters used are Kmet =  \xd7 10\u22124 min-1, \u03bb14 =  \xd7 10\u22124 s-1 (cases 1, 2, and 3) and  \xd7 10\u22125 s-1 (case 4).\nWe can see from Fig 5A that in general periodic dosing conditions do not lead to the strong suppression of tumor growth as in the constant dosing cases, even for the high drug concentration cases (with a division reduction factor P\u03b3 = ). This is because for the periodic dosing, the drug concentration drops quickly in the vascularized micro-environment, which results in a weaker reduction of cellular division. This is to contrast with the constant dosing condition, which has been shown to be able to significantly suppress tumor growth in both vascularized and avascular micro-environments. However, such dosing condition can cause also damages to the normal cells and serious side effects. Thus, an alternative strategy is to infuse the drug more frequently with a shorter dosing period, as we will show below.\nThe growth dynamics of an invasive tumor under periodic dosing condition with P\u03b3 =  is also shown in Fig 5A. We see that the growth curve of the primary tumor almost coincides with that of the proliferative tumor with the same P\u03b3. This is because although the invasive cells leave the primary tumor and migration into surrounding tissues, the division rate of the proliferative cells in both cases are almost identical, leading to the same primary tumor sizes.\nWe now investigate the effects of different periodic dosing conditions on the growth of invasive tumors in avascular micro-environment. Fig 5B shows the growth dynamics of the primary tumor for different dosing period \u03c4cycle and decay time \u03c4decay but the same division reduction factor P\u03b3 = . As shown in Fig 5B, cases 1 and 2 are associated the small decay time (\u03c4cycle > \u03c4decay), corresponding to the tumors in vascularized micro-environment for which the drug concentration decays very quickly due to fast pharmacokinetics. Cases 3 and 4 are associated with the large decay time, corresponding to the tumors in avascular micro-environment. It can be clearly seen that in the latter cases (., avascular cases) the drug can effectively suppress the tumor growth. The reason is that for the avascular micro-environment the drug decay is much slower (also see Fig 1C. This results in a higher drug concentration to suppress the tumor cell division. In addition, a large consumption parameter (\u03bb14 =  \xd7 10\u22124 s-1) is used for case 3, and a small consumption parameter (\u03bb14 =  \xd7 10\u22125 s-1) is used for case 4. We see that with a smaller consumption parameter, the drug concentration can remain a higher for a longer time, which leads to continuously suppression of tumor cell division and thus, a smaller final tumor size.\nFinally, we investigate the invasive tumor morphology under these periodic dosing conditions. Fig 6A\u20136C shows the snapshots of the growing tumors at day 120 under periodic dosing with different decay times, ., a fast decay with \u03c4decay = 600 min for (a) corresponding to tumors in vascularized micro-environment; and a slow decay with \u03c4decay = 1800 min for (b) and (c) corresponding to tumors in avascular micro-environment. We see that in all cases, there are a large number of dendritic invasive branches composed of collectively migrating invasive cells. Since the drug only reduces the proliferative cells\u2019 division rate, the linear extents of the invasive branches in all cases are almost the same. The sizes of the tumors in avascular micro-environment in Fig 6B and 6C are smaller than the tumors in vascularized micro-environment in Fig 6A, which is due to the higher effective drug concentration in the avascular systems. The small consumption in (c) also leads to a decreased size than that in (b).\nIn all these cases, the same dosing period \u03c4cycle = 1 day, chemical decomposition parameter Kmet =  \xd7 10\u22124 min-1, and division reduction factor P\u03b3 =  are used. Here only the proliferative cells (red), the invasive cells (yellow) and the degraded ECM cells (cyan) are plotted. (a)-(c): Snapshots of the simulated invasive tumors in homogeneous microenvironment under periodic dosing conditions at day 120. (a) is the tumor in vascularized micro-environment with a quick drug decay (\u03c4decay = 600 min) due to fast pharmacokinetics and a small consumption parameter ( \xd7 10\u22125 s-1); (b) is the tumor in avascular micro-environment with a slow drug decay (\u03c4decay = 1800 min) and a large consumption parameter ( \xd7 10\u22124 s-1); (c) is the tumor in avascular micro-environment with a slow drug decay (\u03c4decay = 1800 min) and a small consumption parameter ( \xd7 10\u22125 s-1). (d)-(e): Snapshots of the simulated tumors in heterogeneous microenvironment (with a random distribution of ECM density). (d) The ECM density ranges from  to  and with an average value of ; (e) The ECM density ranges from  to  and with an average value of .\nIn this section we employ our hybrid model to investigate invasive tumor growth in heterogeneous environment under periodic dosing conditions. To accurately capture the diffusion dynamics of drugs in the heterogeneous stroma, we explicitly utilize the location-dependent diffusion coefficient in the diffusion-reaction equation, .,\n(11)\nThe discretized form of the heterogeneous diffusion term in Eq 11 is given below\n(12)\nThe diffusion coefficient in a heterogeneous ECM depends on the local ECM density, which also represents the rigidity of the system in our model. Following the formulation of heterogeneous gas diffusion coefficient in systems with non-uniform pressures [79], we use the following empirical expression for (13)\nwhere D0 is the diffusion coefficient in the uniform ECM possessing a density of \u03c10ECM, \u03c1res is the residual density after the ECM is completely degraded by the invasive cells. In the following simulations, we employ a random distribution for the ECM density and choose \u03c10ECM = , which is the value used for the homogeneous ECM in previous sections. And we choose \u03c1res = . In addition, we set \u03b7 =  since the diffusion in the tumor region is evidently slower due to high cellular density than that in the ECM.\nIn the heterogeneous environment, we use the following sinusoidal-like distribution to describe the initial (time = 0) ECM density\n(14)\nwhere \u03c1ECM,av is the average ECM density, \u03c1ECM,flue is the ECM fluctuation amplitude, Lx(Ly, Lz) is the sinusoidal period. In our simulation, we set \u03c1ECM,av =  for Fig 6D and \u03c1ECM,av =  for Fig 6E. Lx(Ly, Lz) is about L/60 or L/30, where L is the size of the cubic simulation box.\nSnapshots of the morphology of both proliferative and invasive tumors growing in heterogeneous ECM with random density under periodic dosing are shown in Fig 6D and 6E. It can be clearly seen that in the heterogeneous ECM, the tumors develop rough and bumpy surface due to position dependent inhomogeneous cell division probability, as well as varying division reduction factors due to inhomogeneous drug concentration. This phenomenon has also been observed in the previous work for tumors growing in heterogeneous ECM with high rigidity [34].\nTable 2 provides a detailed summary of the model parameters for different periodic dosing conditions as well as the growth data of tumors in both vascularized and avascular micro-environments on day 120 in the heterogeneous ECM. We can clearly see that for periodic dosing, the treatment is more effective in suppressing tumors in avascular heterogeneous micro-environment than that in vascularized heterogeneous ECM, consistent with the cases in homogeneous ECM. In addition, we find that denser and more rigid ECM (., with average density ) leads to an overall smaller tumor. However, under the same dosing condition, the tumor growing in heterogeneous ECM becomes more malignant (with larger primary tumor size and more invasive cells) compared the tumor growing in homogeneous ECM with the same density (\u03c1ECM = ).\nTable 2. Summary of the model parameters for different periodic dosing conditions (the division decay factor P\u03b3; the consumption parameter \u03bb14; the two periodic dosage times \u03c4cycle and \u03c4decay) as well as the growth data of tumors in both vascularized and avascular micro-environment (the averaged radius of proliferative cells and invasive cells Rp and RInv; the number of invasive cells NInv) on day 120 in the heterogeneous ECM.\nThe brackets in the last column indicate the corresponding morphology plots in Fig 6.\nWe note that a high ECM density, on the one hand, can suppress tumor growth; and on the other hand, can slow down the drug diffusion to the tumor region, which promotes tumor growth. Therefore, the actual tumor growth dynamics in heterogeneous ECM is the outcome of these two competing effects. For the case of average \u03c1ECM = , the diffusion of the drug is significantly slowed down while the density is not high enough to sufficiently suppress tumor growth, leading to a larger tumor compared with that in homogeneous ECM with the same density. For the case of an average \u03c1ECM = , the ECM density is large enough to suppress tumor growth even with very little drugs, and thus, results in a smaller tumor compared to that growing in corresponding homogeneous ECM. However, the invasiveness of the tumor growing in heterogeneous ECM with high density is significantly enhanced, which is consistent with the observation reported in Ref. [34].\nTo further demonstrate the utility and predictive capability of our hybrid model, we now examine the effects of periodic dosing on the growth dynamics of proliferative tumors in highly heterogeneous microenvironment. Specially, we consider two distinct cases for the environmental heterogeneities: (i) geometrically confined microenvironment and (ii) spatially non-uniform drug dosing.\n. Effects of geometrically confined microenvironment.\nCertain tumors such as ductal carcinoma in situ (DCIS) grow in a geometrically confined microenvironment, which usually results in a highly anisotropic tumor shape. On the other hand, the heterogeneity of the microenvironment also significantly influences the diffusion of drugs to the tumor site. Here, we apply our hybrid model to investigate the effects of periodic dosing on proliferative tumors growing in confined environment. The effects of the environmental confinement are modeled by a discontinuous distribution of ECM density. In particular, we consider the simulation domain is composed of two equal-sized sub regions. The left sub region possesses a higher ECM density value (\u03c1ECM = , ., to mimic the hard basal membrane) and the right region possesses a lower ECM density value (\u03c1ECM = , to mimic soft tissue). The dosing period is \u03c4cycle = 1 day, and the drug decay constant is \u03c4decay = 800 mins. The drug is released at the boundary of the spherical simulation domain with radius R =  cm (see Fig 1), which imposes a uniform initial high drug concentration at (and outside) the simulation boundary and zero concentration within the simulation domain. An initial tumor of linear size  cm is introduced in the center of the domain. The drug diffusion coefficient, which is a function of ECM density and local cell density, is obtained using Eq 13.\nThe spatial-temporal evolution of the drug concentration in the ECM-tumor system is obtained by numerically solving Eq 11. Fig 7A shows the drug concentration distribution in the x-y plane associated with z = 0 at t =  hour. Due to the high ECM density (., low drug diffusivity) in the left region of the simulation domain, a higher concentration is built up compared to that in the right region. This leads to an overall non-symmetric distribution of drug in the system. However, due to the small tumor cell population (and size) at this stage (shown as the red circle in Fig 7A), the difference in drug concentration in the left and right region next to the tumor is relatively small. Fig 7B shows the distribution of the division reduction factor Pr,\u03c6 in the proliferative rim at t = 15 days. We note that the observed fluctuations in Pr,\u03c6 is mainly due to the heterogeneous cell division time in our hybrid model. As discussed in Sec. , in our CA model we consider a proliferative cell can divide at any time during a dosing cycle, implying a random distribution of cell division time. Under periodic dosing condition, the drug concentration at a cell at the time of division is generally different from that of another cell, leading to the non-uniform distribution of Pr,\u03c6.\n(a) Asymmetric distribution of drug concentration in the x-y plane associated with z = 0 at t =  hour. the small red circle denotes the original tumor; (b) Distribution of the division reduction factor Pr,\u03c6 in proliferative cells in the x-y plane associated with z = 0 on day 15. The red dots denote the proliferative cells. (c) Snapshot of a proliferative tumor growing in the confined microenvironment with p0 =  on day 150; (d) Snapshot of a proliferative tumor growing in the confined microenvironment with p0 =  on day 150. In (a), (c), (d), the middle lines denote the interfaces between two different ECM densities (\u03c1ECM is  in the left side and  in the right side).\nFig 7C and 7D show the snapshots of the growing tumors (at t = 150 days) in the confined environment with two different cell division probabilities (p0 =  and ). It can be clearly seen that the tumor develops a highly anisotropic shape, indicating the majority of proliferation occurs in the right low-density ECM region. On the other hand, protrusion-like structures are developed across the soft-hard ECM boundary, which is a key feature of microenvironment-enhanced malignancy. We note that even after 150 days, the protrusions remain relative compact. This is to contrast the elongated dendritic protrusions typically found in tumors growing in drug-free hard ECM [20, 21]. These observations illustrate the effects of drug treatment on proliferative tumor in confined microenvironment.\n. Effects of spatially non-uniform drug dosing.\nFinally, we consider the effects of spatially non-uniform drug dosing. This is motivated by the fact that at certain stage of development, tumor cells can produce vascular endothelial growth factor (VEGF) to recruit endothelial cells for angiogenesis. The newly formed blood vessels can transport both nutrients and drugs to the local tumor site close to the blood vessels. When sufficient amount of drugs are transported to the tumor site, its local growth can be suppressed. Based on these considerations, in our simulation, instead of considering uniformly distributed vascular network (or avascular drug diffusion) on the tumor boundary as shown in Fig 1, we consider the blood vessels recruited by the growing tumor are located in the lower left region of the tumor-ECM system. This is implemented by releasing the periodically dosed drugs at the lower left of the spherical simulation domain. Here, we set the drug concentration on the lower left region as a source boundary condition, where is the periodical function in Eq 10 for only a restricted region, which satisfies the following conditions: ( cm \u2264 r \u2264  cm; x\u2013x0 < 0; y\u2013y0 < 0), where x0 = y0 = z0 =  cm, are the coordinates of the spherical center.\nFig 8A shows the distribution of drug concentration in the x-y plane associated with z = 0. It can be seen from Fig 8A that after initial releasing, the drugs quickly diffuse to the entire system and are consumed and degraded. The lower left region of the domain remains to possess a relatively high drug concentration even after  hours of dosing, suggesting a high suppression of tumor growth in this region. Fig 8B shows the distribution of the division probability Pdiv of the proliferative cells with z = 0. It can be seen that the cells in the lower left region possess a much smaller division probability due to the high drug concentration in this region. Fig 8C and 8D show the snapshots of two proliferative tumors with different cell division probabilities (p0 =  and ) at day 150. It can be seen that the effects of drugs are more significant in the fast growing tumor (Fig 8D). Specifically, the cell division in the lower left region of the fast growing tumor is strongly suppressed by the high drug concentration, which results in a relatively flat edge in this region. On the other hand, the slowly growing tumor develops a relatively isotropic shape with a slightly flat edge in the lower left region.\n(a) Evolution of drug concentration distribution in the x-y plane associated with z = 0. The drugs are dosed in the lower left region of the spherical simulation domain periodically. Left panel: t =  hours; right panel: t =  hours. (b) Distribution of the division probability Pdiv in proliferative cells in the x-y plane associated with z = 0 on day 15. The red dots denote the proliferative cells. (c) Snapshot of a slowly growing tumor with p0 =  on day 150. (d) Snapshot of a fast growing tumor with p0 =  on day 150.\n4. Summary and conclusions\nIn this paper, we presented a comprehensive investigation of the effects of different chemotherapy (., constant vs. periodic dosing) on the growth dynamics of invasive tumors in both vascularized and avascular 3D heterogeneous microenvironment using a novel hybrid computational model. Our hybrid model integrates the physiologically based pharmacokinetic model for predicting overall drug concentration decay in different types of tumors, the continuum diffusion-reaction model for spatial-temporal evolution of the drug distribution in tumor-ECM system, as well as the discrete cell automaton model for invasive tumor growth simulation under effects of drugs. This model allows us to explicitly consider the effects of heterogeneous environment on drug diffusion, tumor growth and invasion as well as the drug-tumor interaction on individual cell level.\nWe have employed the hybrid model to investigate the evolution and growth dynamics of avascular invasive solid tumors in both vascularized and avascular micro-environments under chemotherapy with both constant and periodic dosing. We find that constant dosing is generally more effective in suppressing primary tumor growth compared to periodic dosing, due to the resulting continuous high drug concentration. While periodic dosing is found to be more acceptable in suppressing tumor growth in micro-environment, due to the small side effects. However, as the chemotherapy is assumed not to suppress invasive cell migration, complex invasion branches emitting from the primary tumor have been found. In addition, we find that the malignancy of the tumor is significantly enhanced in highly heterogeneous microenvironment, leading to inefficient chemotherapy. We also use this model to the geometry-confined environment and non-uniform drug dosing situation. Our computational model, once supplemented with sufficient clinical data, could eventually lead to the development of efficient in silico tools for prognosis and treatment strategy optimization.\nIn our current model, the drug-tumor interaction is modeled as a reduction of the division probability (rate) of individual tumor cells, which depends on the local drug concentration. We note that this treatment does not explicitly consider the heterogeneity in the distribution of cell division time and cycle time and has assumed uniform distributions for these quantities. In future, we will further generalize our hybrid model to explicitly take into account the aforementioned heterogeneity, which would lead to a more accurate prediction of tumor growth dynamics under periodic dosing conditions.', 'subject': u'Sciences'}][corpus_en.py:243 - retrieve_feeds()]
INFO:10/29/2018 10:15:59 AM:Saving rss corpus to database[corpus_en.py:253 - save_rsscorpus_to_DB()]
INFO:10/29/2018 10:15:59 AM:(u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206729', u'Etats-Unis', u'Sciences', u'606', u'Correction: Correction: CDK1 Is a Synthetic Lethal Target for KRAS Mutant Tumours', u'', u'Correction: Correction: CDK1 Is a Synthetic Lethal Target for KRAS Mutant Tumours\n\nThere is an error in the Correction published on April 20, 2017. The correct affiliation for the eighth author, Alberto Bartelli, is Candiolo Cancer Institute-FPO, IRCCS, Candiolo, TO, Italy and Department of Oncology, University of Torino, Candiolo, TO 10060, Italy.', u'', u'', 0)[corpus_en.py:283 - save_rsscorpus_to_DB()]
INFO:10/29/2018 10:15:59 AM:(u'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0206721', u'Etats-Unis', u'Sciences', u'606', u'Correction: Familial risks of ovarian cancer by age at diagnosis, proband type and histology', u'', u'Correction: Familial risks of ovarian cancer by age at diagnosis, proband type and histology', u'', u'', 0)[corpus_en.py:283 - save_rsscorpus_to_DB()]
ERROR:10/29/2018 10:15:59 AM:1366[corpus_en.py:288 - save_rsscorpus_to_DB()]
ERROR:10/29/2018 10:15:59 AM:HY000[corpus_en.py:289 - save_rsscorpus_to_DB()]
ERROR:10/29/2018 10:15:59 AM:Incorrect string value: '\xCE\xB242 a...' for column 'V_title' at row 1[corpus_en.py:290 - save_rsscorpus_to_DB()]
INFO:10/29/2018 10:15:59 AM:Saving data into :./tobeindexed/test2.journalsplosorgplosonefeedatom.29-10-18_10.xml[corpus_en.py:304 - save_corpus_to_fileSOLRformat()]
INFO:10/29/2018 10:16:00 AM:indexing with XML procedure...
[corpus_en.py:393 - index_rssfeeds_solr2()]
INFO:10/29/2018 10:16:12 AM:  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0  814k    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0100  814k    0     0  100  814k      0   400k  0:00:02  0:00:02 --:--:--  400k100  814k    0     0  100  814k      0   268k  0:00:03  0:00:03 --:--:--  268k100  814k    0     0  100  814k      0   201k  0:00:04  0:00:04 --:--:--  201k100  814k    0     0  100  814k      0   161k  0:00:05  0:00:05 --:--:--  161k100  814k    0     0  100  814k      0   134k  0:00:06  0:00:06 --:--:--  162k100  814k    0     0  100  814k      0   115k  0:00:07  0:00:07 --:--:--     0100  814k    0     0  100  814k      0   101k  0:00:08  0:00:08 --:--:--     0100  814k    0     0  100  814k      0  92290  0:00:09  0:00:09 --:--:--     0100  814k    0     0  100  814k      0  83092  0:00:10  0:00:10 --:--:--     0100  814k    0     0  100  814k      0  75557  0:00:11  0:00:11 --:--:--     0100  815k  100   159  100  814k     13  73220  0:00:12  0:00:11  0:00:01     0100  815k  100   159  100  814k     13  73209  0:00:12  0:00:11  0:00:01     0
<?xml version="1.0" encoding="UTF-8"?>
<response>

<lst name="responseHeader">
  <int name="status">0</int>
  <int name="QTime">10375</int>
</lst>
</response>

[corpus_en.py:401 - index_rssfeeds_solr2()]
INFO:10/29/2018 10:16:12 AM:All is done! Quitting program.[corpus_en.py:432 - main()]
